[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Põhjuslike seoste hindamine majanduses",
    "section": "",
    "text": "Eessõna\nKäesolev lühikonspekt on mõeldud tutvustamaks mõju hindamise meetodeid majandustudengitele. Konspektis kasutatakse tarkvara R.\nKonspekt on jooksvalt täienev. Siia hakkan panema aines “Põhuse ja tagajärje seosed” kasutatud õppematerjale.\nMe kasutame näidisandmetena järgmisi andmefaile:\n\nPoliitikauuringute Keskuse Praxis 2002. aastal läbiviidud uuringu anonüümset andmefaili aktiivse tööpoliitika mõju hindamise kohta. (Vt Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 2003, 108 lk.)\nPIAAC uuringu avalikud andmefailid\nEesti Töötukassa anonümiseeritud näitefailid",
    "crumbs": [
      "Eessõna"
    ]
  },
  {
    "objectID": "01-sissejuhatus.html",
    "href": "01-sissejuhatus.html",
    "title": "1  Sissejuhatus",
    "section": "",
    "text": "Raamat on järgmise struktuuriga.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sissejuhatus</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html",
    "href": "pohimoistedkordamiseks.html",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "2.1 Potentsiaalse tulemuse mudel (POM)\nTudengid peaksid teadma järgmisi põhimõisteid.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "href": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "Mõiste\nSelgitus\n\n\nPõhjuslik mõju (Causal Effect)\nMõju on defineeritud kui kahe oleku (sekkumine \\(D=1\\) ja võrdlusseisund \\(D=0\\)) tulemuse võrdlus. See on see, mida püütakse hinnata.\n\n\nPotentsiaalne tulemus (\\(Y_{i1}, Y_{i0}\\))\nTulemus, mis võiks realiseeruda isikule \\(i\\). \\(Y_{i1}\\) on tulemus (nt palk), kui isik osales meetmes (\\(D=1\\), osalusseisund); \\(Y_{i0}\\) on tulemus, kui isik ei osalenud meetmes (\\(D=0\\), võrdlusseisund). Me saame vaadelda vaid ühte neist.\n\n\nKeskmine mõju (ATE) (Average Treatment Effect)\nPoliitikameetme keskmine mõju kogu üldkogumile. See näitab, milline oleks programmi keskmine mõju, kui see tehtaks kohustuslikuks, või mis oleks oodatav mõju, kui võtaksime juhuslikult ühe inimese üldkogumist.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult osalesid. Tavaliselt erineb ATE-st, kuna mõju (\\(\\delta_i\\)) on inimeste jaoks erinev.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult ei osalenud.\n(See on hüpoteetiline mõju. Me leiame selle nende põhjal, kes tegelikult osalesid)\n\n\nOsalusrühm / Osalusgrupp (Treatment Group)\nObjektid (isikud, ettevõtted, piirkonnad), mis saavad meetme või mida mõjutab poliitikamuutus.\n\n\nVõrdlusrühm/\nKontrollgrupp (Control Group)\nÜhikud (isikud, ettevõtted, piirkonnad), mis ei saa meedet või mida ei mõjuta poliitikamuutus. Selle rühma püüame enamasti teha võimalikult sarnaseks osalusrühmaga.\n\n\nLihtne keskmiste erinevus (SDO) (Simple Difference of Outcomes)\nVaadeldud osalusgrupi ja võrdlusgrupi keskmiste tulemuste lihtne erinevus. See annab üldjuhul nihkega tulemuse: \\(\\text{SDO} = \\text{ATE} + \\text{Valikunihe} + \\text{Nihe heterogeense mõju tõttu}\\)\n\n\nValikunihe (Selection Bias)\nViga hinnangus, mis tekib, kuna osalenud (\\(D=1\\)) ja mitteosalenud (\\(D=0\\)) inimesed või ettevõtted erinevad üksteisest (nt võimekuse või motivatsiooni poolest). Valikunihke elimineerimine või selle vähendamine on mõju hindamisel üks peamine ülesanne.\n\n\nSUTVA eeldus (Stable Unit Treatment Value Assumption)\nEeldus, mis koosneb järgmistest tingimusest: meetmes osalemine on selgelt defineeritud (osaled või ei osale), üksikisiku osalemine ja tulemus sõltuvad ainult tema enda osalemise otsusest, mitte teiste omast (puuduvad välismõjud, general equilibrium effects).\nSeega on vaatlused sõltumatud ja meetmed peaks olema väikesed.\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nTuntud ka kui Unconfoundedness või Selection on Observables. Eeldus, et potentsiaalne tulemus (\\(Y\\)) ja meetmes osalemine (\\(D\\)) on sõltumatud pärast seda, kui oleme arvesse võtnud kõik olulised jälgitavad tunnused (X).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "href": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.2 Graafiline mõju modelleerimine (DAG)",
    "text": "2.2 Graafiline mõju modelleerimine (DAG)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSuunatud atsükliline graaf (DAG) (Directed Acyclic Graph)\nGraafiline vahend, mis kirjeldab muutujate vahelisi põhjuslikke seoseid. Noolteta jooned tähendavad, et seost ei ole. Põhjuslikkus on ühesuunaline ja ei sisalda tsükleid.\n\n\nSegaja (Confounder)\nMuutuja (nt \\(X\\)), mis on seotud nii meetmega (\\(D\\)) kui ka tulemusega (\\(Y\\)). (\\(D \\leftarrow X \\rightarrow Y\\)) Segaja kaudu kulgeb tagauks (backdoor path), mis tuleb sulgeda, et hinnang \\(D\\) mõju kohta \\(Y\\)-le oleks nihketa.\n\n\nTagauks (Backdoor Path)\nPõhjuslik tee meetme (\\(D\\)) ja tulemuse (\\(Y\\)) vahel, mis kulgeb läbi segaja(te). See teeb tuleb sulgeda, kas regressioonimudeli, sobitamise, eksperimendi või muu viisi abil. .\n\n\nOmitted Variable Bias (Nihe välja jäetud muutuja tõttu)\nNihkega hinnang, mis tekib, kui oluline segaja (\\(X\\)) jäetakse analüüsist välja.\n\n\nKollaider / Põrguti (Collider)\nMuutuja (nt \\(X\\)), mis on põhjustatud meetme (\\(D\\)) ja tulemuse (\\(Y\\)) poolt (\\(D \\rightarrow X \\leftarrow Y\\)). Kui kollaider pannakse mudelisse, luuakse uus (nihkega) seos (avatakse tagauks), mistõttu neid ei tohi mudelitesse lisada.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "href": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.3 Mõju hindamise meetodid",
    "text": "2.3 Mõju hindamise meetodid\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nHomogeenne efekt (Homogeneous Effect)\nRegressioonimudeli eeldus (kui ristkorrutised puuduvad), et põhjuslik mõju (\\(\\delta\\)) on kõigi jaoks ühesugune. Sellisel juhul \\(\\text{ATE} = \\text{ATT} = \\text{ATU}\\).\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus, et põhjuslik mõju erineb isikuti või alamrühmade kaupa. Seda saab modelleerida, lisades regressioonivõrrandisse ristkorrutised (nt \\(D_i \\cdot X_i\\))\n\n\nInstrument-muutuja (Instrumental Variable, Z)\nRegressioonianalüüsis kasutatav muutuja, mis on seotud meetmega (\\(D\\)), aga seos tulemusega (\\(Y\\)) tekib ainult \\(D\\) kaudu34. Aitab vähendada mittejälgitavate segajate (u) mõju.\n\n\nSobitamine (Matching)\nMeetod valikunihke vähendamiseks, kus osalenud isikutele leitakse sarnased mitteosalenud isikud (nt haridustaseme, vanuse vms \\(X\\) väärtuste alusel).\n\n\nPaneelandmete kasutamine\nMeetod, mis aitab elimineerida ajas muutumatute mittejälgitavate segajate (\\(u\\)) mõju (nt kaasasündinud võimekust).\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus loodus või institutsionaalne muutus (nt seaduse muutus) eraldab juhuslikult kaks rühma, andes uurijale peaaegu samaväärse tingimuse kui juhuslik eksperiment, vähendades mittejälgitava segaja (\\(u\\)) mõju\n\n\nÜhine tugi (Common Support)\nTingimus, mis peab olema täidetud CIA eelduse ja sobitamismeetodite korral. See tähendab, et antud \\(X\\) väärtuste juures peavad olema esindatud nii osalejad (\\(D=1\\)) kui ka mitteosalejad (\\(D=0\\)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "href": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.4 Juurdekasvude erinevus (DiD)",
    "text": "2.4 Juurdekasvude erinevus (DiD)\nDifference-in-differences method\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nJuurdekasvude erinevus (DiD)\nMeetod paneelandmete (või korduvate ristandmete) abil põhjusliku mõju hindamiseks. Eeldab, et meil on osalusgrupp (saab meetme) ja võrdlusgrupp (ei saa) ning andmed nii enne kui ka pärast meetme rakendamist.\n\n\nParalleelsete trendide eeldus (Parallel Trends Assumption)\nKõige olulisem eeldus DiD-meetodis. See nõuab, et kui osalusgrupp ei oleks meedet saanud, oleks nende tulemuse trend ajas olnud sama kui võrdlusgrupil.\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus DiD-meetodit sageli kasutatakse. Tekib, kui väline (eksogeenne) muutus, näiteks uus seadus, mõjutab ühte rühma, aga mitte teist.\n\n\nKolmekordne erinevus (Triple Difference)\nDiD-meetodi edasiarendus. Võrdleb DiD hinnangut (nt mõjutatud rühma ja kontrollrühma vahel) teise DiD hinnanguga (nt sarnase, kuid vähem mõjutatud rühma vahel). Kasutatakse potentsiaalsete väliste segajate eemaldamiseks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "href": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.5 Regressiooni katkemise disain",
    "text": "2.5 Regressiooni katkemise disain\n(Regression Discontinuity Design, RDD)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegressiooni katkemise disain (RDD)\nMõju hindamise meetod, mida kasutatakse, kui meetmes osalemine on määratud täpse lävendi (cut-off) alusel pideva muutuja (running variable) väärtusel. Näiteks vanus (lävend: 65 eluaastat pensionile jäämiseks).\n\n\nLõikepunkt / Lävend (Cut-off / Threshold)\nTäpne väärtus määravas muutujas (X), mis määrab, kas isik saab meetme (D=1) või mitte (D=0).\n\n\nMäärav muutuja (Running Variable / Assignment Variable)\nPidev muutuja (nt vanus, sissetulek, eksami tulemus), mille lävend määrab meetmes osalemise.\n\n\nLokaalne keskmine mõju (Local Average Treatment Effect, LATE)\nRDD-ga saadud hinnang näitab meetme põhjuslikku mõju ainult lävendi piiril olevatele isikutele, mitte kogu elanikkonnale.\n\n\nTäpne RDD (Sharp RDD)\nRDD vorm, kus lävendi ületamine määrab täielikult meetmes osalemise (st \\(P(D=1 \\vert X) = 1\\) lävendist paremal, ja \\(P(D=1 \\vert X) = 0\\) lävendist vasakul).\n\n\nHägune RDD (Fuzzy RDD)\nRDD vorm, kus lävendi ületamine muudab järsult tõenäosust meetmes osaleda, kuid ei määra seda täielikult (st \\(0 &lt; P(D=1 \\vert X) &lt; 1\\)).\n(Sarnane instrument-muutuja meetodile).\n\n\nPidevuse eeldus (Continuity Assumption)\nOluline eeldus RDD puhul. Nõuab, et potentsiaalsed tulemused (\\(Y_0, Y_1\\)) oleks pidevad lävendi juures. Tähendab, et lävendi lähedal ei tohi olla muid järske muutusi (nt manipuleerimist) peale meetme (\\(D\\)) osalemise muutuse.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sobitamine",
    "href": "pohimoistedkordamiseks.html#sobitamine",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.6 Sobitamine",
    "text": "2.6 Sobitamine\n(Matching)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSobitamine (Matching)\nMõju hindamise meetod, mille eesmärk on leida igale osalusrühmas olevale isikule (kes sai meetme) võimalikult sarnane isik võrdlusrühmast (kes meedet ei saanud).\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nSobitamise põhi-eeldus: \\(Y_0\\) ja \\(Y_1\\) on sõltumatud \\(D\\)-st tingimusel, et on arvesse võetud kõik jälgitavad segajad \\(X\\). See tähendab, et sobitamine tegeleb vaid valikunihkega, mis tuleb jälgitavatest tunnustest.\n\n\nÜhine tugi (Common Support)\nEeldus, mis peab kehtima: Iga osalusrühmas oleva isiku jälgitavate tunnuste \\(X\\) väärtuste (või tõenäosusskoori) läheduses peab olema piisavalt vaatlusi ka võrdlusrühmas.\n\n\nTõenäosuse skoor (PS) (Propensity Score, \\(P(X)\\))\nTõenäosus, et isik kuulub osalusrühma, arvestades tema jälgitavaid tunnuseid \\(X\\). See on tavaliselt logit- või probit regressioonimudeli abil hinnatud väärtus: \\(P(D_i = 1 \\mid X_i)\\).\n\n\nSobitamine tõenäosuse skoori alusel (PSM) (Propensity Score Matching)\nSagedasti kasutatud sobitamismeetod, mis kasutab mitme muutuja \\(X\\) asemel ühte mõõdikut: tõenäosuse skoori meetmes osaleda. Osalusrühma isikutele sobitatakse võrdlusrühma isikud, kelle \\(P(X)\\) väärtused on väga lähedal.\n\n\nLähima naabri sobitamine (Nearest Neighbor Matching)\nMeetod, kus igale osalusrühma vaatlusele leitakse kõige lähima kaugusega (nt \\(P(X)\\) alusel või Mahalanobise kauguse alusel) vaste võrdlusrühmast. Kasutada saab tagasipanekuga (või ilma).\n\n\nKaliiber (Caliper)\nMääratud maksimaalne lubatud kaugus (\\(P(X)\\) erinevus) paari sobitamisel. Aitab tagada kvaliteetsemad vasted, isegi kui see vähendab sobitatud isikute arvu.\n\n\nTasakaalu test (Balance Test)\nOluline samm sobitamise järel. Kontrollitakse, kas jälgitavate tunnuste \\(X\\) keskmised väärtused on sobitatud osalus- ja võrdlusrühmas piisavalt sarnased (statistiliselt oluliselt ei erine).\n\n\nOtste lõikamine (Trimming)\nSobitamise-eelne või -järgne tegevus, millega eemaldatakse analüüsist vaatlused, millel puudub ühine tugi (nt liiga väike või liiga suur \\(P(X)\\) väärtus).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "href": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.7 Instrumentmuutuja meetod (IV)",
    "text": "2.7 Instrumentmuutuja meetod (IV)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nInstrumentmuutuja (Z) (Instrumental Variable, IV)\nMuutuja, mida kasutatakse regressioonimudelis, et saada nihketa hinnang meetme (\\(D\\)) mõjule tulemusele (\\(Y\\)). Peab vastama kahele tingimusele (vt allpool).\n\n\nEndogeensus / Nihe (Endogeneity / Bias)\nProbleem, kus meetme muutuja (\\(D\\)) on korreleeritud regressioonimudeli vealiikmega (\\(u\\)). See tekib valikunihke või kahesuunalise põhjuslikkuse tõttu ning viib OLS-i puhul nihkega hinnanguni.\n\n\nIV Tingimus 1: Relevantsus (Relevance)\nEsimene ja testitav eeldus: instrumentmuutuja (\\(Z\\)) peab olema tugevalt korreleeritud meetme muutujaga (\\(D\\)). St, \\(Z\\) peab mõjutama \\(D\\)-d.\n\n\nIV Tingimus 2: Väline kehtivus / Eksogeensus (Exclusion Restriction / Exogeneity)\nTeine ja mittetestitav eeldus: Instrumentmuutuja (\\(Z\\)) tohib mõjutada tulemust (\\(Y\\)) ainult meetme muutuja (\\(D\\)) kaudu. St, \\(Z\\) ei tohi olla korreleeritud vealiikmega (\\(u\\)).\n\n\nKaheetapiline vähimruutude meetod (2SLS) (Two-Stage Least Squares)\nIV-meetodi rakendamise viis. 1. etapp: regresseeritakse \\(D\\) \\(Z\\)-i ja \\(X\\)-ide suhtes. 2. etapp: regresseeritakse \\(Y\\) \\(D\\) ennustatud väärtuse ja \\(X\\)-ide suhtes.\n\n\nLokaalne keskmine mõju (LATE) (Local Average Treatment Effect)\nIV-meetodi puhul saadud põhjuslik mõju hinnang. See mõju kehtib vaid allujatele (compliers) – neile, kelle osalemisotsus (\\(D\\)) oli mõjutatud instrumentmuutujast (\\(Z\\)).\nKui eeldame, et mõju on kõigi jaoks ühesugune (homogeenne), siis rühmade eristus ei ole vajalik.\n\n\nNõrk instrument (Weak Instrument)\nOlukord, kus instrumentmuutuja (\\(Z\\)) ei ole piisavalt tugevalt seotud meetme muutujaga (\\(D\\)). Viib nihkega (OLS-i poole kaldu) ja ebatäpsete IV-hinnanguteni.\n\n\nHausman-Wu test (Hausman-Wu Test)\nTest, millega kontrollitakse endogeensuse olemasolu meetme muutuja (\\(D\\)) ja vealiikme (\\(u\\)) vahel. Kui test on oluline, näitab see, et \\(D\\) on endogeenne ja IV-meetodi kasutamine on vajalik.\n\n\nSargani test (Sargan Test)\nTest, millega kontrollitakse eksogeensuse eelduse paikapidavust (Exclusion Restriction), kui meil on rohkem instrumente kui endogeenseid muutujaid (üleidentifitseeritud juht).\n\n\nWaldi hinnang binaarse meetme ja binaarse instrumendi korral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "href": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.8 Sünteetilise võrdlusobjekti meetod",
    "text": "2.8 Sünteetilise võrdlusobjekti meetod\n(Synthetic Control Method)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSünteetiline Võrdlusobjekt (SCM) (Synthetic Control Method), sünteetilise kontrollgrupi meetod\nMeetod, mida kasutatakse ühe meetmes osaleja puhul (nt ühe riigi) mõju hindamiseks, luues teistest, mitteosalevatest objektidest (doonorrühmast) kaalutud kombinatsioon.\n\n\nSihtobjekt (Treated Unit)\nAinus uuritav ühik (nt linn, riik), mis on saanud sekkumise (meetme). SCM eesmärk on leida sellele veenev võrdlusobjekt.\n\n\nDoonorrühm, võrdlusobjektid (Donor Pool / Control Units)\nMeetmest mitte mõjutatud ühikute kogum, mille kaalutud keskmisest tehakse sünteetiline võrdlusobjekt. Nende kaalude summa peab olema 1 ja kaalud ei tohi olla negatiivsed.\n\n\nKaalud (\\(\\mathbf{W}\\)) (Weights)\nPositiivsed väärtused, mis määratakse võrdlusrobjektidele. Need kaalud minimeerivad sihtobjekti ja sünteetilise võrdlusobjekti erinevust meetmele eelneval perioodil.\n\n\nSobitamisperiood / Eelperiood (Pre-intervention Period)\nAjavahemik enne meedet, mida kasutatakse kaalude \\(\\mathbf{W}\\) leidmiseks. Kaalud valitakse nii, et sihtobjekti ja sünteetilise võrdlusobjekti tulemused \\(\\mathbf{Y_t}\\) ja ka selgitavad tunnused \\(\\mathbf{X_{mt}}\\) oleksid selles perioodis võimalikult lähedased.\n\n\nMõju hinnang (Treatment Effect Estimate)\nSCM-iga saadud põhjuslik mõju, mis leitakse sihtobjekti ja sünteetilise võrdlusobjekti tulemuste vahe alusel pärast meetme rakendamist.\n\n\nPlatseebotest / Permutatsioonitest (Placebo Test / Permutation Test)\nEelduste ja järelduste statistiline testimismeetod SCM-is. Leitakse sama arvutuse tulemus ka teistele võrdlusrühma liikmetele ja hinnatakse, kas meid huvitava objekti tulemus on ebatavaliselt suur võrreldes teistega. Kui meie tulemus on eriline, siis see viitab, et tegemist on tegeliku mõjuga.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "href": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.9 Masinõppemeetodid - puud ja mets",
    "text": "2.9 Masinõppemeetodid - puud ja mets\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nOtsustuspuu (Decision Tree), Regressioonipuu (Regression Tree)\nMasinõppe algoritm, mis jaotab andmestiku rekursiivselt alamhulkadeks, et leida ennustusreegleid tulemuse (\\(Y\\)) või meetmes osalemise (\\(D\\)) kohta. Moodustab aluse juhumetsale.\n\n\nJuhumets (Random Forest)\nAnsambelmeetod, mis kombineerib mitu puud. Iga puu on ehitatud juhusliku valimiga (bootstrapping) ja kasutades juhuslikku alamhulka tunnustest igas harus. Kasutatakse peamiselt täpseks prognoosimiseks (\\(E[Y\\vert X]\\) või \\(P[D\\vert X]\\)).\n\n\nPõhjuslik mets / Kausaalmets\n(Causal Forest)\nJuhumetsa edasiarendus, mis on loodud spetsiaalselt heterogeense põhjusliku mõju (CATE) hindamiseks. Eraldab andmed kaheks: üks osa puude ehitamiseks ja teine osa mõju hindamiseks, et vältida üle-sobitamist (overfitting).\nKui tavaline puu maksimeerib prognooside erinevust igas lehes, siis kausaalpuu maksimeerib mõju erinevust igas lehes.\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus või tulemus, et põhjuslik mõju (\\(\\delta\\)) on erinevatel inimestel (alamrühmadel) erinev (st sõltub \\(X\\) väärtustest). Masinõppemeetodid on selle tuvastamisel eriti võimsad.\n\n\nKõrge-dimensiooniline andmestik (High-Dimensional Data)\nAndmestik, kus on väga palju jälgitavaid tunnuseid (\\(X\\)), mida peab arvesse võtma valikunihke korrigeerimiseks. Masinõpe aitab neist olulised leida.\n\n\nDouble Machine Learning (DML)\nÜks juhtivaid lähenemisi põhjusliku mõju hindamiseks masinõppe abil. Kasutab kaheetapilist meetodit (nagu 2SLS või AIPW), kus mõlemad etapid viiakse läbi (regressiooni vealiikmed leitakse) paindlike masinõppe meetodite (nt juhumets) abil.\n\n\nIPW (Inverse Probability Weighting)\nMeetod, kus mõju arvutamisel vaatlusi kaalutakse pöördvõrdeliselt nende tõenäosuse skooriga (\\(P(D=1 \\mid X)\\)). See annab osalejatele, kelle \\(P(X)\\) on väike, suurema kaalu, ja mitte-osalejatele, kelle \\(P(X)\\) on suur, suurema kaalu.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "href": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.10 LASSO mõju hindamisel",
    "text": "2.10 LASSO mõju hindamisel\n\n\n\n\n\n\n\nRegulariseerimine (Regularized Regression)\nÜldnimetus meetoditele (nagu LASSO ja Ridge), mis lisavad regressioonimudeli eesmärgile (RSS minimeerimine) karistusliikme koefitsientide suuruse eest. See aitab vähendada üle-sobitamist (overfitting) ja teeb mudelid lihtsamaks.\n\n\nLASSO (Least Absolute Shrinkage and Selection Operator)\nRegulariseeriv regressioonimeetod, mis karistab suurte koefitsientide eest, lisades jääkliikmete ruutude summale (RSS) koefitsientide absoluutväärtuste summa (L1-norm). See sunnib paljusid väheolulisi tunnuseid \\(X\\) olema täpselt null – teeb automaatse tunnuste valiku.\n\n\nTunnuste valik (Feature Selection)\nLASSO peamine kasulik omadus ökonomeetrias. See suudab automaatselt tuhandete võimalike tunnuste (\\(X\\)) hulgast leida need, mis on põhjusliku mõju nihketa hindamiseks kõige olulisemad.\n\n\nRegulatsiooniparameeter (\\(\\lambda\\)) (Regularization Parameter, \\(\\lambda\\))\nParameeter LASSO ja Ridge mudelites, mis määrab karistuse tugevuse. Mida suurem \\(\\lambda\\), seda rohkem koefitsiente sunnitakse nulliks (LASSO puhul) ja seda suurem on koefitsientide kokkutõmbumine (mõlema puhul). \\(\\lambda\\) valitakse tavaliselt ristvalideerimise abil.\n\n\nRistvalideerimine (Cross-Validation)\nStatistiline tehnika \\(\\lambda\\) (regulatsiooniparameetri) optimaalse väärtuse leidmiseks. Andmestik jagatakse alamhulkadeks. \\(\\lambda\\) valitakse nii, et see minimeeriks prognoosivea (nt mean squared error) valimi-välisel andmestiku osal. See sobib hästi, kui eesmärk on prognoosimine\n\n\nTeoreetiline \\(\\lambda\\) valik (`rlasso` meetod)\nPakett `rlasso` (Belloni jt.) kasutab teoorial põhinevat, andmepõhist regulatsiooniparameetri \\(\\lambda\\) valikut\n\n\nPost-LASSO\nMeetod, kus kõigepealt kasutatakse LASSO-t, et valida välja olulised tunnused (koefitsiendiga \\(\\neq 0\\)). Seejärel hintakse seos tavalise OLSiga (vähimruutude) regressiooni, kasutades ainult valitud tunnuseid.\n\n\nDouble Selection LASSO (DS-LASSO)\nMeetod, mille eesmärk on leida kõik olulised segajad (\\(X\\)), mis võivad mõjutada nihet (\\(D \\leftrightarrow Y\\) seose puhul). Viib läbi kaks LASSO-valikut: 1) \\(Y\\) seos \\(X\\)-idega 2) \\(D\\) seos \\(X\\)-idega. Mudelisse jäetakse kõik tunnused, mis valiti kas 1. või 2. etapis. Saadud mudel hinnatakse post-LASSO meetodiga.\n\n\nResidualisation (Jääkliikmete meetod)\nAlternatiivne lähenemine, mida kasutatakse LASSO-ga. See toimub kahes etapis: 1) \\(Y \\sim X\\) abil ja leitakse jääkliikmed \\(r_Y\\). 2) Modelleeritakse \\(D \\sim X\\) abil ja leitakse jääkliikmed \\(r_D\\). Lõpuks hinnatakse mõju regressiooniga: \\(r_Y \\sim r_D\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  }
]