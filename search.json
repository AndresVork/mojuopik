[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Põhjuslike seoste hindamine majanduses",
    "section": "",
    "text": "Eessõna\nKäesolev lühikonspekt on mõeldud tutvustamaks mõju hindamise meetodeid majandustudengitele. Konspektis kasutatakse tarkvara R.\nKonspekt on jooksvalt täienev. Siia hakkan panema aines “Põhuse ja tagajärje seosed” kasutatud õppematerjale.\nMe kasutame näidisandmetena järgmisi andmefaile:\n\nPoliitikauuringute Keskuse Praxis 2002. aastal läbiviidud uuringu anonüümset andmefaili aktiivse tööpoliitika mõju hindamise kohta. (Vt Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 2003, 108 lk.)\nPIAAC uuringu avalikud andmefailid\nEesti Töötukassa anonümiseeritud näitefailid",
    "crumbs": [
      "Eessõna"
    ]
  },
  {
    "objectID": "01-sissejuhatus.html",
    "href": "01-sissejuhatus.html",
    "title": "1  Sissejuhatus",
    "section": "",
    "text": "Raamat on järgmise struktuuriga.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sissejuhatus</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html",
    "href": "pohimoistedkordamiseks.html",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "2.1 Potentsiaalse tulemuse mudel (POM)\nTudengid peaksid teadma järgmisi põhimõisteid.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "href": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "Mõiste\nSelgitus\n\n\nPõhjuslik mõju (Causal Effect)\nMõju on defineeritud kui kahe oleku (sekkumine \\(D=1\\) ja võrdlusseisund \\(D=0\\)) tulemuse võrdlus. See on see, mida püütakse hinnata.\n\n\nPotentsiaalne tulemus (\\(Y_{i1}, Y_{i0}\\))\nTulemus, mis võiks realiseeruda isikule \\(i\\). \\(Y_{i1}\\) on tulemus (nt palk), kui isik osales meetmes (\\(D=1\\), osalusseisund); \\(Y_{i0}\\) on tulemus, kui isik ei osalenud meetmes (\\(D=0\\), võrdlusseisund). Me saame vaadelda vaid ühte neist.\n\n\nKeskmine mõju (ATE) (Average Treatment Effect)\nPoliitikameetme keskmine mõju kogu üldkogumile. See näitab, milline oleks programmi keskmine mõju, kui see tehtaks kohustuslikuks, või mis oleks oodatav mõju, kui võtaksime juhuslikult ühe inimese üldkogumist.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult osalesid. Tavaliselt erineb ATE-st, kuna mõju (\\(\\delta_i\\)) on inimeste jaoks erinev.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult ei osalenud.\n(See on hüpoteetiline mõju. Me leiame selle nende põhjal, kes tegelikult osalesid)\n\n\nOsalusrühm / Osalusgrupp (Treatment Group)\nObjektid (isikud, ettevõtted, piirkonnad), mis saavad meetme või mida mõjutab poliitikamuutus.\n\n\nVõrdlusrühm/\nKontrollgrupp (Control Group)\nÜhikud (isikud, ettevõtted, piirkonnad), mis ei saa meedet või mida ei mõjuta poliitikamuutus. Selle rühma püüame enamasti teha võimalikult sarnaseks osalusrühmaga.\n\n\nLihtne keskmiste erinevus (SDO) (Simple Difference of Outcomes)\nVaadeldud osalusgrupi ja võrdlusgrupi keskmiste tulemuste lihtne erinevus. See annab üldjuhul nihkega tulemuse: \\(\\text{SDO} = \\text{ATE} + \\text{Valikunihe} + \\text{Nihe heterogeense mõju tõttu}\\)\n\n\nValikunihe (Selection Bias)\nViga hinnangus, mis tekib, kuna osalenud (\\(D=1\\)) ja mitteosalenud (\\(D=0\\)) inimesed või ettevõtted erinevad üksteisest (nt võimekuse või motivatsiooni poolest). Valikunihke elimineerimine või selle vähendamine on mõju hindamisel üks peamine ülesanne.\n\n\nSUTVA eeldus (Stable Unit Treatment Value Assumption)\nEeldus, mis koosneb järgmistest tingimusest: meetmes osalemine on selgelt defineeritud (osaled või ei osale), üksikisiku osalemine ja tulemus sõltuvad ainult tema enda osalemise otsusest, mitte teiste omast (puuduvad välismõjud, general equilibrium effects).\nSeega on vaatlused sõltumatud ja meetmed peaks olema väikesed.\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nTuntud ka kui Unconfoundedness või Selection on Observables. Eeldus, et potentsiaalne tulemus (\\(Y\\)) ja meetmes osalemine (\\(D\\)) on sõltumatud pärast seda, kui oleme arvesse võtnud kõik olulised jälgitavad tunnused (X).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "href": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.2 Graafiline mõju modelleerimine (DAG)",
    "text": "2.2 Graafiline mõju modelleerimine (DAG)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSuunatud atsükliline graaf (DAG) (Directed Acyclic Graph)\nGraafiline vahend, mis kirjeldab muutujate vahelisi põhjuslikke seoseid. Noolteta jooned tähendavad, et seost ei ole. Põhjuslikkus on ühesuunaline ja ei sisalda tsükleid.\n\n\nSegaja (Confounder)\nMuutuja (nt \\(X\\)), mis on seotud nii meetmega (\\(D\\)) kui ka tulemusega (\\(Y\\)). (\\(D \\leftarrow X \\rightarrow Y\\)) Segaja kaudu kulgeb tagauks (backdoor path), mis tuleb sulgeda, et hinnang \\(D\\) mõju kohta \\(Y\\)-le oleks nihketa.\n\n\nTagauks (Backdoor Path)\nPõhjuslik tee meetme (\\(D\\)) ja tulemuse (\\(Y\\)) vahel, mis kulgeb läbi segaja(te). See teeb tuleb sulgeda, kas regressioonimudeli, sobitamise, eksperimendi või muu viisi abil. .\n\n\nOmitted Variable Bias (Nihe välja jäetud muutuja tõttu)\nNihkega hinnang, mis tekib, kui oluline segaja (\\(X\\)) jäetakse analüüsist välja.\n\n\nKollaider / Põrguti (Collider)\nMuutuja (nt \\(X\\)), mis on põhjustatud meetme (\\(D\\)) ja tulemuse (\\(Y\\)) poolt (\\(D \\rightarrow X \\leftarrow Y\\)). Kui kollaider pannakse mudelisse, luuakse uus (nihkega) seos (avatakse tagauks), mistõttu neid ei tohi mudelitesse lisada.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "href": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.3 Mõju hindamise meetodid",
    "text": "2.3 Mõju hindamise meetodid\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nHomogeenne efekt (Homogeneous Effect)\nRegressioonimudeli eeldus (kui ristkorrutised puuduvad), et põhjuslik mõju (\\(\\delta\\)) on kõigi jaoks ühesugune. Sellisel juhul \\(\\text{ATE} = \\text{ATT} = \\text{ATU}\\).\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus, et põhjuslik mõju erineb isikuti või alamrühmade kaupa. Seda saab modelleerida, lisades regressioonivõrrandisse ristkorrutised (nt \\(D_i \\cdot X_i\\))\n\n\nInstrument-muutuja (Instrumental Variable, Z)\nRegressioonianalüüsis kasutatav muutuja, mis on seotud meetmega (\\(D\\)), aga seos tulemusega (\\(Y\\)) tekib ainult \\(D\\) kaudu34. Aitab vähendada mittejälgitavate segajate (u) mõju.\n\n\nSobitamine (Matching)\nMeetod valikunihke vähendamiseks, kus osalenud isikutele leitakse sarnased mitteosalenud isikud (nt haridustaseme, vanuse vms \\(X\\) väärtuste alusel).\n\n\nPaneelandmete kasutamine\nMeetod, mis aitab elimineerida ajas muutumatute mittejälgitavate segajate (\\(u\\)) mõju (nt kaasasündinud võimekust).\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus loodus või institutsionaalne muutus (nt seaduse muutus) eraldab juhuslikult kaks rühma, andes uurijale peaaegu samaväärse tingimuse kui juhuslik eksperiment, vähendades mittejälgitava segaja (\\(u\\)) mõju\n\n\nÜhine tugi (Common Support)\nTingimus, mis peab olema täidetud CIA eelduse ja sobitamismeetodite korral. See tähendab, et antud \\(X\\) väärtuste juures peavad olema esindatud nii osalejad (\\(D=1\\)) kui ka mitteosalejad (\\(D=0\\)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "href": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.4 Juurdekasvude erinevus (DiD)",
    "text": "2.4 Juurdekasvude erinevus (DiD)\nDifference-in-differences method\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nJuurdekasvude erinevus (DiD)\nMeetod paneelandmete (või korduvate ristandmete) abil põhjusliku mõju hindamiseks. Eeldab, et meil on osalusgrupp (saab meetme) ja võrdlusgrupp (ei saa) ning andmed nii enne kui ka pärast meetme rakendamist.\n\n\nParalleelsete trendide eeldus (Parallel Trends Assumption)\nKõige olulisem eeldus DiD-meetodis. See nõuab, et kui osalusgrupp ei oleks meedet saanud, oleks nende tulemuse trend ajas olnud sama kui võrdlusgrupil.\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus DiD-meetodit sageli kasutatakse. Tekib, kui väline (eksogeenne) muutus, näiteks uus seadus, mõjutab ühte rühma, aga mitte teist.\n\n\nKolmekordne erinevus (Triple Difference)\nDiD-meetodi edasiarendus. Võrdleb DiD hinnangut (nt mõjutatud rühma ja kontrollrühma vahel) teise DiD hinnanguga (nt sarnase, kuid vähem mõjutatud rühma vahel). Kasutatakse potentsiaalsete väliste segajate eemaldamiseks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "href": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.5 Regressiooni katkemise disain",
    "text": "2.5 Regressiooni katkemise disain\n(Regression Discontinuity Design, RDD)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegressiooni katkemise disain (RDD)\nMõju hindamise meetod, mida kasutatakse, kui meetmes osalemine on määratud täpse lävendi (cut-off) alusel pideva muutuja (running variable) väärtusel. Näiteks vanus (lävend: 65 eluaastat pensionile jäämiseks).\n\n\nLõikepunkt / Lävend (Cut-off / Threshold)\nTäpne väärtus määravas muutujas (X), mis määrab, kas isik saab meetme (D=1) või mitte (D=0).\n\n\nMäärav muutuja (Running Variable / Assignment Variable)\nPidev muutuja (nt vanus, sissetulek, eksami tulemus), mille lävend määrab meetmes osalemise.\n\n\nLokaalne keskmine mõju (Local Average Treatment Effect, LATE)\nRDD-ga saadud hinnang näitab meetme põhjuslikku mõju ainult lävendi piiril olevatele isikutele, mitte kogu elanikkonnale.\n\n\nTäpne RDD (Sharp RDD)\nRDD vorm, kus lävendi ületamine määrab täielikult meetmes osalemise (st \\(P(D=1 \\vert X) = 1\\) lävendist paremal, ja \\(P(D=1 \\vert X) = 0\\) lävendist vasakul).\n\n\nHägune RDD (Fuzzy RDD)\nRDD vorm, kus lävendi ületamine muudab järsult tõenäosust meetmes osaleda, kuid ei määra seda täielikult (st \\(0 &lt; P(D=1 \\vert X) &lt; 1\\)).\n(Sarnane instrument-muutuja meetodile).\n\n\nPidevuse eeldus (Continuity Assumption)\nOluline eeldus RDD puhul. Nõuab, et potentsiaalsed tulemused (\\(Y_0, Y_1\\)) oleks pidevad lävendi juures. Tähendab, et lävendi lähedal ei tohi olla muid järske muutusi (nt manipuleerimist) peale meetme (\\(D\\)) osalemise muutuse.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sobitamine",
    "href": "pohimoistedkordamiseks.html#sobitamine",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.6 Sobitamine",
    "text": "2.6 Sobitamine\n(Matching)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSobitamine (Matching)\nMõju hindamise meetod, mille eesmärk on leida igale osalusrühmas olevale isikule (kes sai meetme) võimalikult sarnane isik võrdlusrühmast (kes meedet ei saanud).\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nSobitamise põhi-eeldus: \\(Y_0\\) ja \\(Y_1\\) on sõltumatud \\(D\\)-st tingimusel, et on arvesse võetud kõik jälgitavad segajad \\(X\\). See tähendab, et sobitamine tegeleb vaid valikunihkega, mis tuleb jälgitavatest tunnustest.\n\n\nÜhine tugi (Common Support)\nEeldus, mis peab kehtima: Iga osalusrühmas oleva isiku jälgitavate tunnuste \\(X\\) väärtuste (või tõenäosusskoori) läheduses peab olema piisavalt vaatlusi ka võrdlusrühmas.\n\n\nTõenäosuse skoor (PS) (Propensity Score, \\(P(X)\\))\nTõenäosus, et isik kuulub osalusrühma, arvestades tema jälgitavaid tunnuseid \\(X\\). See on tavaliselt logit- või probit regressioonimudeli abil hinnatud väärtus: \\(P(D_i = 1 \\mid X_i)\\).\n\n\nSobitamine tõenäosuse skoori alusel (PSM) (Propensity Score Matching)\nSagedasti kasutatud sobitamismeetod, mis kasutab mitme muutuja \\(X\\) asemel ühte mõõdikut: tõenäosuse skoori meetmes osaleda. Osalusrühma isikutele sobitatakse võrdlusrühma isikud, kelle \\(P(X)\\) väärtused on väga lähedal.\n\n\nLähima naabri sobitamine (Nearest Neighbor Matching)\nMeetod, kus igale osalusrühma vaatlusele leitakse kõige lähima kaugusega (nt \\(P(X)\\) alusel või Mahalanobise kauguse alusel) vaste võrdlusrühmast. Kasutada saab tagasipanekuga (või ilma).\n\n\nKaliiber (Caliper)\nMääratud maksimaalne lubatud kaugus (\\(P(X)\\) erinevus) paari sobitamisel. Aitab tagada kvaliteetsemad vasted, isegi kui see vähendab sobitatud isikute arvu.\n\n\nTasakaalu test (Balance Test)\nOluline samm sobitamise järel. Kontrollitakse, kas jälgitavate tunnuste \\(X\\) keskmised väärtused on sobitatud osalus- ja võrdlusrühmas piisavalt sarnased (statistiliselt oluliselt ei erine).\n\n\nOtste lõikamine (Trimming)\nSobitamise-eelne või -järgne tegevus, millega eemaldatakse analüüsist vaatlused, millel puudub ühine tugi (nt liiga väike või liiga suur \\(P(X)\\) väärtus).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "href": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.7 Instrumentmuutuja meetod (IV)",
    "text": "2.7 Instrumentmuutuja meetod (IV)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nInstrumentmuutuja (Z) (Instrumental Variable, IV)\nMuutuja, mida kasutatakse regressioonimudelis, et saada nihketa hinnang meetme (\\(D\\)) mõjule tulemusele (\\(Y\\)). Peab vastama kahele tingimusele (vt allpool).\n\n\nEndogeensus / Nihe (Endogeneity / Bias)\nProbleem, kus meetme muutuja (\\(D\\)) on korreleeritud regressioonimudeli vealiikmega (\\(u\\)). See tekib valikunihke või kahesuunalise põhjuslikkuse tõttu ning viib OLS-i puhul nihkega hinnanguni.\n\n\nIV Tingimus 1: Relevantsus (Relevance)\nEsimene ja testitav eeldus: instrumentmuutuja (\\(Z\\)) peab olema tugevalt korreleeritud meetme muutujaga (\\(D\\)). St, \\(Z\\) peab mõjutama \\(D\\)-d.\n\n\nIV Tingimus 2: Väline kehtivus / Eksogeensus (Exclusion Restriction / Exogeneity)\nTeine ja mittetestitav eeldus: Instrumentmuutuja (\\(Z\\)) tohib mõjutada tulemust (\\(Y\\)) ainult meetme muutuja (\\(D\\)) kaudu. St, \\(Z\\) ei tohi olla korreleeritud vealiikmega (\\(u\\)).\n\n\nKaheetapiline vähimruutude meetod (2SLS) (Two-Stage Least Squares)\nIV-meetodi rakendamise viis. 1. etapp: regresseeritakse \\(D\\) \\(Z\\)-i ja \\(X\\)-ide suhtes. 2. etapp: regresseeritakse \\(Y\\) \\(D\\) ennustatud väärtuse ja \\(X\\)-ide suhtes.\n\n\nLokaalne keskmine mõju (LATE) (Local Average Treatment Effect)\nIV-meetodi puhul saadud põhjuslik mõju hinnang. See mõju kehtib vaid allujatele (compliers) – neile, kelle osalemisotsus (\\(D\\)) oli mõjutatud instrumentmuutujast (\\(Z\\)).\nKui eeldame, et mõju on kõigi jaoks ühesugune (homogeenne), siis rühmade eristus ei ole vajalik.\n\n\nNõrk instrument (Weak Instrument)\nOlukord, kus instrumentmuutuja (\\(Z\\)) ei ole piisavalt tugevalt seotud meetme muutujaga (\\(D\\)). Viib nihkega (OLS-i poole kaldu) ja ebatäpsete IV-hinnanguteni.\n\n\nHausman-Wu test (Hausman-Wu Test)\nTest, millega kontrollitakse endogeensuse olemasolu meetme muutuja (\\(D\\)) ja vealiikme (\\(u\\)) vahel. Kui test on oluline, näitab see, et \\(D\\) on endogeenne ja IV-meetodi kasutamine on vajalik.\n\n\nSargani test (Sargan Test)\nTest, millega kontrollitakse eksogeensuse eelduse paikapidavust (Exclusion Restriction), kui meil on rohkem instrumente kui endogeenseid muutujaid (üleidentifitseeritud juht).\n\n\nWaldi hinnang binaarse meetme ja binaarse instrumendi korral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "href": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.8 Sünteetilise võrdlusobjekti meetod",
    "text": "2.8 Sünteetilise võrdlusobjekti meetod\n(Synthetic Control Method)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSünteetiline Võrdlusobjekt (SCM) (Synthetic Control Method), sünteetilise kontrollgrupi meetod\nMeetod, mida kasutatakse ühe meetmes osaleja puhul (nt ühe riigi) mõju hindamiseks, luues teistest, mitteosalevatest objektidest (doonorrühmast) kaalutud kombinatsioon.\n\n\nSihtobjekt (Treated Unit)\nAinus uuritav ühik (nt linn, riik), mis on saanud sekkumise (meetme). SCM eesmärk on leida sellele veenev võrdlusobjekt.\n\n\nDoonorrühm, võrdlusobjektid (Donor Pool / Control Units)\nMeetmest mitte mõjutatud ühikute kogum, mille kaalutud keskmisest tehakse sünteetiline võrdlusobjekt. Nende kaalude summa peab olema 1 ja kaalud ei tohi olla negatiivsed.\n\n\nKaalud (\\(\\mathbf{W}\\)) (Weights)\nPositiivsed väärtused, mis määratakse võrdlusrobjektidele. Need kaalud minimeerivad sihtobjekti ja sünteetilise võrdlusobjekti erinevust meetmele eelneval perioodil.\n\n\nSobitamisperiood / Eelperiood (Pre-intervention Period)\nAjavahemik enne meedet, mida kasutatakse kaalude \\(\\mathbf{W}\\) leidmiseks. Kaalud valitakse nii, et sihtobjekti ja sünteetilise võrdlusobjekti tulemused \\(\\mathbf{Y_t}\\) ja ka selgitavad tunnused \\(\\mathbf{X_{mt}}\\) oleksid selles perioodis võimalikult lähedased.\n\n\nMõju hinnang (Treatment Effect Estimate)\nSCM-iga saadud põhjuslik mõju, mis leitakse sihtobjekti ja sünteetilise võrdlusobjekti tulemuste vahe alusel pärast meetme rakendamist.\n\n\nPlatseebotest / Permutatsioonitest (Placebo Test / Permutation Test)\nEelduste ja järelduste statistiline testimismeetod SCM-is. Leitakse sama arvutuse tulemus ka teistele võrdlusrühma liikmetele ja hinnatakse, kas meid huvitava objekti tulemus on ebatavaliselt suur võrreldes teistega. Kui meie tulemus on eriline, siis see viitab, et tegemist on tegeliku mõjuga.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "href": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.9 Masinõppemeetodid - puud ja mets",
    "text": "2.9 Masinõppemeetodid - puud ja mets\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nOtsustuspuu (Decision Tree), Regressioonipuu (Regression Tree)\nMasinõppe algoritm, mis jaotab andmestiku samm-sammuliselt alamhulkadeks, et leida prognoosimise reeglid tulemuse (\\(Y\\)) või meetmes osalemise (\\(D\\)) kohta. Moodustab aluse juhumetsale.\nOtsustuspuu - väljund on diskreetne (nt kas töötab või osaleb meetmes)\nRegressioonipuu - väljund on pidev (nt palk)\n\n\nJuhumets (Random Forest)\nAnsambelmeetod, mis kombineerib mitu puud. Iga puu on ehitatud juhusliku valimiga (bootstrapping) ja kasutades juhuslikku alamhulka tunnustest igas harus. Kasutatakse peamiselt täpseks prognoosimiseks (\\(E[Y\\vert X]\\) või \\(P[D\\vert X]\\)).\n\n\nPõhjuslik mets / Kausaalmets\n(Causal Forest)\nJuhumetsa edasiarendus, mis on loodud spetsiaalselt heterogeense põhjusliku mõju (CATE) hindamiseks. Eraldab andmed kaheks: üks osa puude ehitamiseks ja teine osa mõju hindamiseks, et vältida üle-sobitamist (overfitting).\nKui tavaline puu maksimeerib prognooside erinevust igas lehes, siis kausaalpuu maksimeerib mõju erinevust igas lehes.\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus või tulemus, et põhjuslik mõju (\\(\\delta\\)) on erinevatel inimestel (alamrühmadel) erinev (st sõltub \\(X\\) väärtustest). Masinõppemeetodid on selle tuvastamisel eriti võimsad.\n\n\nKõrge-dimensiooniline andmestik (High-Dimensional Data)\nAndmestik, kus on väga palju jälgitavaid tunnuseid (\\(X\\)), mida peab arvesse võtma valikunihke korrigeerimiseks. Masinõpe aitab neist olulised leida.\n\n\nDouble Machine Learning (DML)\nÜks juhtivaid lähenemisi põhjusliku mõju hindamiseks masinõppe abil. Kasutab kaheetapilist meetodit (nagu 2SLS või AIPW), kus mõlemad etapid viiakse läbi (regressiooni vealiikmed leitakse) paindlike masinõppe meetodite (nt juhumets) abil.\n\n\nIPW (Inverse Probability Weighting)\nMeetod, kus mõju arvutamisel vaatlusi kaalutakse pöördvõrdeliselt nende tõenäosuse skooriga (\\(P(D=1 \\mid X)\\)). See annab osalejatele, kelle \\(P(X)\\) on väike, suurema kaalu, ja mitte-osalejatele, kelle \\(P(X)\\) on suur, suurema kaalu.\n\n\nAIPW (augmented inverse probability weighting)\nMeetod kus mõjuhinnangut korrigeeritakse tõenäosuskooridega korrigeeritud",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "href": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.10 LASSO mõju hindamisel",
    "text": "2.10 LASSO mõju hindamisel\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegulariseerimine (Regularized Regression)\nÜldnimetus meetoditele (nagu LASSO ja Ridge), mis lisavad regressioonimudeli eesmärgile (RSS minimeerimine) karistusliikme koefitsientide suuruse eest. See aitab vähendada üle-sobitamist (overfitting) ja teeb mudelid lihtsamaks.\n\n\nLASSO (Least Absolute Shrinkage and Selection Operator)\nRegulariseeriv regressioonimeetod, mis karistab suurte koefitsientide eest, lisades jääkliikmete ruutude summale (RSS) koefitsientide absoluutväärtuste summa (L1-norm). See sunnib paljusid väheolulisi tunnuseid \\(X\\) olema täpselt null – teeb automaatse tunnuste valiku.\n\n\nTunnuste valik (Feature Selection)\nLASSO peamine kasulik omadus ökonomeetrias. See suudab automaatselt tuhandete võimalike tunnuste (\\(X\\)) hulgast leida need, mis on põhjusliku mõju nihketa hindamiseks kõige olulisemad.\n\n\nRegulatsiooniparameeter (\\(\\lambda\\)) (Regularization Parameter, \\(\\lambda\\))\nParameeter LASSO ja Ridge mudelites, mis määrab karistuse tugevuse. Mida suurem \\(\\lambda\\), seda rohkem koefitsiente sunnitakse nulliks (LASSO puhul) ja seda suurem on koefitsientide kokkutõmbumine (mõlema puhul). \\(\\lambda\\) valitakse tavaliselt ristvalideerimise abil.\n\n\nRistvalideerimine (Cross-Validation)\nStatistiline tehnika \\(\\lambda\\) (regulatsiooniparameetri) optimaalse väärtuse leidmiseks. Andmestik jagatakse alamhulkadeks. \\(\\lambda\\) valitakse nii, et see minimeeriks prognoosivea (nt mean squared error) valimi-välisel andmestiku osal. See sobib hästi, kui eesmärk on prognoosimine\n\n\nTeoreetiline \\(\\lambda\\) valik (`rlasso` meetod)\nPakett `rlasso` (Belloni jt.) kasutab teoorial põhinevat, andmepõhist regulatsiooniparameetri \\(\\lambda\\) valikut\n\n\nPost-LASSO\nMeetod, kus kõigepealt kasutatakse LASSO-t, et valida välja olulised tunnused (koefitsiendiga \\(\\neq 0\\)). Seejärel hintakse seos tavalise OLSiga (vähimruutude) regressiooni, kasutades ainult valitud tunnuseid.\n\n\nDouble Selection LASSO (DS-LASSO)\nMeetod, mille eesmärk on leida kõik olulised segajad (\\(X\\)), mis võivad mõjutada nihet (\\(D \\leftrightarrow Y\\) seose puhul). Viib läbi kaks LASSO-valikut: 1) \\(Y\\) seos \\(X\\)-idega 2) \\(D\\) seos \\(X\\)-idega. Mudelisse jäetakse kõik tunnused, mis valiti kas 1. või 2. etapis. Saadud mudel hinnatakse post-LASSO meetodiga.\n\n\nResidualisation (Jääkliikmete meetod)\nAlternatiivne lähenemine, mida kasutatakse LASSO-ga. See toimub kahes etapis: 1) \\(Y \\sim X\\) abil ja leitakse jääkliikmed \\(r_Y\\). 2) Modelleeritakse \\(D \\sim X\\) abil ja leitakse jääkliikmed \\(r_D\\). Lõpuks hinnatakse mõju regressiooniga: \\(r_Y \\sim r_D\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#muud",
    "href": "pohimoistedkordamiseks.html#muud",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.11 Muud",
    "text": "2.11 Muud\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nROC-kõver, AUC (Area under curve)\nReceiver operating characteristic (ROC) kõver kujutab sensitiivsuse (õigesti prognoositud sündmuste osakaal) and 1- spetsiifilisus (valepositiivsete osakaalu sündmust mitte omanud juhtudest) erinevates lõikepunktides. Selle joonie alune pindala on AUC – area under curve\n\n\nSensitiivsus\nPrognoositud toimumiste osakaal kokku tegelikest toimumistest\n\n\nSpetsiifilisus\nPrognoositud mitte-toimumiste osakaal kokku tegelikest mitte-toimumistest",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html",
    "href": "03-regressioon.html",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "4.1 Mudeli seade\nVaatame mõju (nt meetmes osalemise \\(D\\) mõju tulemile \\(Y\\)) hindamise meetodeid, kasutades regressioonimudeleid ja eeldust tingimuslikust sõltumatusest (Conditional Independence Assumption, CIA).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#mudeli-seade",
    "href": "03-regressioon.html#mudeli-seade",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "Tingimusliku sõltumatuse eeldus (CIA)\nPõhjusliku mõju leidmiseks regressiooniga peab kehtima tingimusliku sõltumatuse eeldus (CIA - conditional independence assumption).\n\\[E[Y_0 | D=1, \\mathbf{X}] = E[Y_0 | D=0, \\mathbf{X}]\\]\nSee tähendab, et pärast kõigi oluliste segavate tegurite \\(\\mathbf{X}\\) (eelkõige \\(X \\rightarrow D\\) ja \\(X \\rightarrow Y\\)) arvesse võtmist ei ole potentsiaalsel tulemusel \\(Y_0\\) ja meetmes osalemisel \\(D\\) enam seost. Seega, tingimuslikult sarnased osalejad ja mitte-osalejad on võrreldavad.\n\n\nRegressioonimudelid mõju hindamiseks\nKui CIA kehtib ja eeldame aditiivset (lineaarset) mudelit, saame regressiooniga hinnata erinevaid keskmisi mõjusid.\n\nTavaline regressioonimudel (ATE hinnang)\nKõige lihtsam mudel eeldab, et mõju \\(\\delta\\) on homogeenne (sama kõigi \\(\\mathbf{X}\\) väärtuste korral) ja aditiivne.\n\\[Y_i = \\alpha + \\delta D_i + \\mathbf{X}_i \\beta + \\epsilon_i\\]\nVõi üldjuhul, kui on selgitavaid tegureid rohkem:\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\dots + \\epsilon_i\\)\nMõju hinnang: \\(\\hat{\\delta}\\) on hinnang ATE-le (Average Treatment Effect), st keskmisele mõjule kõigile.\n\n\n\nRegressioonimudel interaktsiooniga (heterogeenne mõju)\nKui on alust arvata, et meetme mõju \\(D\\) sõltub mõnest tunnusest \\(X_k\\) (st mõju on heterogeenne), lisatakse mudelisse interaktsiooniliige.\n\\[Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\mathbf{X}_i \\beta + \\epsilon_i\\]\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\beta_1 X_{1i} + \\dots + \\epsilon_i\\)\nMõju \\(X_{ki}\\) väärtusel: \\(\\text{Mõju} = \\hat{\\delta} + \\hat{\\gamma} X_{ki}\\).\nKasutamine: Seda mudelit kasutades saab hinnata CATE-t (Conditional Average Treatment Effect), st keskmist mõju alamrühmas, ja leida seejärel kaalutud keskmist leides ATE või ATT.\n\n\n\n\nKaks eraldi eegressioonimudelit (G-Computation)\nSee meetod hinnatakse regressioonimudeleid eraldi osalejate (\\(D=1\\)) ja mitte-osalejate (\\(D=0\\)) andmetel, mis võimaldab arvestada heterogeenset funktsionaalset seost \\(Y_0\\) ja \\(Y_1\\) vahel.\n\nMudel osalejatel (\\(D=1\\)): \\[Y_i = \\alpha_1 + \\mathbf{X}_i \\beta_1 + \\epsilon_{i1} \\quad \\text{kui } D_i=1\\] Prognoosime tulemuse \\(Y_{i1}\\) kõigile vaatlustele: \\(\\hat{Y}_{i1} = \\hat{\\alpha}_1 + \\mathbf{X}_i \\hat{\\beta}_1\\).\nMudel mitte-osalejatel (\\(D=0\\)):\n\n\\[Y_i = \\alpha_0 + \\mathbf{X}_i \\beta_0 + \\epsilon_{i0} \\quad \\text{kui } D_i=0\\]\nPrognoosime tulemuse \\(Y_{i0}\\) kõigile vaatlustele: \\(\\hat{Y}_{i0} = \\hat{\\alpha}_0 + \\mathbf{X}_i \\hat{\\beta}_0\\).\n\nMõju arvutamine (G-Computation): Mõju on igal isikul prognooside vahe: \\(\\hat{\\Delta}_i = \\hat{Y}_{i1} - \\hat{Y}_{i0}\\).\n\nATE (kogu populatsioon): \\(\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^N \\hat{\\Delta}_i\\)\nATT (meetmes osalejatele): \\(\\text{ATT} = \\frac{1}{N_T} \\sum_{i: D_i=1} \\hat{\\Delta}_i\\)\nATU (võrdlusrühmale): \\(\\text{ATU} = \\frac{1}{N_C} \\sum_{i: D_i=0} \\hat{\\Delta}_i\\)\n\n\nSee meetod on regressiooni mudeliga hindamise erijuht ja annab paindlikumad hinnangud, kuna võimaldab funktsionaalsel seosel \\(Y \\sim \\mathbf{X}\\) olla erinev osalejatel ja mitte-osalejatel.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#näide-tööpoliitikast",
    "href": "03-regressioon.html#näide-tööpoliitikast",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "4.2 Näide tööpoliitikast",
    "text": "4.2 Näide tööpoliitikast\nMe kasutame näidisandmetena Poliitikauuringute Keskuse Praxis 2002. aastal läbiviidud uuringut aktiivse tööpoliitika mõju hindamise kohta. (Vt Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 108 lk. Vt ka: Praxis töö ja Leetmaa & Võrk (2004))\nAnonümiseeritud andmestik asub failis:\nhttp://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\n\nMuutujate selgitused\n\n\n\n\n\n\n\nMuutuja\nSelgitus\n\n\n\n\ntraining\nReceived labour market training in 2000 / Tunnus kas sai tööturukoolitust või ei 2000. aasta esimeses pooles\n\n\nnwage\nNetopalk 2002. aasta septembris\n\n\nemployed\nEmployed in September 2002 / Hõivatus 2002. aasta septembris (1 – hõivatud, 0 – töötu või mitteaktiivne)\n\n\nstatus\nTööturustaatus 2002. aasta septembris (1 – hõivatud, 2 – töötu, 3 – mitteaktiivne)\n\n\nkaal\nSample weight / Vaatluse statistiline kaal\n\n\nmale\nmale / Meessoost\n\n\nest\nEstonian / Eestlane\n\n\nage\nVanus aastates 2002. aastal\n\n\nlangest\nKas oskab eesti keelt\n\n\nemplbefore\nKas oli töökogemus enne töötuks registreerimist 2000. aastal\n\n\neduc\nHaridustase: 1 – ISCED 0,1,2 (põhiharidus); 2 – ISCED 3 (keskharidus); 3 – ISCED 3,4 (kutsekeskharidus); 4 – ISCED 5,6 (kõrgharidus)\n\n\ncounty\nMaakond: Tallinn, Viljandimaa, Tartumaa, Ida-Virumaa\n\n\ntown\nElab linnas vs maal\n\n\nchildren\nLaste arv töötuks registreerimise hetkel\n\n\nmarital\nPerekonna seis töötuks registreerimise hetkel: 0 – vallaline; 1 – abielus; 2 – vabaabielu; 3 – lahutatud; 4 – lesk\n\n\ntraining1\nOsalusrühm tingimusel, et ei nõutud tõendit hilisema töö saamise kohta – kellelt nõuti, neil puuduv väärtus\n\n\ntraining2\nVõrdlusgrupp, kes soovisid, kuid ei saanud/soovinud osaleda mingil põhjusel\n\n\ntraining3\nKombinatsioon training2 ja training3: need osalusgrupist, kellelt ei nõutud töökohta; need võrdlusgrupist, kes uurisid koolitust, kuid ei osalenud\n\n\ntraining4\nKoolituse osalusrühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid\n\n\ntraining5\nKoolituse põhirühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid ja kellelt ei nõutud tõendit\n\n\n\n\n\nVajalikud paketid\n\nlibrary(dplyr)\nlibrary(stargazer)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(boot)\nlibrary(ggplot2)\n\n\n\nAndmestiku lugemine\n\natp &lt;- read.csv(\"http://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\")\n\n\n\nKirjeldav analüüs\nLeidke, mitu inimestest osales 2000. aastal koolituses ja mitu ei osalenud\n\ntable(atp$training)\n\n\n  0   1 \n878 429 \n\n\nKui suur osakaal koolituses osalejatest ja mitte-osalejatest töötas 2002. aasta septembris? Tabuleerige muutujad “training” ja “employed” ning leidke protsendid.\n\ntab &lt;- table(atp$training, atp$employed)\nprop.table(tab, margin = 1)\n\n   \n            0         1\n  0 0.4100228 0.5899772\n  1 0.2913753 0.7086247\n\n\nMilline oli keskmine palk koolituses osalejatel ja mitte-osalejatel 2002. aasta septembris?\n\natp %&gt;% group_by(training) %&gt;% summarise(mean_wage = mean(nwage, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  training mean_wage\n     &lt;int&gt;     &lt;dbl&gt;\n1        0     1678.\n2        1     2042.\n\n\n\n\nRegressioonimudel\nHinnake regressioonimudel, kus väljundid employed ja nwage sõltuvad ainult koolituses osalemisest.\n\nm1 &lt;- lm(employed ~ training, data = atp)\nm2 &lt;- lm(nwage ~ training, data = atp)\nstargazer(m1, m2, type = \"text\")\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                            employed                  nwage         \n                              (1)                      (2)          \n--------------------------------------------------------------------\ntraining                    0.119***               363.850***       \n                            (0.028)                 (119.754)       \n                                                                    \nConstant                    0.590***              1,677.766***      \n                            (0.016)                 (68.337)        \n                                                                    \n--------------------------------------------------------------------\nObservations                 1,307                    1,256         \nR2                           0.013                    0.007         \nAdjusted R2                  0.013                    0.007         \nResidual Std. Error    0.480 (df = 1305)      1,988.834 (df = 1254) \nF Statistic         17.591*** (df = 1; 1305) 9.231*** (df = 1; 1254)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nHinnake mudelid koos teiste selgitavate teguritega\n\natp$age2 &lt;- atp$age^2\nlin_employed &lt;- lm(employed ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_employed, vcov = vcovHC(lin_employed, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -0.15070176  0.15151587 -0.9946 0.3201030    \ntraining     0.09816437  0.02764834  3.5505 0.0003983 ***\nmale         0.07986481  0.02872120  2.7807 0.0055027 ** \nest          0.09711124  0.02694719  3.6038 0.0003255 ***\nage          0.02945808  0.00978750  3.0098 0.0026649 ** \nage2        -0.00040217  0.00012743 -3.1560 0.0016364 ** \neduc         0.05265150  0.01496051  3.5194 0.0004475 ***\nemplbefore   0.05064137  0.05218072  0.9705 0.3319782    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHinnake samasugune mudel ka palga kohta ja tõlgendage tulemusi.\n\nlin_nwage &lt;- lm(nwage ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_nwage, vcov = vcovHC(lin_nwage, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -1284.89226   687.88260 -1.8679   0.06201 .  \ntraining      254.84877   111.15732  2.2927   0.02203 *  \nmale          871.32268   138.00166  6.3139 3.775e-10 ***\nest           821.63833   127.20240  6.4593 1.504e-10 ***\nage            82.57500    43.00273  1.9202   0.05506 .  \nage2           -1.33722     0.53949 -2.4786   0.01332 *  \neduc          297.93783    61.36353  4.8553 1.354e-06 ***\nemplbefore    540.05556   220.40577  2.4503   0.01441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTõlgendage tulemusi!\nLubage võimalikku heteroskedastiivsust.\nLeiame robustsed standarvead.\n\nrobust_se1 &lt;- sqrt(diag(vcovHC(lin_employed, type = \"HC1\")))\nrobust_se2 &lt;- sqrt(diag(vcovHC(lin_nwage, type = \"HC1\")))\nstargazer(lin_employed, lin_nwage, se = list(robust_se1, robust_se2), type = \"text\", no.space = TRUE)\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                           employed                  nwage          \n                              (1)                     (2)           \n--------------------------------------------------------------------\ntraining                   0.098***                254.849**        \n                            (0.028)                (111.157)        \nmale                       0.080***                871.323***       \n                            (0.029)                (138.002)        \nest                        0.097***                821.638***       \n                            (0.027)                (127.202)        \nage                        0.029***                 82.575*         \n                            (0.010)                 (43.003)        \nage2                      -0.0004***                -1.337**        \n                           (0.0001)                 (0.539)         \neduc                       0.053***                297.938***       \n                            (0.015)                 (61.364)        \nemplbefore                   0.051                 540.056**        \n                            (0.052)                (220.406)        \nConstant                    -0.151                -1,284.892*       \n                            (0.152)                (687.883)        \n--------------------------------------------------------------------\nObservations                 1,307                   1,256          \nR2                           0.051                   0.109          \nAdjusted R2                  0.046                   0.104          \nResidual Std. Error    0.472 (df = 1299)     1,888.387 (df = 1248)  \nF Statistic         9.954*** (df = 7; 1299) 21.885*** (df = 7; 1248)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKas robustsete standardvigade kasutamine muudab statistilist parameetrite statistilist olulisust?\n\n\nEraldi mudelid osalejatele ja mitteosalejatele\n\nNäide - meetme mõju palgale vanuse lõikes\n\natpj &lt;- atp %&gt;% filter(!is.na(nwage)) %&gt;% \n  filter(nwage&lt;5000, nwage&gt;0)\n\nggplot(atpj,\n       aes(x = age, y = nwage, color = \"Palk\")) +\n  geom_point() +\n  geom_smooth(data = atpj %&gt;% filter(training ==1), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 1\")) +\n  geom_smooth(data = atpj %&gt;% filter(training ==0), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 0\")) +\n  scale_color_manual(name = \"\", values = c(\"Palk\" = \"grey\",\n                                           \"Prognoos, D = 1\" = \"blue\",\n                                           \"Prognoos, D = 0\" = \"green\")) +\n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Palk\", color = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\natpj$ate &lt;-\n  predict(lm(nwage ~ age, data=atpj[atpj$training==1,]), new=atpj) - \n           predict(lm(nwage ~ age, data=atpj[atpj$training==0,]), new=atpj)\n\nSee joonis näitab, kuidas vanus mõjutab palka kahes erinevas grupis (osalejad vs mitte-osalejad). Kasutame valemi \\(Y \\sim X\\) seost vanuse osas.\nMõju sõltub vanusest. Mida noorem, seda suurem efekt.\n\nggplot(atpj,\n       aes(x = age, y = ate)) +\n  geom_line() +\n  #geom_rug(sides = \"b\") +\n  #geom_histogram(aes(y = ..count..), \n  #               binwidth = 1, alpha = 0.9, fill = \"grey\", position = \"identity\") +\n  geom_histogram(aes(fill = as.factor(training), y = ..count..), \n                 binwidth = 1, alpha = 0.5, position = \"identity\") +  # Colored histogram by gender\n  scale_fill_manual(values = c(\"green\", \"blue\")) +\n  \n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Meetme mõju\", fill = \"Meetmes\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nLisame täiendavad selgitavad tunnused\nTöötamise jaoks\nHindame mudeli osalejate andmete põhjal ja prognoosime tulemused kõigile.\n\nlin_employed_ra1 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$pemployed_1 &lt;- predict(lin_employed_ra1, newdata = atp)\n\nHinnake samasugune mudel ka mitteosalejate põhjal  training==0 ja prognoosige tulemused kõigile\n\nlin_employed_ra0 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$pemployed_0 &lt;- predict(lin_employed_ra0, newdata = atp)\n\nLeiame individuaalsed erinevused prognoositud hinnangutes\n\natp$demployed &lt;- atp$pemployed_1 - atp$pemployed_0\n\nKeskmised mõjuhinnangud (ATE) ja eraldi ka osalejatele ning mitteosalejatele\n\nate_empl &lt;- mean(atp$demployed)\natt_empl &lt;- mean(atp$demployed[atp$training == 1])\natu_empl &lt;- mean(atp$demployed[atp$training == 0])\n\nate_empl\n\n[1] 0.1063243\n\natt_empl\n\n[1] 0.0926108\n\natu_empl\n\n[1] 0.1130248\n\n\nKas tulemused muutusid võrreldes ühise regressioonimudeliga?\nSama palgaga\n\nlin_nwage_ra1 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$nwage_1 &lt;- predict(lin_nwage_ra1, newdata = atp)\n\nlin_nwage_ra0 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$nwage_0 &lt;- predict(lin_nwage_ra0, newdata = atp)\n\natp$dnwage &lt;- atp$nwage_1 - atp$nwage_0\nate_nwage &lt;- mean(atp$dnwage)\natt_nwage &lt;- mean(atp$dnwage[atp$training == 1])\natu_nwage &lt;- mean(atp$dnwage[atp$training == 0])\n\nate_nwage\n\n[1] 259.2266\n\natt_nwage\n\n[1] 254.2755\n\natu_nwage\n\n[1] 261.6458\n\n\nKas koolituse mõju on suurem osalejatele või oleks olnud suurem mitte-osalejatele? Kas mõju on statistiliselt oluline?\n\n\n\nBootstrapping hinnangute standardvea leidmiseks - fännidele\nTeeme funktsiooni\n\nf &lt;- formula(employed ~ male + est + age + age2 + educ + emplbefore)\n\nmybs = function(data, indices, formula =f) {\n  dat = data[indices, ]\n  dify = predict(lm(formula, data = dat[dat$training == 1, ]), newdata = dat) -\n         predict(lm(formula, data = dat[dat$training == 0, ]), newdata = dat)\n  c(ate = mean(dify), att = mean(dify[dat$training == 1]))\n}\n\nja rakendame seda\n\nset.seed(1632)\nresults &lt;- boot(data = atp, statistic = mybs, R = 50, stype = \"i\")\nboot.ci(results)\n\nWarning in norm.inter(t, adj.alpha): extreme order statistics used as endpoints\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 50 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic             Studentized     \n95%   ( 0.0528,  0.1499 )   ( 0.0510,  0.1590 )   ( 0.0621,  0.1969 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.0536,  0.1617 )   ( 0.0503,  0.1415 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\nSome studentized intervals may be unstable\nSome percentile intervals may be unstable\nWarning : BCa Intervals used Extreme Quantiles\nSome BCa intervals may be unstable",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  }
]