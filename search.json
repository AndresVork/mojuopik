[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Põhjuslike seoste hindamine majanduses",
    "section": "",
    "text": "Eessõna\nKäesolev lühikonspekt on mõeldud tutvustamaks mõju hindamise meetodeid majandustudengitele.\nSiia hakkan panema aines “Põhuse ja tagajärje seosed” kasutatud õppematerjale.\nKonspekt on jooksvalt täienev.",
    "crumbs": [
      "Eessõna"
    ]
  },
  {
    "objectID": "01-sissejuhatus.html",
    "href": "01-sissejuhatus.html",
    "title": "1  Sissejuhatus",
    "section": "",
    "text": "Tuleb kunagi\nLisada peatükid:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sissejuhatus</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html",
    "href": "pohimoistedkordamiseks.html",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "2.1 Potentsiaalse tulemuse mudel (POM)\nTudengid peaksid teadma järgmisi põhimõisteid.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "href": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "Mõiste\nSelgitus\n\n\nPõhjuslik mõju (Causal Effect)\nMõju on defineeritud kui kahe oleku (sekkumine \\(D=1\\) ja võrdlusseisund \\(D=0\\)) tulemuse võrdlus. See on see, mida püütakse hinnata.\n\n\nPotentsiaalne tulemus (\\(Y_{i1}, Y_{i0}\\))\nTulemus, mis võiks realiseeruda isikule \\(i\\). \\(Y_{i1}\\) on tulemus (nt palk), kui isik osales meetmes (\\(D=1\\), osalusseisund); \\(Y_{i0}\\) on tulemus, kui isik ei osalenud meetmes (\\(D=0\\), võrdlusseisund). Me saame vaadelda vaid ühte neist.\n\n\nKeskmine mõju (ATE) (Average Treatment Effect)\nPoliitikameetme keskmine mõju kogu üldkogumile. See näitab, milline oleks programmi keskmine mõju, kui see tehtaks kohustuslikuks, või mis oleks oodatav mõju, kui võtaksime juhuslikult ühe inimese üldkogumist.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult osalesid. Tavaliselt erineb ATE-st, kuna mõju (\\(\\delta_i\\)) on inimeste jaoks erinev.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult ei osalenud.\n(See on hüpoteetiline mõju. Me leiame selle nende põhjal, kes tegelikult osalesid)\n\n\nOsalusrühm / Osalusgrupp (Treatment Group)\nObjektid (isikud, ettevõtted, piirkonnad), mis saavad meetme või mida mõjutab poliitikamuutus.\n\n\nVõrdlusrühm/\nKontrollgrupp (Control Group)\nÜhikud (isikud, ettevõtted, piirkonnad), mis ei saa meedet või mida ei mõjuta poliitikamuutus. Selle rühma püüame enamasti teha võimalikult sarnaseks osalusrühmaga.\n\n\nLihtne keskmiste erinevus (SDO) (Simple Difference of Outcomes)\nVaadeldud osalusgrupi ja võrdlusgrupi keskmiste tulemuste lihtne erinevus. See annab üldjuhul nihkega tulemuse: \\(\\text{SDO} = \\text{ATE} + \\text{Valikunihe} + \\text{Nihe heterogeense mõju tõttu}\\)\n\n\nValikunihe (Selection Bias)\nViga hinnangus, mis tekib, kuna osalenud (\\(D=1\\)) ja mitteosalenud (\\(D=0\\)) inimesed või ettevõtted erinevad üksteisest (nt võimekuse või motivatsiooni poolest). Valikunihke elimineerimine või selle vähendamine on mõju hindamisel üks peamine ülesanne.\n\n\nSUTVA eeldus (Stable Unit Treatment Value Assumption)\nEeldus, mis koosneb järgmistest tingimusest: meetmes osalemine on selgelt defineeritud (osaled või ei osale), üksikisiku osalemine ja tulemus sõltuvad ainult tema enda osalemise otsusest, mitte teiste omast (puuduvad välismõjud, general equilibrium effects).\nSeega on vaatlused sõltumatud ja meetmed peaks olema väikesed.\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nTuntud ka kui Unconfoundedness või Selection on Observables. Eeldus, et potentsiaalne tulemus (\\(Y\\)) ja meetmes osalemine (\\(D\\)) on sõltumatud pärast seda, kui oleme arvesse võtnud kõik olulised jälgitavad tunnused (X).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "href": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.2 Graafiline mõju modelleerimine (DAG)",
    "text": "2.2 Graafiline mõju modelleerimine (DAG)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSuunatud atsükliline graaf (DAG) (Directed Acyclic Graph)\nGraafiline vahend, mis kirjeldab muutujate vahelisi põhjuslikke seoseid. Noolteta jooned tähendavad, et seost ei ole. Põhjuslikkus on ühesuunaline ja ei sisalda tsükleid.\n\n\nSegaja (Confounder)\nMuutuja (nt \\(X\\)), mis on seotud nii meetmega (\\(D\\)) kui ka tulemusega (\\(Y\\)). (\\(D \\leftarrow X \\rightarrow Y\\)) Segaja kaudu kulgeb tagauks (backdoor path), mis tuleb sulgeda, et hinnang \\(D\\) mõju kohta \\(Y\\)-le oleks nihketa.\n\n\nTagauks (Backdoor Path)\nPõhjuslik tee meetme (\\(D\\)) ja tulemuse (\\(Y\\)) vahel, mis kulgeb läbi segaja(te). See teeb tuleb sulgeda, kas regressioonimudeli, sobitamise, eksperimendi või muu viisi abil. .\n\n\nOmitted Variable Bias (Nihe välja jäetud muutuja tõttu)\nNihkega hinnang, mis tekib, kui oluline segaja (\\(X\\)) jäetakse analüüsist välja.\n\n\nKollaider / Põrguti (Collider)\nMuutuja (nt \\(X\\)), mis on põhjustatud meetme (\\(D\\)) ja tulemuse (\\(Y\\)) poolt (\\(D \\rightarrow X \\leftarrow Y\\)). Kui kollaider pannakse mudelisse, luuakse uus (nihkega) seos (avatakse tagauks), mistõttu neid ei tohi mudelitesse lisada.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "href": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.3 Mõju hindamise meetodid",
    "text": "2.3 Mõju hindamise meetodid\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nHomogeenne efekt (Homogeneous Effect)\nRegressioonimudeli eeldus (kui ristkorrutised puuduvad), et põhjuslik mõju (\\(\\delta\\)) on kõigi jaoks ühesugune. Sellisel juhul \\(\\text{ATE} = \\text{ATT} = \\text{ATU}\\).\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus, et põhjuslik mõju erineb isikuti või alamrühmade kaupa. Seda saab modelleerida, lisades regressioonivõrrandisse ristkorrutised (nt \\(D_i \\cdot X_i\\))\n\n\nInstrument-muutuja (Instrumental Variable, Z)\nRegressioonianalüüsis kasutatav muutuja, mis on seotud meetmega (\\(D\\)), aga seos tulemusega (\\(Y\\)) tekib ainult \\(D\\) kaudu34. Aitab vähendada mittejälgitavate segajate (u) mõju.\n\n\nSobitamine (Matching)\nMeetod valikunihke vähendamiseks, kus osalenud isikutele leitakse sarnased mitteosalenud isikud (nt haridustaseme, vanuse vms \\(X\\) väärtuste alusel).\n\n\nPaneelandmete kasutamine\nMeetod, mis aitab elimineerida ajas muutumatute mittejälgitavate segajate (\\(u\\)) mõju (nt kaasasündinud võimekust).\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus loodus või institutsionaalne muutus (nt seaduse muutus) eraldab juhuslikult kaks rühma, andes uurijale peaaegu samaväärse tingimuse kui juhuslik eksperiment, vähendades mittejälgitava segaja (\\(u\\)) mõju\n\n\nÜhine tugi (Common Support)\nTingimus, mis peab olema täidetud CIA eelduse ja sobitamismeetodite korral. See tähendab, et antud \\(X\\) väärtuste juures peavad olema esindatud nii osalejad (\\(D=1\\)) kui ka mitteosalejad (\\(D=0\\)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "href": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.4 Juurdekasvude erinevus (DiD)",
    "text": "2.4 Juurdekasvude erinevus (DiD)\nDifference-in-differences method\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nJuurdekasvude erinevus (DiD)\nMeetod paneelandmete (või korduvate ristandmete) abil põhjusliku mõju hindamiseks. Eeldab, et meil on osalusgrupp (saab meetme) ja võrdlusgrupp (ei saa) ning andmed nii enne kui ka pärast meetme rakendamist.\n\n\nParalleelsete trendide eeldus (Parallel Trends Assumption)\nKõige olulisem eeldus DiD-meetodis. See nõuab, et kui osalusgrupp ei oleks meedet saanud, oleks nende tulemuse trend ajas olnud sama kui võrdlusgrupil.\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus DiD-meetodit sageli kasutatakse. Tekib, kui väline (eksogeenne) muutus, näiteks uus seadus, mõjutab ühte rühma, aga mitte teist.\n\n\nKolmekordne erinevus (Triple Difference)\nDiD-meetodi edasiarendus. Võrdleb DiD hinnangut (nt mõjutatud rühma ja kontrollrühma vahel) teise DiD hinnanguga (nt sarnase, kuid vähem mõjutatud rühma vahel). Kasutatakse potentsiaalsete väliste segajate eemaldamiseks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "href": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.5 Regressiooni katkemise disain",
    "text": "2.5 Regressiooni katkemise disain\n(Regression Discontinuity Design, RDD)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegressiooni katkemise disain (RDD)\nMõju hindamise meetod, mida kasutatakse, kui meetmes osalemine on määratud täpse lävendi (cut-off) alusel pideva muutuja (running variable) väärtusel. Näiteks vanus (lävend: 65 eluaastat pensionile jäämiseks).\n\n\nLõikepunkt / Lävend (Cut-off / Threshold)\nTäpne väärtus määravas muutujas (X), mis määrab, kas isik saab meetme (D=1) või mitte (D=0).\n\n\nMäärav muutuja (Running Variable / Assignment Variable)\nPidev muutuja (nt vanus, sissetulek, eksami tulemus), mille lävend määrab meetmes osalemise.\n\n\nLokaalne keskmine mõju (Local Average Treatment Effect, LATE)\nRDD-ga saadud hinnang näitab meetme põhjuslikku mõju ainult lävendi piiril olevatele isikutele, mitte kogu elanikkonnale.\n\n\nTäpne RDD (Sharp RDD)\nRDD vorm, kus lävendi ületamine määrab täielikult meetmes osalemise (st \\(P(D=1 \\vert X) = 1\\) lävendist paremal, ja \\(P(D=1 \\vert X) = 0\\) lävendist vasakul).\n\n\nHägune RDD (Fuzzy RDD)\nRDD vorm, kus lävendi ületamine muudab järsult tõenäosust meetmes osaleda, kuid ei määra seda täielikult (st \\(0 &lt; P(D=1 \\vert X) &lt; 1\\)).\n(Sarnane instrument-muutuja meetodile).\n\n\nPidevuse eeldus (Continuity Assumption)\nOluline eeldus RDD puhul. Nõuab, et potentsiaalsed tulemused (\\(Y_0, Y_1\\)) oleks pidevad lävendi juures. Tähendab, et lävendi lähedal ei tohi olla muid järske muutusi (nt manipuleerimist) peale meetme (\\(D\\)) osalemise muutuse.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sobitamine",
    "href": "pohimoistedkordamiseks.html#sobitamine",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.6 Sobitamine",
    "text": "2.6 Sobitamine\n(Matching)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSobitamine (Matching)\nMõju hindamise meetod, mille eesmärk on leida igale osalusrühmas olevale isikule (kes sai meetme) võimalikult sarnane isik võrdlusrühmast (kes meedet ei saanud).\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nSobitamise põhi-eeldus: \\(Y_0\\) ja \\(Y_1\\) on sõltumatud \\(D\\)-st tingimusel, et on arvesse võetud kõik jälgitavad segajad \\(X\\). See tähendab, et sobitamine tegeleb vaid valikunihkega, mis tuleb jälgitavatest tunnustest.\n\n\nÜhine tugi (Common Support)\nEeldus, mis peab kehtima: Iga osalusrühmas oleva isiku jälgitavate tunnuste \\(X\\) väärtuste (või tõenäosusskoori) läheduses peab olema piisavalt vaatlusi ka võrdlusrühmas.\n\n\nTõenäosuse skoor (PS) (Propensity Score, \\(P(X)\\))\nTõenäosus, et isik kuulub osalusrühma, arvestades tema jälgitavaid tunnuseid \\(X\\). See on tavaliselt logit- või probit regressioonimudeli abil hinnatud väärtus: \\(P(D_i = 1 \\mid X_i)\\).\n\n\nSobitamine tõenäosuse skoori alusel (PSM) (Propensity Score Matching)\nSagedasti kasutatud sobitamismeetod, mis kasutab mitme muutuja \\(X\\) asemel ühte mõõdikut: tõenäosuse skoori meetmes osaleda. Osalusrühma isikutele sobitatakse võrdlusrühma isikud, kelle \\(P(X)\\) väärtused on väga lähedal.\n\n\nLähima naabri sobitamine (Nearest Neighbor Matching)\nMeetod, kus igale osalusrühma vaatlusele leitakse kõige lähima kaugusega (nt \\(P(X)\\) alusel või Mahalanobise kauguse alusel) vaste võrdlusrühmast. Kasutada saab tagasipanekuga (või ilma).\n\n\nKaliiber (Caliper)\nMääratud maksimaalne lubatud kaugus (\\(P(X)\\) erinevus) paari sobitamisel. Aitab tagada kvaliteetsemad vasted, isegi kui see vähendab sobitatud isikute arvu.\n\n\nTasakaalu test (Balance Test)\nOluline samm sobitamise järel. Kontrollitakse, kas jälgitavate tunnuste \\(X\\) keskmised väärtused on sobitatud osalus- ja võrdlusrühmas piisavalt sarnased (statistiliselt oluliselt ei erine).\n\n\nOtste lõikamine (Trimming)\nSobitamise-eelne või -järgne tegevus, millega eemaldatakse analüüsist vaatlused, millel puudub ühine tugi (nt liiga väike või liiga suur \\(P(X)\\) väärtus).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "href": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.7 Instrumentmuutuja meetod (IV)",
    "text": "2.7 Instrumentmuutuja meetod (IV)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nInstrumentmuutuja (Z) (Instrumental Variable, IV)\nMuutuja, mida kasutatakse regressioonimudelis, et saada nihketa hinnang meetme (\\(D\\)) mõjule tulemusele (\\(Y\\)). Peab vastama kahele tingimusele (vt allpool).\n\n\nEndogeensus / Nihe (Endogeneity / Bias)\nProbleem, kus meetme muutuja (\\(D\\)) on korreleeritud regressioonimudeli vealiikmega (\\(u\\)). See tekib valikunihke või kahesuunalise põhjuslikkuse tõttu ning viib OLS-i puhul nihkega hinnanguni.\n\n\nIV Tingimus 1: Relevantsus (Relevance)\nEsimene ja testitav eeldus: instrumentmuutuja (\\(Z\\)) peab olema tugevalt korreleeritud meetme muutujaga (\\(D\\)). St, \\(Z\\) peab mõjutama \\(D\\)-d.\n\n\nIV Tingimus 2: Väline kehtivus / Eksogeensus (Exclusion Restriction / Exogeneity)\nTeine ja mittetestitav eeldus: Instrumentmuutuja (\\(Z\\)) tohib mõjutada tulemust (\\(Y\\)) ainult meetme muutuja (\\(D\\)) kaudu. St, \\(Z\\) ei tohi olla korreleeritud vealiikmega (\\(u\\)).\n\n\nKaheetapiline vähimruutude meetod (2SLS) (Two-Stage Least Squares)\nIV-meetodi rakendamise viis. 1. etapp: regresseeritakse \\(D\\) \\(Z\\)-i ja \\(X\\)-ide suhtes. 2. etapp: regresseeritakse \\(Y\\) \\(D\\) ennustatud väärtuse ja \\(X\\)-ide suhtes.\n\n\nLokaalne keskmine mõju (LATE) (Local Average Treatment Effect)\nIV-meetodi puhul saadud põhjuslik mõju hinnang. See mõju kehtib vaid allujatele (compliers) – neile, kelle osalemisotsus (\\(D\\)) oli mõjutatud instrumentmuutujast (\\(Z\\)).\nKui eeldame, et mõju on kõigi jaoks ühesugune (homogeenne), siis rühmade eristus ei ole vajalik.\n\n\nNõrk instrument (Weak Instrument)\nOlukord, kus instrumentmuutuja (\\(Z\\)) ei ole piisavalt tugevalt seotud meetme muutujaga (\\(D\\)). Viib nihkega (OLS-i poole kaldu) ja ebatäpsete IV-hinnanguteni.\n\n\nHausman-Wu test (Hausman-Wu Test)\nTest, millega kontrollitakse endogeensuse olemasolu meetme muutuja (\\(D\\)) ja vealiikme (\\(u\\)) vahel. Kui test on oluline, näitab see, et \\(D\\) on endogeenne ja IV-meetodi kasutamine on vajalik.\n\n\nSargani test (Sargan Test)\nTest, millega kontrollitakse eksogeensuse eelduse paikapidavust (Exclusion Restriction), kui meil on rohkem instrumente kui endogeenseid muutujaid (üleidentifitseeritud juht).\n\n\nWaldi hinnang binaarse meetme ja binaarse instrumendi korral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "href": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.8 Sünteetilise võrdlusobjekti meetod",
    "text": "2.8 Sünteetilise võrdlusobjekti meetod\n(Synthetic Control Method)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSünteetiline Võrdlusobjekt (SCM) (Synthetic Control Method), sünteetilise kontrollgrupi meetod\nMeetod, mida kasutatakse ühe meetmes osaleja puhul (nt ühe riigi) mõju hindamiseks, luues teistest, mitteosalevatest objektidest (doonorrühmast) kaalutud kombinatsioon.\n\n\nSihtobjekt (Treated Unit)\nAinus uuritav ühik (nt linn, riik), mis on saanud sekkumise (meetme). SCM eesmärk on leida sellele veenev võrdlusobjekt.\n\n\nDoonorrühm, võrdlusobjektid (Donor Pool / Control Units)\nMeetmest mitte mõjutatud ühikute kogum, mille kaalutud keskmisest tehakse sünteetiline võrdlusobjekt. Nende kaalude summa peab olema 1 ja kaalud ei tohi olla negatiivsed.\n\n\nKaalud (\\(\\mathbf{W}\\)) (Weights)\nPositiivsed väärtused, mis määratakse võrdlusrobjektidele. Need kaalud minimeerivad sihtobjekti ja sünteetilise võrdlusobjekti erinevust meetmele eelneval perioodil.\n\n\nSobitamisperiood / Eelperiood (Pre-intervention Period)\nAjavahemik enne meedet, mida kasutatakse kaalude \\(\\mathbf{W}\\) leidmiseks. Kaalud valitakse nii, et sihtobjekti ja sünteetilise võrdlusobjekti tulemused \\(\\mathbf{Y_t}\\) ja ka selgitavad tunnused \\(\\mathbf{X_{mt}}\\) oleksid selles perioodis võimalikult lähedased.\n\n\nMõju hinnang (Treatment Effect Estimate)\nSCM-iga saadud põhjuslik mõju, mis leitakse sihtobjekti ja sünteetilise võrdlusobjekti tulemuste vahe alusel pärast meetme rakendamist.\n\n\nPlatseebotest / Permutatsioonitest (Placebo Test / Permutation Test)\nEelduste ja järelduste statistiline testimismeetod SCM-is. Leitakse sama arvutuse tulemus ka teistele võrdlusrühma liikmetele ja hinnatakse, kas meid huvitava objekti tulemus on ebatavaliselt suur võrreldes teistega. Kui meie tulemus on eriline, siis see viitab, et tegemist on tegeliku mõjuga.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "href": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.9 Masinõppemeetodid - puud ja mets",
    "text": "2.9 Masinõppemeetodid - puud ja mets\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nOtsustuspuu (Decision Tree), Regressioonipuu (Regression Tree)\nMasinõppe algoritm, mis jaotab andmestiku samm-sammuliselt alamhulkadeks, et leida prognoosimise reeglid tulemuse (\\(Y\\)) või meetmes osalemise (\\(D\\)) kohta. Moodustab aluse juhumetsale.\nOtsustuspuu - väljund on diskreetne (nt kas töötab või osaleb meetmes)\nRegressioonipuu - väljund on pidev (nt palk)\n\n\nJuhumets (Random Forest)\nAnsambelmeetod, mis kombineerib mitu puud. Iga puu on ehitatud juhusliku valimiga (bootstrapping) ja kasutades juhuslikku alamhulka tunnustest igas harus. Kasutatakse peamiselt täpseks prognoosimiseks (\\(E[Y\\vert X]\\) või \\(P[D\\vert X]\\)).\n\n\nPõhjuslik mets / Kausaalmets\n(Causal Forest)\nJuhumetsa edasiarendus, mis on loodud spetsiaalselt heterogeense põhjusliku mõju (CATE) hindamiseks. Eraldab andmed kaheks: üks osa puude ehitamiseks ja teine osa mõju hindamiseks, et vältida üle-sobitamist (overfitting).\nKui tavaline puu maksimeerib prognooside erinevust igas lehes, siis kausaalpuu maksimeerib mõju erinevust igas lehes.\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus või tulemus, et põhjuslik mõju (\\(\\delta\\)) on erinevatel inimestel (alamrühmadel) erinev (st sõltub \\(X\\) väärtustest). Masinõppemeetodid on selle tuvastamisel eriti võimsad.\n\n\nKõrge-dimensiooniline andmestik (High-Dimensional Data)\nAndmestik, kus on väga palju jälgitavaid tunnuseid (\\(X\\)), mida peab arvesse võtma valikunihke korrigeerimiseks. Masinõpe aitab neist olulised leida.\n\n\nDouble Machine Learning (DML)\nÜks juhtivaid lähenemisi põhjusliku mõju hindamiseks masinõppe abil. Kasutab kaheetapilist meetodit (nagu 2SLS või AIPW), kus mõlemad etapid viiakse läbi (regressiooni vealiikmed leitakse) paindlike masinõppe meetodite (nt juhumets) abil.\n\n\nIPW (Inverse Probability Weighting)\nMeetod, kus mõju arvutamisel vaatlusi kaalutakse pöördvõrdeliselt nende tõenäosuse skooriga (\\(P(D=1 \\mid X)\\)). See annab osalejatele, kelle \\(P(X)\\) on väike, suurema kaalu, ja mitte-osalejatele, kelle \\(P(X)\\) on suur, suurema kaalu.\n\n\nAIPW (augmented inverse probability weighting)\nMeetod kus mõjuhinnangut korrigeeritakse tõenäosuskooridega korrigeeritud",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "href": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.10 LASSO mõju hindamisel",
    "text": "2.10 LASSO mõju hindamisel\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegulariseerimine (Regularized Regression)\nÜldnimetus meetoditele (nagu LASSO ja Ridge), mis lisavad regressioonimudeli eesmärgile (RSS minimeerimine) karistusliikme koefitsientide suuruse eest. See aitab vähendada üle-sobitamist (overfitting) ja teeb mudelid lihtsamaks.\n\n\nLASSO (Least Absolute Shrinkage and Selection Operator)\nRegulariseeriv regressioonimeetod, mis karistab suurte koefitsientide eest, lisades jääkliikmete ruutude summale (RSS) koefitsientide absoluutväärtuste summa (L1-norm). See sunnib paljusid väheolulisi tunnuseid \\(X\\) olema täpselt null – teeb automaatse tunnuste valiku.\n\n\nTunnuste valik (Feature Selection)\nLASSO peamine kasulik omadus ökonomeetrias. See suudab automaatselt tuhandete võimalike tunnuste (\\(X\\)) hulgast leida need, mis on põhjusliku mõju nihketa hindamiseks kõige olulisemad.\n\n\nRegulatsiooniparameeter (\\(\\lambda\\)) (Regularization Parameter, \\(\\lambda\\))\nParameeter LASSO ja Ridge mudelites, mis määrab karistuse tugevuse. Mida suurem \\(\\lambda\\), seda rohkem koefitsiente sunnitakse nulliks (LASSO puhul) ja seda suurem on koefitsientide kokkutõmbumine (mõlema puhul). \\(\\lambda\\) valitakse tavaliselt ristvalideerimise abil.\n\n\nRistvalideerimine (Cross-Validation)\nStatistiline tehnika \\(\\lambda\\) (regulatsiooniparameetri) optimaalse väärtuse leidmiseks. Andmestik jagatakse alamhulkadeks. \\(\\lambda\\) valitakse nii, et see minimeeriks prognoosivea (nt mean squared error) valimi-välisel andmestiku osal. See sobib hästi, kui eesmärk on prognoosimine\n\n\nTeoreetiline \\(\\lambda\\) valik (`rlasso` meetod)\nPakett `rlasso` (Belloni jt.) kasutab teoorial põhinevat, andmepõhist regulatsiooniparameetri \\(\\lambda\\) valikut\n\n\nPost-LASSO\nMeetod, kus kõigepealt kasutatakse LASSO-t, et valida välja olulised tunnused (koefitsiendiga \\(\\neq 0\\)). Seejärel hintakse seos tavalise OLSiga (vähimruutude) regressiooni, kasutades ainult valitud tunnuseid.\n\n\nDouble Selection LASSO (DS-LASSO)\nMeetod, mille eesmärk on leida kõik olulised segajad (\\(X\\)), mis võivad mõjutada nihet (\\(D \\leftrightarrow Y\\) seose puhul). Viib läbi kaks LASSO-valikut: 1) \\(Y\\) seos \\(X\\)-idega 2) \\(D\\) seos \\(X\\)-idega. Mudelisse jäetakse kõik tunnused, mis valiti kas 1. või 2. etapis. Saadud mudel hinnatakse post-LASSO meetodiga.\n\n\nResidualisation (Jääkliikmete meetod)\nAlternatiivne lähenemine, mida kasutatakse LASSO-ga. See toimub kahes etapis: 1) \\(Y \\sim X\\) abil ja leitakse jääkliikmed \\(r_Y\\). 2) Modelleeritakse \\(D \\sim X\\) abil ja leitakse jääkliikmed \\(r_D\\). Lõpuks hinnatakse mõju regressiooniga: \\(r_Y \\sim r_D\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#muud",
    "href": "pohimoistedkordamiseks.html#muud",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.11 Muud",
    "text": "2.11 Muud\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nROC-kõver, AUC (Area under curve)\nReceiver operating characteristic (ROC) kõver kujutab sensitiivsuse (õigesti prognoositud sündmuste osakaal) and 1- spetsiifilisus (valepositiivsete osakaalu sündmust mitte omanud juhtudest) erinevates lõikepunktides. Selle joonie alune pindala on AUC – area under curve\n\n\nSensitiivsus\nPrognoositud toimumiste osakaal kokku tegelikest toimumistest\n\n\nSpetsiifilisus\nPrognoositud mitte-toimumiste osakaal kokku tegelikest mitte-toimumistest",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html",
    "href": "02-pohimoisted.html",
    "title": "3  Põhimõisted",
    "section": "",
    "text": "3.1 Tähistused\nPotentsiaalse tulemuse mudel (potential outcomes model, POM) on põhjusliku mõju hindamise standardne raamistik statistikas ja majandusteaduses. Mudeli juured on Splawa-Neymani (1923), Roy (1951), Quandt’i (1958) ja Rubini (1974) töödes ning seda nimetatakse sageli Neyman–Rubin–Roy mudeliks.\nPõhiidee on lihtne: enne poliitikameedet või sekkumist on igal indiviidil mitu võimalikku tulemust, sõltuvalt sellest, kas ta osaleb meetmes või mitte. Reaalses elus näeme iga indiviidi kohta vaid üht realiseerunud tulemust. Sellest tekib põhjuslikkuse „põhiprobleem”: me ei näe kunagi sama indiviidi nii osalemas kui mitteosalejana samal ajal.\nPOM annab süsteemse raamistiku, kuidas notatsiooni abil defineerida huvipakkuvad suurused (ATE, ATT, ATU, CATE, LATE jne) ning milliste eelduste korral võime neid põhjuslikult tõlgendada.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#tähistused",
    "href": "02-pohimoisted.html#tähistused",
    "title": "3  Põhimõisted",
    "section": "",
    "text": "Meede ja tulemused\nOlgu indiviid (i) jaoks\n\nmeetmes osalemise tunnus\n\\[\nD_i \\in \\{0,1\\},\n\\] kus (D_i = 1) tähendab osalemist meetmes ja (D_i = 0) mitteosalemist;\npotentsiaalsed tulemused\nMeetmes osalemise korral:\n\\[ Y_i(1) \\quad \\text{tulemus, kui } D_i = 1, \\]\n\nMeetmes mitteosalemise korral\n\\[ Y_i(0) \\quad \\text{tulemus, kui } D_i = 0. \\]\nReaalselt jälgitav tulemus on\n\\[ Y_i = D_i \\, Y_i(1) + (1 - D_i)\\, Y_i(0). \\]\nSageli on meil lisaks ka vektor individuaalseid tunnuseid\n\\[ X_i = (X_{i1}, X_{i2}, \\dots, X_{ik}), \\]\nnäiteks sugu, vanus, haridus, piirkond, varasem sissetulek jne.\n\n\nIndividuaalne mõju\nIndividuaalne põhjuslik mõju indiviidi (i) jaoks on\n\\[\n\\delta_i = Y_i(1) - Y_i(0).\n\\]\nSellist mõju ei saa kunagi otse mõõta, sest me ei näe sama indiviidi korraga kahes olekus. Seetõttu keskendume populatsiooni- või alampopulatsiooni keskmistele mõjudele.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#huvipakkuvad-keskmised-mõjud",
    "href": "02-pohimoisted.html#huvipakkuvad-keskmised-mõjud",
    "title": "3  Põhimõisted",
    "section": "3.2 Huvipakkuvad keskmised mõjud",
    "text": "3.2 Huvipakkuvad keskmised mõjud\n\nATE – keskmine mõju populatsioonis\nPoliitikameetme keskmine mõju (average treatment effect, ATE) on defineeritud kui\n\\[\n\\text{ATE} = \\mathbb{E}\\big[ Y_i(1) - Y_i(0) \\big]\n           = \\mathbb{E}\\big[ Y_i(1) \\big] - \\mathbb{E}\\big[ Y_i(0) \\big].\n\\]\nTõlgendus: milline oleks keskmine tulemus, kui kogu populatsioon osaleks meetmes, võrreldes olukorraga, kui keegi ei osaleks meetmes. Või, milline oleks meetme oodatav mõju, kui võtame juhuslikult ühe inimese üldkogumist.\n\n\nATT – keskmine mõju osalenutele\nKeskmine mõju osalejate jaoks (average treatment effect on the treated, ATT) on\n\\[\n\\text{ATT} = \\mathbb{E}\\big[ Y_i(1) - Y_i(0) \\mid D_i = 1 \\big].\n\\]\nTõlgendus: kui palju paranesid tulemused nende jaoks, kes tegelikult osalesid, võrreldes hüpoteetilise olukorraga, kus just need samad inimesed ei oleks osalenud.\n\n\nATU – keskmine mõju mitteosalenutele\nMitteosalenute keskmine mõju (average treatment effect on the untreated, ATU) on\n\\[\n\\text{ATU} = \\mathbb{E}\\big[ Y_i(1) - Y_i(0) \\mid D_i = 0 \\big].\n\\]\nTõlgendus: kui palju oleks muutunud mitteosalenute tulemused, kui just nemad oleksid meetmes osalenud.\n\n\nATE seos ATT ja ATU-ga\nOlgu\n\\[\np = \\Pr(D_i = 1)\n\\]\nosalenute osakaal populatsioonis. Siis kehtib seos\n\\[\n\\text{ATE} = p \\cdot \\text{ATT} + (1 - p) \\cdot \\text{ATU}.\n\\]\nSeega võivad ATT ja ATU olla erinevad, kui mõju on heterogeenne eri rühmades, ning ATE on nende kaalutud keskmine.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#näited-ate-att-ja-atu-tõlgendamisest",
    "href": "02-pohimoisted.html#näited-ate-att-ja-atu-tõlgendamisest",
    "title": "3  Põhimõisted",
    "section": "3.3 Näited ATE, ATT ja ATU tõlgendamisest",
    "text": "3.3 Näited ATE, ATT ja ATU tõlgendamisest\nAlljärgnevalt mõned rakendusnäited majandusest.\n\nNäide 1: Töötajate koolitusprogramm\n\nMeede: ettevõte viib valitud töötajatele läbi edasijõudnute programmeerimiskoolituse.\nTulemus: tootlikkuse kasv (nt müük töötaja kohta, koodi kvaliteet).\nGrupid:\n\nkoolitatud: koolitusele valitud töötajad ((D=1));\nkoolitamata: töötajad, kes koolitust ei saanud ((D=0)).\n\n\nTõlgendused:\n\nATT:\nKui palju paranes tootlikkus koolitusel osalenud töötajatel võrreldes olukorraga, kus just need samad töötajad ei oleks koolitusel osalenud?\nATU:\nKui palju oleks muutunud tootlikkus töötajatel, kes ei osalenud, kui nemad oleksid koolituse saanud?\nATE:\nKui kõik töötajad oleks koolitatud, milline oleks keskmine tootlikkuse kasv ettevõttes?\n\n\n\nNäide 2: Turunduskampaania\n\nMeede: ettevõte saadab valitud klientidele e-posti kampaania allahindlusega.\nTulemus: ostutõenäosuse või käibe muutus.\n\nTõlgendused:\n\nATT: milline oli müügi kasv kampaania saanud klientide seas (võrreldes olukorraga, kus need kliendid poleks pakkumist saanud)?\nATU: kui palju oleks muutunud kampaania saamata klientide ostutõenäosus, kui neile oleks pakkumine saadetud?\nATE: mis oleks tulemus, kui kampaania saadetaks kõigile klientidele?\n\nSarnasel viisil saab tõlgendada ka tehnoloogiauendusi (nt uue AI-laohaldussüsteemi kasutuselevõtt) või paindlikke töökorraldusi (kaugtöö võimalus).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#lihtne-keskmiste-erinevus-ja-nihe",
    "href": "02-pohimoisted.html#lihtne-keskmiste-erinevus-ja-nihe",
    "title": "3  Põhimõisted",
    "section": "3.4 Lihtne keskmiste erinevus ja nihe",
    "text": "3.4 Lihtne keskmiste erinevus ja nihe\n\nLihtne erinevus tulemustes\nPraktikas alustatakse sageli lihtsa keskmiste erinevusega\n\\[\n\\text{SDO}\n= \\mathbb{E}[Y_i \\mid D_i = 1] - \\mathbb{E}[Y_i \\mid D_i = 0],\n\\]\ninglise keeles SDO - simple difference of outcomes.\nÜldjuhul ei võrdunud see ATE-ga, sest osalejad ja mitteosalejad erinevad süsteemselt (valikunihe) ning mõju võib olla heterogeenne.\n\n\nValikunihe ja heterogeense mõju nihe\nSDO saame kirjutada kujul\n\\[\n\\begin{aligned}\n\\text{SDO}\n&= \\mathbb{E}\\big[ Y_i(1) \\mid D_i = 1 \\big]\n   - \\mathbb{E}\\big[ Y_i(0) \\mid D_i = 0 \\big] \\\\\n&= \\underbrace{\\mathbb{E}\\big[ Y_i(1) - Y_i(0) \\mid D_i = 1 \\big]}_{\\text{ATT}}\n   + \\underbrace{\\Big(\\mathbb{E}\\big[ Y_i(0) \\mid D_i = 1 \\big]\n   - \\mathbb{E}\\big[ Y_i(0) \\mid D_i = 0 \\big]\\Big)}_{\\text{valikunihe}}.\n\\end{aligned}\n\\]\nLihtne erinevus sisaldab seega kahte komponenti:\n\ntõeline põhjuslik mõju osalenutele (ATT);\nvalikunihe (selection bias), mis tuleneb sellest, et osalenute ja mitteosalenute potentsiaalsed tulemused ilma meetmeta on erinevad.\n\nLisaks võib tekkida nihe heterogeense mõju tõttu, sest ATE, ATT ja ATU on erinevad ning lihtne erinevus ei kasuta „õigeid” kaale eri rühmade keskmiste kombineerimisel. Kokkuvõttes võib kirjutada skemaatiliselt\n\\[\n\\text{SDO} = \\text{ATE} + \\text{valikunihe} + \\text{heterogeense mõju nihe}.\n\\]\nAinult juhul, kui puudub valikunihe ja mõju ei ole heterogeenne (või kasutatakse sobivaid kaale), võime lihtsat erinevust tõlgendada keskmise põhjusliku mõjuna.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#sutva-stabiilse-ühikunäitaja-eeldus",
    "href": "02-pohimoisted.html#sutva-stabiilse-ühikunäitaja-eeldus",
    "title": "3  Põhimõisted",
    "section": "3.5 SUTVA – stabiilse ühikunäitaja eeldus",
    "text": "3.5 SUTVA – stabiilse ühikunäitaja eeldus\nStable unit treatment value assumption (SUTVA) koosneb kahest osast.\n\nPuuduvad interferentsid: ühe indiviidi tulemus ei sõltu sellest, kas teised indiviidid osalevad meetmes. Formaliseeritult\n\\[\nY_i(D) \\text{ ei sõltu } D_j, \\quad j \\neq i.\n\\]\nPuuduvad erinevad meetme versioonid: (D=1) tähendab kõigi jaoks sama tüüpi sekkumist.\n\nSUTVA rikkumise näited:\n\nkui üks töötutest osaleb koolitusel, võib see vähendada teiste töötute võimalust sama koolitust saada;\nkui üks töötutest leiab töö, võib see vähendada teiste töötute töö leidmise tõenäosust (konkurents töökohtade pärast);\nkui igal aastal koolitatakse suur hulk töötuid, võib see mõjutada palgataset kogu tööturul, muutes nii osalejate kui mitteosalejate palku.\n\nSUTVA on POM-i keskne eeldus: ilma selleta ei saa potentsiaalseid tulemusi selgelt defineerida.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#sõltumatuse-eeldus-ja-juhuslik-eksperiment",
    "href": "02-pohimoisted.html#sõltumatuse-eeldus-ja-juhuslik-eksperiment",
    "title": "3  Põhimõisted",
    "section": "3.6 Sõltumatuse eeldus ja juhuslik eksperiment",
    "text": "3.6 Sõltumatuse eeldus ja juhuslik eksperiment\n\nTugev sõltumatuse eeldus\nKõige lihtsam olukord on juhuslik eksperiment, kus töötlus määratakse loosiga. Sellisel juhul eeldame, et\n\\[\n\\big( Y_i(0), Y_i(1) \\big) \\;\\perp\\!\\!\\!\\perp\\; D_i,\n\\]\nst osalemine ei sõltu potentsiaalsetest tulemustest.\nSellisel juhul\n\\[\n\\mathbb{E}[Y_i(0) \\mid D_i = 1] = \\mathbb{E}[Y_i(0) \\mid D_i = 0],\n\\]\n\\[\n\\mathbb{E}[Y_i(1) \\mid D_i = 1] = \\mathbb{E}[Y_i(1) \\mid D_i = 0],\n\\]\nja lihtne keskmiste erinevus annab ATE:\n\\[\n\\text{SDO} = \\mathbb{E}[Y_i \\mid D_i=1] - \\mathbb{E}[Y_i \\mid D_i=0] = \\text{ATE}.\n\\]\nMajanduses on see eeldus sageli ebarealistlik: inimesed otsustavad osaleda meetmes, pidades silmas oma eeldatavat kasu (enesevalik), ning meedet pakkuvad töötajad võivad „koort riisuda”, valides osalejateks motiveeritumaid või võimekamaid indiviide.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#tingimuslik-sõltumatus-cia-ja-sellega-seotud-eeldused",
    "href": "02-pohimoisted.html#tingimuslik-sõltumatus-cia-ja-sellega-seotud-eeldused",
    "title": "3  Põhimõisted",
    "section": "3.7 Tingimuslik sõltumatus (CIA) ja sellega seotud eeldused",
    "text": "3.7 Tingimuslik sõltumatus (CIA) ja sellega seotud eeldused\n\nTingimuslik sõltumatuse eeldus (CIA)\nTingimusliku sõltumatuse eeldus (conditional independence assumption, CIA) ütleb, et kui võtame arvesse jälgitavad tunnused (X), siis potentsiaalsed tulemused ei sõltu enam osalemisotsusest:\n\\[\n\\big( Y_i(0), Y_i(1) \\big) \\;\\perp\\!\\!\\!\\perp\\; D_i \\mid X_i.\n\\]\nSarnased terminid kirjanduses:\n\nunconfoundedness (Rosenbaum ja Rubin, 1983),\nselection on observables (Barnow jt, 1980),\nexogeneity (Imbens, 2004),\nignorability (Rubin, 1978).\n\nIntuitsioon: kui võtame arvesse piisavalt rikkalikku (X)-vektorit (nt sugu, vanus, haridus, varasem palgatase, tööstusharu jne), siis osalemisotsus on „nagu juhuslik” tingimuslikult (X)-le.\n\n\nTingimuslik keskväärtuse sõltumatus\nNõrgem versioon on tingimusliku keskväärtuse sõltumatuse eeldus:\n\\[\n\\mathbb{E}[ Y_i(0) \\mid D_i=1, X_i = x]\n= \\mathbb{E}[ Y_i(0) \\mid D_i=0, X_i = x],\n\\]\n\\[\n\\mathbb{E}[ Y_i(1) \\mid D_i=1, X_i = x]\n= \\mathbb{E}[ Y_i(1) \\mid D_i=0, X_i = x].\n\\]\nSee eeldab, et erinevused keskmistes potentsiaalsetes tulemustes kaovad, kui vaatleme piisavalt kitsaid (X)-alamrühmi, ehkki jaotuste kujud võivad erineda.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#ühine-tugi-common-support",
    "href": "02-pohimoisted.html#ühine-tugi-common-support",
    "title": "3  Põhimõisted",
    "section": "3.8 Ühine tugi (common support)",
    "text": "3.8 Ühine tugi (common support)\nCIA praktiline rakendamine nõuab ühist tuge:\n\\[\n0 &lt; \\Pr(D_i = 1 \\mid X_i = x) &lt; 1\n\\]\nkõigi huvipakkuvate (x) jaoks.\nIntuitsioon: iga (X)-väärtuse korral peavad olema nii osalejad kui mitteosalejad; ei tohi olla selliseid (X)-alasid, kus osalevad ainult ühte tüüpi indiviidid. Vastasel juhul ei saa nendes alamrühmades väärset võrdlust teha.\nPraktikas tähendab see, et ei tohi minna liiga detailsele tasemele väga paljude tunnuste ja kategooriatega, ning sageli kasutatakse pidevate tunnuste puhul intervalljaotust (nt sissetuleku kvantiilid).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#att-hindamine-cia-abil",
    "href": "02-pohimoisted.html#att-hindamine-cia-abil",
    "title": "3  Põhimõisted",
    "section": "3.9 ATT hindamine CIA abil",
    "text": "3.9 ATT hindamine CIA abil\nKui CIA ja ühine tugi kehtivad, saame ATT väljendada jälgitavate suuruste abil. Üks võimalus on kirjutada\n\\[\n\\text{ATT}\n= \\mathbb{E}_{X \\mid D=1}\n  \\Big[ \\mathbb{E}[Y_i \\mid D_i = 1, X_i]\n       - \\mathbb{E}[Y_i \\mid D_i = 0, X_i] \\Big].\n\\]\nIntuitsioon:\n\njagame andmed (K) rühma (X)-vektori alusel (nt mehed, vanuses 40–60, kõrgharidusega);\nigas rühmas võrdleme osalenute ja mitteosalenute keskmisi tulemusi;\nvõtame nende rühmakeskmiste erinevuste kaalutud keskmise, kus kaaludeks on osalenute osakaalud nendes rühmades.\n\nSee on mitteparametriline lähenemine; praktikas kasutatakse sagel ka:\n\nlogistilist regressiooni osalemise tõenäosuse hindamiseks ja propensity score matching’ut,\nregressioonimudeleid,\nkaalumismeetodeid (inverse probability weighting),\nvõi nende kombinatsioone.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#täiendavad-statistikud-itt-late-ja-cate",
    "href": "02-pohimoisted.html#täiendavad-statistikud-itt-late-ja-cate",
    "title": "3  Põhimõisted",
    "section": "3.10 Täiendavad statistikud: ITT, LATE ja CATE",
    "text": "3.10 Täiendavad statistikud: ITT, LATE ja CATE\n\nIntention to treat effect (ITT)\nSageli ei saa me kontrollida, kas indiviid tegelikult meetmes osales; kontrollime ainult, kas talle pakuti meedet. Olgu (Z_i) indikaator, kas indiviidile pakuti osalemist (nagu instrumentmuutuja).\nITT on\n\\[\n\\text{ITT} = \\mathbb{E}[Y_i \\mid Z_i = 1] - \\mathbb{E}[Y_i \\mid Z_i = 0].\n\\]\nSee mõõdab meetme pakkumise mõju, mitte tegeliku osalemise mõju ning võib olla oluline poliitika mõjude hindamisel, kus täitmine on ebatäielik.\n\n\nLokaalne keskmine mõju (LATE)\nInstrumentaalmuutujate raamistikus saame määratleda lokaalse keskmise mõju (local average treatment effect - LATE) indiviididele, kes muudavad oma osalemiskäitumist instrumentmuutuja muutumise tõttu (compliers):\n\\[\n\\text{LATE}\n= \\frac{\\mathbb{E}[Y_i \\mid Z_i = 1] - \\mathbb{E}[Y_i \\mid Z_i = 0]}\n       {\\mathbb{E}[D_i \\mid Z_i = 1] - \\mathbb{E}[D_i \\mid Z_i = 0]}.\n\\]\nLATE on keskmine mõju nende indiviidide jaoks, kes „on piiri peal” ning kelle osalemine sõltub instrumendist (näiteks seadusemuudatusest, kvoodist, loteriivõidust).\n\n\nTingimuslik keskmine mõju (CATE)\nKui mõju on heterogeenne, võib huvitada tingimuslik keskmine mõju teatud (X)-väärtuse korral:\n\\[\n\\text{CATE}(x)\n= \\mathbb{E}\\big[ Y_i(1) - Y_i(0) \\mid X_i = x \\big].\n\\]\nCATE võimaldab uurida näiteks:\n\nkuidas erineb tööturukoolituse mõju vanusegruppide lõikes;\nkuidas sõltub mõju varasemast palgatasemest;\nmillistele alarühmadele programm kõige rohkem kasu toob.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html#kokkuvõte",
    "href": "02-pohimoisted.html#kokkuvõte",
    "title": "3  Põhimõisted",
    "section": "3.11 Kokkuvõte",
    "text": "3.11 Kokkuvõte\nPotentsiaalse tulemuse mudel formaliseerib põhjusliku mõju mõiste, kirjeldades iga indiviidi jaoks kahte potentsiaalset tulemust (Y_i(0)) ja (Y_i(1)). Kuna reaalses elus näeme ainult üht neist, keskendume erinevatele keskmistele mõjudele (ATE, ATT, ATU, CATE, LATE, ITT) ja eeldustele, mille alusel neid saab hinnata.\nLihtne keskmiste erinevus osalenute ja mitteosalenute vahel on enamasti nihkes valikunihe ja heterogeense mõju tõttu. Selleks, et anda põhjuslik tõlgendus, on vaja tugevaid eeldusi (nt juhuslik eksperiment) või realistlikumaid tingimuslikke eeldusi (CIA, ühine tugi) koos sobivate meetoditega (sobitamine, regressioon, kaalud).\nPOM on kooskõlas ka teiste lähenemistega, näiteks DAG-id (suunatud asüklilised graafid), mis keskenduvad eelkõige identifitseerimisele. Praktikas kasutatakse sageli POM-i raamistikku koos graafiliste mudelitega, et selgelt sõnastada nii eeldused kui ka hinnatav põhjuslik mõju.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Põhimõisted</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html",
    "href": "03-regressioon.html",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "4.1 Mudeli seade\nPoolik - arenev\nVaatame mõju (nt meetmes osalemise \\(D\\) mõju tulemile \\(Y\\)) hindamise meetodeid, kasutades regressioonimudeleid ja eeldust tingimuslikust sõltumatusest (Conditional Independence Assumption, CIA).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#mudeli-seade",
    "href": "03-regressioon.html#mudeli-seade",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "Tingimusliku sõltumatuse eeldus (CIA)\nPõhjusliku mõju leidmiseks regressiooniga peab kehtima tingimusliku sõltumatuse eeldus (CIA - conditional independence assumption).\n\\[E[Y_0 | D=1, \\mathbf{X}] = E[Y_0 | D=0, \\mathbf{X}]\\]\nSee tähendab, et pärast kõigi oluliste segavate tegurite \\(\\mathbf{X}\\) (eelkõige \\(X \\rightarrow D\\) ja \\(X \\rightarrow Y\\)) arvesse võtmist ei ole potentsiaalsel tulemusel \\(Y_0\\) ja meetmes osalemisel \\(D\\) enam seost. Seega, tingimuslikult sarnased osalejad ja mitte-osalejad on võrreldavad.\n\n\nRegressioonimudelid mõju hindamiseks\nKui CIA kehtib ja eeldame aditiivset (lineaarset) mudelit, saame regressiooniga hinnata erinevaid keskmisi mõjusid.\n\nTavaline regressioonimudel (ATE hinnang)\nKõige lihtsam mudel eeldab, et mõju \\(\\delta\\) on homogeenne (sama kõigi \\(\\mathbf{X}\\) väärtuste korral) ja aditiivne.\n\\[Y_i = \\alpha + \\delta D_i + \\mathbf{X}_i \\beta + \\epsilon_i\\]\nVõi üldjuhul, kui on selgitavaid tegureid rohkem:\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\dots + \\epsilon_i\\)\nMõju hinnang: \\(\\hat{\\delta}\\) on hinnang ATE-le (Average Treatment Effect), st keskmisele mõjule kõigile.\n\n\n\nRegressioonimudel interaktsiooniga (heterogeenne mõju)\nKui on alust arvata, et meetme mõju \\(D\\) sõltub mõnest tunnusest \\(X_k\\) (st mõju on heterogeenne), lisatakse mudelisse interaktsiooniliige.\n\\[Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\mathbf{X}_i \\beta + \\epsilon_i\\]\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\beta_1 X_{1i} + \\dots + \\epsilon_i\\)\nMõju \\(X_{ki}\\) väärtusel: \\(\\text{Mõju} = \\hat{\\delta} + \\hat{\\gamma} X_{ki}\\).\nKasutamine: Seda mudelit kasutades saab hinnata CATE-t (Conditional Average Treatment Effect), st keskmist mõju alamrühmas, ja leida seejärel kaalutud keskmist leides ATE või ATT.\n\n\n\n\nKaks eraldi eegressioonimudelit (G-Computation)\nSee meetod hinnatakse regressioonimudeleid eraldi osalejate (\\(D=1\\)) ja mitte-osalejate (\\(D=0\\)) andmetel, mis võimaldab arvestada heterogeenset funktsionaalset seost \\(Y_0\\) ja \\(Y_1\\) vahel.\n\nMudel osalejatel (\\(D=1\\)): \\[Y_i = \\alpha_1 + \\mathbf{X}_i \\beta_1 + \\epsilon_{i1} \\quad \\text{kui } D_i=1\\] Prognoosime tulemuse \\(Y_{i1}\\) kõigile vaatlustele: \\(\\hat{Y}_{i1} = \\hat{\\alpha}_1 + \\mathbf{X}_i \\hat{\\beta}_1\\).\nMudel mitte-osalejatel (\\(D=0\\)):\n\n\\[Y_i = \\alpha_0 + \\mathbf{X}_i \\beta_0 + \\epsilon_{i0} \\quad \\text{kui } D_i=0\\]\nPrognoosime tulemuse \\(Y_{i0}\\) kõigile vaatlustele: \\(\\hat{Y}_{i0} = \\hat{\\alpha}_0 + \\mathbf{X}_i \\hat{\\beta}_0\\).\n\nMõju arvutamine (G-Computation): Mõju on igal isikul prognooside vahe: \\(\\hat{\\Delta}_i = \\hat{Y}_{i1} - \\hat{Y}_{i0}\\).\n\nATE (kogu populatsioon): \\(\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^N \\hat{\\Delta}_i\\)\nATT (meetmes osalejatele): \\(\\text{ATT} = \\frac{1}{N_T} \\sum_{i: D_i=1} \\hat{\\Delta}_i\\)\nATU (võrdlusrühmale): \\(\\text{ATU} = \\frac{1}{N_C} \\sum_{i: D_i=0} \\hat{\\Delta}_i\\)\n\n\nSee meetod on regressiooni mudeliga hindamise erijuht ja annab paindlikumad hinnangud, kuna võimaldab funktsionaalsel seosel \\(Y \\sim \\mathbf{X}\\) olla erinev osalejatel ja mitte-osalejatel.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#näide-tööpoliitikast",
    "href": "03-regressioon.html#näide-tööpoliitikast",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "4.2 Näide tööpoliitikast",
    "text": "4.2 Näide tööpoliitikast\nMe kasutame näidisandmetena Poliitikauuringute Keskuse Praxis 2002. aastal läbiviidud uuringut aktiivse tööpoliitika mõju hindamise kohta. (Vt Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 108 lk. Vt ka: Praxis töö ja Leetmaa & Võrk (2004))\nAnonümiseeritud andmestik asub failis:\nhttp://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\n\nMuutujate selgitused\n\n\n\n\n\n\n\nMuutuja\nSelgitus\n\n\n\n\ntraining\nReceived labour market training in 2000 / Tunnus kas sai tööturukoolitust või ei 2000. aasta esimeses pooles\n\n\nnwage\nNetopalk 2002. aasta septembris\n\n\nemployed\nEmployed in September 2002 / Hõivatus 2002. aasta septembris (1 – hõivatud, 0 – töötu või mitteaktiivne)\n\n\nstatus\nTööturustaatus 2002. aasta septembris (1 – hõivatud, 2 – töötu, 3 – mitteaktiivne)\n\n\nkaal\nSample weight / Vaatluse statistiline kaal\n\n\nmale\nmale / Meessoost\n\n\nest\nEstonian / Eestlane\n\n\nage\nVanus aastates 2002. aastal\n\n\nlangest\nKas oskab eesti keelt\n\n\nemplbefore\nKas oli töökogemus enne töötuks registreerimist 2000. aastal\n\n\neduc\nHaridustase: 1 – ISCED 0,1,2 (põhiharidus); 2 – ISCED 3 (keskharidus); 3 – ISCED 3,4 (kutsekeskharidus); 4 – ISCED 5,6 (kõrgharidus)\n\n\ncounty\nMaakond: Tallinn, Viljandimaa, Tartumaa, Ida-Virumaa\n\n\ntown\nElab linnas vs maal\n\n\nchildren\nLaste arv töötuks registreerimise hetkel\n\n\nmarital\nPerekonna seis töötuks registreerimise hetkel: 0 – vallaline; 1 – abielus; 2 – vabaabielu; 3 – lahutatud; 4 – lesk\n\n\ntraining1\nOsalusrühm tingimusel, et ei nõutud tõendit hilisema töö saamise kohta – kellelt nõuti, neil puuduv väärtus\n\n\ntraining2\nVõrdlusgrupp, kes soovisid, kuid ei saanud/soovinud osaleda mingil põhjusel\n\n\ntraining3\nKombinatsioon training2 ja training3: need osalusgrupist, kellelt ei nõutud töökohta; need võrdlusgrupist, kes uurisid koolitust, kuid ei osalenud\n\n\ntraining4\nKoolituse osalusrühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid\n\n\ntraining5\nKoolituse põhirühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid ja kellelt ei nõutud tõendit\n\n\n\n\n\nVajalikud paketid\n\nlibrary(dplyr)\nlibrary(stargazer)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(boot)\nlibrary(ggplot2)\n\n\n\nAndmestiku lugemine\n\natp &lt;- read.csv(\"http://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\")\n\n\n\nKirjeldav analüüs\nLeidke, mitu inimestest osales 2000. aastal koolituses ja mitu ei osalenud\n\ntable(atp$training)\n\n\n  0   1 \n878 429 \n\n\nKui suur osakaal koolituses osalejatest ja mitte-osalejatest töötas 2002. aasta septembris? Tabuleerige muutujad “training” ja “employed” ning leidke protsendid.\n\ntab &lt;- table(atp$training, atp$employed)\nprop.table(tab, margin = 1)\n\n   \n            0         1\n  0 0.4100228 0.5899772\n  1 0.2913753 0.7086247\n\n\nMilline oli keskmine palk koolituses osalejatel ja mitte-osalejatel 2002. aasta septembris?\n\natp %&gt;% group_by(training) %&gt;% summarise(mean_wage = mean(nwage, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  training mean_wage\n     &lt;int&gt;     &lt;dbl&gt;\n1        0     1678.\n2        1     2042.\n\n\n\n\nRegressioonimudel\nHinnake regressioonimudel, kus väljundid employed ja nwage sõltuvad ainult koolituses osalemisest.\n\nm1 &lt;- lm(employed ~ training, data = atp)\nm2 &lt;- lm(nwage ~ training, data = atp)\nstargazer(m1, m2, type = \"text\")\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                            employed                  nwage         \n                              (1)                      (2)          \n--------------------------------------------------------------------\ntraining                    0.119***               363.850***       \n                            (0.028)                 (119.754)       \n                                                                    \nConstant                    0.590***              1,677.766***      \n                            (0.016)                 (68.337)        \n                                                                    \n--------------------------------------------------------------------\nObservations                 1,307                    1,256         \nR2                           0.013                    0.007         \nAdjusted R2                  0.013                    0.007         \nResidual Std. Error    0.480 (df = 1305)      1,988.834 (df = 1254) \nF Statistic         17.591*** (df = 1; 1305) 9.231*** (df = 1; 1254)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nHinnake mudelid koos teiste selgitavate teguritega\n\natp$age2 &lt;- atp$age^2\nlin_employed &lt;- lm(employed ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_employed, vcov = vcovHC(lin_employed, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -0.15070176  0.15151587 -0.9946 0.3201030    \ntraining     0.09816437  0.02764834  3.5505 0.0003983 ***\nmale         0.07986481  0.02872120  2.7807 0.0055027 ** \nest          0.09711124  0.02694719  3.6038 0.0003255 ***\nage          0.02945808  0.00978750  3.0098 0.0026649 ** \nage2        -0.00040217  0.00012743 -3.1560 0.0016364 ** \neduc         0.05265150  0.01496051  3.5194 0.0004475 ***\nemplbefore   0.05064137  0.05218072  0.9705 0.3319782    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHinnake samasugune mudel ka palga kohta ja tõlgendage tulemusi.\n\nlin_nwage &lt;- lm(nwage ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_nwage, vcov = vcovHC(lin_nwage, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -1284.89226   687.88260 -1.8679   0.06201 .  \ntraining      254.84877   111.15732  2.2927   0.02203 *  \nmale          871.32268   138.00166  6.3139 3.775e-10 ***\nest           821.63833   127.20240  6.4593 1.504e-10 ***\nage            82.57500    43.00273  1.9202   0.05506 .  \nage2           -1.33722     0.53949 -2.4786   0.01332 *  \neduc          297.93783    61.36353  4.8553 1.354e-06 ***\nemplbefore    540.05556   220.40577  2.4503   0.01441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTõlgendage tulemusi!\nLubage võimalikku heteroskedastiivsust.\nLeiame robustsed standarvead.\n\nrobust_se1 &lt;- sqrt(diag(vcovHC(lin_employed, type = \"HC1\")))\nrobust_se2 &lt;- sqrt(diag(vcovHC(lin_nwage, type = \"HC1\")))\nstargazer(lin_employed, lin_nwage, se = list(robust_se1, robust_se2), type = \"text\", no.space = TRUE)\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                           employed                  nwage          \n                              (1)                     (2)           \n--------------------------------------------------------------------\ntraining                   0.098***                254.849**        \n                            (0.028)                (111.157)        \nmale                       0.080***                871.323***       \n                            (0.029)                (138.002)        \nest                        0.097***                821.638***       \n                            (0.027)                (127.202)        \nage                        0.029***                 82.575*         \n                            (0.010)                 (43.003)        \nage2                      -0.0004***                -1.337**        \n                           (0.0001)                 (0.539)         \neduc                       0.053***                297.938***       \n                            (0.015)                 (61.364)        \nemplbefore                   0.051                 540.056**        \n                            (0.052)                (220.406)        \nConstant                    -0.151                -1,284.892*       \n                            (0.152)                (687.883)        \n--------------------------------------------------------------------\nObservations                 1,307                   1,256          \nR2                           0.051                   0.109          \nAdjusted R2                  0.046                   0.104          \nResidual Std. Error    0.472 (df = 1299)     1,888.387 (df = 1248)  \nF Statistic         9.954*** (df = 7; 1299) 21.885*** (df = 7; 1248)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKas robustsete standardvigade kasutamine muudab statistilist parameetrite statistilist olulisust?\n\n\nEraldi mudelid osalejatele ja mitteosalejatele\n\nNäide - meetme mõju palgale vanuse lõikes\n\natpj &lt;- atp %&gt;% filter(!is.na(nwage)) %&gt;% \n  filter(nwage&lt;5000, nwage&gt;0)\n\nggplot(atpj,\n       aes(x = age, y = nwage, color = \"Palk\")) +\n  geom_point() +\n  geom_smooth(data = atpj %&gt;% filter(training ==1), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 1\")) +\n  geom_smooth(data = atpj %&gt;% filter(training ==0), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 0\")) +\n  scale_color_manual(name = \"\", values = c(\"Palk\" = \"grey\",\n                                           \"Prognoos, D = 1\" = \"blue\",\n                                           \"Prognoos, D = 0\" = \"green\")) +\n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Palk\", color = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\natpj$ate &lt;-\n  predict(lm(nwage ~ age, data=atpj[atpj$training==1,]), new=atpj) - \n           predict(lm(nwage ~ age, data=atpj[atpj$training==0,]), new=atpj)\n\nSee joonis näitab, kuidas vanus mõjutab palka kahes erinevas grupis (osalejad vs mitte-osalejad). Kasutame valemi \\(Y \\sim X\\) seost vanuse osas.\nMõju sõltub vanusest. Mida noorem, seda suurem efekt.\n\nggplot(atpj,\n       aes(x = age, y = ate)) +\n  geom_line() +\n  #geom_rug(sides = \"b\") +\n  #geom_histogram(aes(y = ..count..), \n  #               binwidth = 1, alpha = 0.9, fill = \"grey\", position = \"identity\") +\n  geom_histogram(aes(fill = as.factor(training), y = ..count..), \n                 binwidth = 1, alpha = 0.5, position = \"identity\") +  # Colored histogram by gender\n  scale_fill_manual(values = c(\"green\", \"blue\")) +\n  \n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Meetme mõju\", fill = \"Meetmes\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nLisame täiendavad selgitavad tunnused\nTöötamise jaoks\nHindame mudeli osalejate andmete põhjal ja prognoosime tulemused kõigile.\n\nlin_employed_ra1 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$pemployed_1 &lt;- predict(lin_employed_ra1, newdata = atp)\n\nHinnake samasugune mudel ka mitteosalejate põhjal  training==0 ja prognoosige tulemused kõigile\n\nlin_employed_ra0 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$pemployed_0 &lt;- predict(lin_employed_ra0, newdata = atp)\n\nLeiame individuaalsed erinevused prognoositud hinnangutes\n\natp$demployed &lt;- atp$pemployed_1 - atp$pemployed_0\n\nKeskmised mõjuhinnangud (ATE) ja eraldi ka osalejatele ning mitteosalejatele\n\nate_empl &lt;- mean(atp$demployed)\natt_empl &lt;- mean(atp$demployed[atp$training == 1])\natu_empl &lt;- mean(atp$demployed[atp$training == 0])\n\nate_empl\n\n[1] 0.1063243\n\natt_empl\n\n[1] 0.0926108\n\natu_empl\n\n[1] 0.1130248\n\n\nKas tulemused muutusid võrreldes ühise regressioonimudeliga?\nSama palgaga\n\nlin_nwage_ra1 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$nwage_1 &lt;- predict(lin_nwage_ra1, newdata = atp)\n\nlin_nwage_ra0 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$nwage_0 &lt;- predict(lin_nwage_ra0, newdata = atp)\n\natp$dnwage &lt;- atp$nwage_1 - atp$nwage_0\nate_nwage &lt;- mean(atp$dnwage)\natt_nwage &lt;- mean(atp$dnwage[atp$training == 1])\natu_nwage &lt;- mean(atp$dnwage[atp$training == 0])\n\nate_nwage\n\n[1] 259.2266\n\natt_nwage\n\n[1] 254.2755\n\natu_nwage\n\n[1] 261.6458\n\n\nKas koolituse mõju on suurem osalejatele või oleks olnud suurem mitte-osalejatele? Kas mõju on statistiliselt oluline?\n\n\n\nBootstrapping hinnangute standardvea leidmiseks - fännidele\nTeeme funktsiooni\n\nf &lt;- formula(employed ~ male + est + age + age2 + educ + emplbefore)\n\nmybs = function(data, indices, formula =f) {\n  dat = data[indices, ]\n  dify = predict(lm(formula, data = dat[dat$training == 1, ]), newdata = dat) -\n         predict(lm(formula, data = dat[dat$training == 0, ]), newdata = dat)\n  c(ate = mean(dify), att = mean(dify[dat$training == 1]))\n}\n\nja rakendame seda\n\nset.seed(1632)\nresults &lt;- boot(data = atp, statistic = mybs, R = 50, stype = \"i\")\nboot.ci(results)\n\nWarning in norm.inter(t, adj.alpha): extreme order statistics used as endpoints\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 50 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic             Studentized     \n95%   ( 0.0528,  0.1499 )   ( 0.0510,  0.1590 )   ( 0.0621,  0.1969 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.0536,  0.1617 )   ( 0.0503,  0.1415 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\nSome studentized intervals may be unstable\nSome percentile intervals may be unstable\nWarning : BCa Intervals used Extreme Quantiles\nSome BCa intervals may be unstable",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "04-difdif.html",
    "href": "04-difdif.html",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "",
    "text": "5.1 Mudeli seade\nPoolik - arenev\nJuurdekasvude erinevuse (DiD) meetod on üks populaarsemaid kvaasi-eksperimentaalseid meetodeid põhjusliku mõju hindamiseks. See eemaldab ajas muutumatud erinevused gruppide vahel ja ajas muutuvad tegurid, mis mõjutavad mõlemaid gruppe ühtemoodi.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#mudeli-seade",
    "href": "04-difdif.html#mudeli-seade",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "",
    "text": "Klassikaline 2x2 DiD disain\nKõige lihtsamal kujul on meil kaks rühma ja kaks ajahetke:\n\nGrupid (\\(D\\)):\n\n\\(D=1\\): Osalusrühm (Treatment), kes saab mingil hetkel sekkumise.\n\\(D=0\\): Võrdlusrühm (Control), kes sekkumist ei saa.\n\nAeg (\\(T\\)):\n\n\\(T=1\\): Pärast sekkumist (Post).\n\\(T=0\\): Enne sekkumist (Pre).\n\n\n\n\nDiD hinnang Valemina\nDiD hinnang (\\(\\hat{\\delta}_{DiD}\\)) leitakse kui erinevus osalejate ajas toimunud muutuse ja võrdlusrühma ajas toimunud muutuse vahel:\n\\[\n\\hat{\\delta}_{DiD} = \\underbrace{(\\bar{Y}_{T=1}^{D=1} - \\bar{Y}_{T=0}^{D=1})}_{\\text{Muutus osalejatel}} - \\underbrace{(\\bar{Y}_{T=1}^{D=0} - \\bar{Y}_{T=0}^{D=0})}_{\\text{Muutus võrdlusrühmal}}\n\\] Kus \\(\\bar{Y}_{T}^{D}\\) on tulemuse keskmine vastavas grupis ja ajahetkel.\n\n\nDiD Regressioonimudelina\nSeda sama hinnangut saab leida lineaarse regressioonimudeli abil, kasutades interaktsiooniliiget:\n\\[Y_{it} = \\alpha + \\beta_1 \\text{D}_i + \\beta_2 \\text{Post}_t + \\delta*(\\text{D}_i \\times \\text{Post}_t) + \\epsilon_{it}\n\\]\nKus:\n\n\\(\\alpha\\): Kontrollgrupi keskmine enne sekkumist (Constant).\n\\(\\beta_1\\): Gruppidevaheline püsiv erinevus (Treatment Group Effect).\n\\(\\beta_2\\): Ajaline trend, mis on ühine mõlemale grupile (Time Trend).\n** \\(\\delta_{DiD}\\) **: Põhjuslik mõju ehk huvipakkuv parameeter (ATT). See näitab lisandumist tulemuses, mis tekib ainult osalejatel pärast sekkumist.\n\n\n\nParalleelse trendi eeldus ja ATT\nDiD meetodi kehtivus sõltub paralleelse trendi eeldusest (Parallel trends assumption).\nEeldus väidab, et sekkumise puudumisel oleks osalusrühma keskmine tulemus muutunud ajas samamoodi nagu võrdlusrühmal.\nMatemaatiliselt (kasutades potentsiaalseid tulemusi \\(Y^0\\)):\n\\[\nE[Y^0_{t=1} - Y^0_{t=0} | D=1] = E[Y^0_{t=1} - Y^0_{t=0} | D=0]\n\\]\nKuidas see annab ATT?\nMeie eesmärk on leida keskmine mõju osalejatele (ATT - Average Treatment Effect on the Treated):\n\\[ATT = E[Y^1_{t=1} - Y^0_{t=1} | D=1] \\] Kuna \\(Y^0_{t=1}\\) (osalejate tulemus ilma sekkumiseta) ei ole vaadeldav, kasutame paralleelse trendi eeldust selle asendamiseks:\n\nTegelik muutus osalejatel: \\(E[Y^1_{t=1} | D=1] - E[Y^0_{t=0} | D=1]\\)\nMuutus kui sekkumist poleks: Eelduse kohaselt võrdne kontrollgrupi muutusega \\(E[Y^0_{t=1} | D=0] - E[Y^0_{t=0} | D=0]\\).\n\nSeega:\n\\[\nATT = (\\text{Osalusrühma muutus}) - (\\text{Võrdlusrühma muutus})\n\\]\n\n\nKahesuunaline fikseeritud effektide mudel (TWFE)\nTwo-way Fixed Effects model\nKui andmed on paneelkujul (sama objekti jälgitakse mitmel ajahetkel) või meil on palju objekte ja ajahetki, kasutatakse TWFE mudelit. See on 2x2 disaini üldistus.\n\\[\nY_{it} = \\alpha_i + \\gamma_t + \\delta D_{it} + \\mathbf{X}_{it}\\beta + \\epsilon_{it}\n\\]\nKus:\n\n\\(\\alpha_i\\) (Unit Fixed Effects): Ühiku-spetsiifiline fikseeritud efekt. See kontrollib kõiki tegureid, mis on ühikule \\(i\\) omased ja ajas ei muutu (nt asukoht, kultuur, geneetika). Asendab \\(\\text{Treat}_i\\) muutujat.\n\\(\\gamma_t\\) (Time Fixed Effects): Aja-spetsiifiline fikseeritud efekt. See kontrollib šokke, mis mõjutavad kõiki ühikuid antud aastal \\(t\\) ühtemoodi (nt majanduskriis, seadusemuudatused). Asendab \\(\\text{Post}_t\\) muutujat.\n\\(D_{it}\\) (Treatment Indicator): Binaarne muutuja, mis on 1, kui ühik \\(i\\) on ajal \\(t\\) sekkumise all.\n\\(\\delta\\): Hinnanguline ATT (eeldusel, et mõju on homogeenne).\n\n\n\nSündmuste uuring (Event study)\nSündmuste uuring (Event Study) on dünaamiline regressioonimudel, mis võimaldab hinnata meetme mõju muutumist ajas ning testida visuaalselt ja statistiliselt paralleelse trendi eeldust.\n\nRegressioonivalem\nÜldkuju Kahesuunalise Fikseeritud Efektide (TWFE) mudelina:\n\\[\nY_{it} = \\alpha_i + \\gamma_t + \\sum_{k=-K, k \\neq 0}^{L} \\beta_k \\cdot D_{it}^k + \\epsilon_{it}\n\\]\n\n\n\nMuutujate selgitus\n\n\\(Y_{it}\\): Tulemusmuutuja ühikule \\(i\\) ajahetkel \\(t\\).\n\\(\\alpha_i\\): Ühiku fikseeritud efekt (Unit Fixed Effects). Kontrollib ajas muutumatuid eripärasid (nt asukoht, kultuur).\n\\(\\gamma_t\\): Aja fikseeritud efekt (Time Fixed Effects). Kontrollib šokke, mis mõjutavad kõiki ühikuid samal ajal (nt majanduskriis, inflatsioon).\n\\(k\\): Suhteline aeg sündmuseni (\\(t - E_i\\), kus \\(E_i\\) on sündmuse toimumise aeg).\n\n\\(k &lt; 0\\): Perioodid enne meedet (Leads).\n\\(k \\ge 0\\): Perioodid pärast meedet (Lags).\n\n\\(D_{it}^k\\): Sündmuse indikaatorid (Event Time Dummies).\n\nMuutuja on 1, kui ühik \\(i\\) on ajahetkel \\(t\\) täpselt \\(k\\) perioodi kaugusel sündmusest.\nMuutuja on 0 muudel juhtudel.\n\n\\(\\beta_k\\): Huvipakkuvad koefitsiendid:\n\nKui \\(k &lt; 0\\) (Eel-periood): \\(\\beta_k\\) näitab erinevust töötlus- ja kontrollgrupi vahel enne meedet. See testib paralleelseid trende. Kui eeldus kehtib, peaksid need \\(\\beta\\)-d olema statistiliselt nullist eristamatud (nulljoone lähedal).\nKui \\(k \\ge 0\\) (Järel-periood): \\(\\beta_k\\) näitab meetme dünaamilist mõju \\(k\\) perioodi pärast sündmust.\n\n\\(k \\neq 0\\): Väljajäetud kategooria.\n\nTavaliselt jäetakse mudelist välja periood vahetult enne sündmust (\\(k = 0\\)), et vältida multikollineaarsust. Kõiki teisi koefitsiente (\\(\\beta_k\\)) tõlgendatakse selle baasperioodi suhtes. Eeldame, et perioodil 1 tekib esimest korda avatus meetmele.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#näide-tööpoliitikast",
    "href": "04-difdif.html#näide-tööpoliitikast",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.2 Näide tööpoliitikast",
    "text": "5.2 Näide tööpoliitikast\n\nlibrary(dplyr)\nlibrary(coefplot)\nlibrary(stargazer)\n\n\n#Muutke ära andmete kataloog\ndatapath = \"http://kodu.ut.ee/~avork/files/oppetoo/pohjustagajarg/\"\n\n#Lugege sisse andmefail\ndf &lt;- read.csv(file = paste0(datapath, \"adulttraining.csv\"))\ndfl &lt;- read.csv(file = paste0(datapath, \"adulttraininglong.csv\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#kirjeldav-statistiline-analüüs",
    "href": "04-difdif.html#kirjeldav-statistiline-analüüs",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.3 Kirjeldav statistiline analüüs",
    "text": "5.3 Kirjeldav statistiline analüüs\n\nstargazer(df, type = \"text\")\n\n\n=========================================================\nStatistic       N     Mean    St. Dev.    Min      Max   \n---------------------------------------------------------\nid            4,586 2,293.500 1,324.008    1      4,586  \nkoolituses    4,586   0.500     0.500      0        1    \npalk2008      4,586   6.063     5.537    0.000   24.959  \npalk2009      4,586   4.971     5.003    0.000   22.860  \npalk2010      4,586   4.509     4.872    0.000   21.768  \npalk2011      4,586   5.014     5.181    0.000   22.508  \npalk2012      4,586   5.737     5.764    0.000   25.584  \npalk2013      4,586   6.208     6.217    0.000   27.530  \nharidus       4,586   4.154     1.287      2        6    \nmees          4,586   0.573     0.495      0        1    \neestlane      4,586   0.657     0.475      0        1    \nvanus         4,586  39.831    11.892     16       73    \nkulu          2,293 3,334.167 1,461.837 331.320 6,624.000\nkoolitusaasta 4,586 1,005.240 1,005.350    0      2,011  \nseisund       4,586   1.463     0.749      1        3    \n---------------------------------------------------------\n\nstargazer(df %&gt;% filter(koolituses ==1), type = \"text\")\n\n\n=========================================================\nStatistic       N     Mean    St. Dev.    Min      Max   \n---------------------------------------------------------\nid            2,293 1,147.000  662.076     1      2,293  \nkoolituses    2,293   1.000     0.000      1        1    \npalk2008      2,293   6.399     5.412    0.000   24.959  \npalk2009      2,293   5.298     4.971    0.000   22.860  \npalk2010      2,293   4.736     4.817    0.000   21.768  \npalk2011      2,293   5.492     5.174    0.000   22.508  \npalk2012      2,293   6.339     5.758    0.000   25.584  \npalk2013      2,293   6.776     6.293    0.000   27.530  \nharidus       2,293   4.215     1.288      2        6    \nmees          2,293   0.604     0.489      0        1    \neestlane      2,293   0.652     0.476      0        1    \nvanus         2,293  39.310    11.719     17       73    \nkulu          2,293 3,334.167 1,461.837 331.320 6,624.000\nkoolitusaasta 2,293 2,010.481   0.500    2,010    2,011  \nseisund       2,293   1.578     0.846      1        3    \n---------------------------------------------------------\n\nstargazer(df %&gt;% filter(koolituses ==0), type = \"text\")\n\n\n===================================================\nStatistic       N     Mean    St. Dev.  Min   Max  \n---------------------------------------------------\nid            2,293 3,440.000 662.076  2,294 4,586 \nkoolituses    2,293   0.000    0.000     0     0   \npalk2008      2,293   5.726    5.640   0.000 24.959\npalk2009      2,293   4.644    5.014   0.000 22.860\npalk2010      2,293   4.282    4.918   0.000 21.768\npalk2011      2,293   4.536    5.146   0.000 22.508\npalk2012      2,293   5.135    5.708   0.000 25.584\npalk2013      2,293   5.640    6.088   0.000 27.530\nharidus       2,293   4.092    1.283     2     6   \nmees          2,293   0.543    0.498     0     1   \neestlane      2,293   0.662    0.473     0     1   \nvanus         2,293  40.353    12.042   16     64  \nkoolitusaasta 2,293   0.000    0.000     0     0   \nseisund       2,293   1.348    0.616     1     3   \n---------------------------------------------------\n\n\n\n#Gruppide võrdlus\nprop.table(table(\"Koolituses\" = df$koolituses, \"Mees\" = df$mees),1)\n\n          Mees\nKoolituses         0         1\n         0 0.4570432 0.5429568\n         1 0.3964239 0.6035761\n\n\nKeskmine vanus\n\ndf %&gt;% group_by(koolituses) %&gt;% \n  summarise(keskminevanus = mean(vanus))\n\n# A tibble: 2 × 2\n  koolituses keskminevanus\n       &lt;int&gt;         &lt;dbl&gt;\n1          0          40.4\n2          1          39.3\n\n\nPalk on tuhandetes eurodes\nMis on palga muutus osalusgrupis ja võrdlusgrupis? (Enne-pärast hinnang)\nVaatame 2008 vs 2013. Arvutame erinevuse.\n\ndf %&gt;% \n  group_by(koolituses) %&gt;% \n  summarise(palk2008 = mean(palk2008),\n            palk2013 = mean(palk2013))\n\n# A tibble: 2 × 3\n  koolituses palk2008 palk2013\n       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1          0     5.73     5.64\n2          1     6.40     6.78\n\n\nPalga muutus osalusgrupis\n\ntemp &lt;- df %&gt;% \n  group_by(koolituses) %&gt;% \n  summarise(palk2008 = mean(palk2008),\n            palk2013 = mean(palk2013)) %&gt;% \n  mutate(palgamuut = palk2013-palk2008)\n\n#Enne-pärast hinnang\ntemp\n\n# A tibble: 2 × 4\n  koolituses palk2008 palk2013 palgamuut\n       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1          0     5.73     5.64   -0.0865\n2          1     6.40     6.78    0.377 \n\n#Osalusgrupis\ntemp$palgamuut[2]\n\n[1] 0.3773767\n\ndifdif = temp$palgamuut[2] - temp$palgamuut[1]\ndifdif\n\n[1] 0.463845",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#joonis",
    "href": "04-difdif.html#joonis",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.4 Joonis",
    "text": "5.4 Joonis\n\n#Keskmised palgad osalus ja võrdlusrühmas\n\ntemp &lt;- dfl %&gt;% group_by(koolituses, aasta) %&gt;% \n  summarise(palk = mean(palk))\n\n`summarise()` has grouped output by 'koolituses'. You can override using the\n`.groups` argument.\n\ntemp\n\n# A tibble: 12 × 3\n# Groups:   koolituses [2]\n   koolituses aasta  palk\n        &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1          0  2008  5.73\n 2          0  2009  4.64\n 3          0  2010  4.28\n 4          0  2011  4.54\n 5          0  2012  5.14\n 6          0  2013  5.64\n 7          1  2008  6.40\n 8          1  2009  5.30\n 9          1  2010  4.74\n10          1  2011  5.49\n11          1  2012  6.34\n12          1  2013  6.78\n\n#Praksis tee rida haaval\n\nggplot(temp, aes(x = aasta, y = palk, color = factor(koolituses))) +\n  geom_rect(xmin = 2009.5, xmax = 2011.5, ymin = min(temp$palk)-0.5, ymax = max(temp$palk), fill = \"grey100\", \n            alpha = 0.1, color = \"steelblue\") +\n  geom_point() +\n  geom_line() +\n  geom_text(aes(label = round(palk,1)), vjust = -2, show.legend = FALSE) +\n  labs(color = \"\", x = \"\", y = \"tuh.eur\") + \n  theme_light()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#regressioonanalüüs",
    "href": "04-difdif.html#regressioonanalüüs",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.5 Regressioonanalüüs",
    "text": "5.5 Regressioonanalüüs\n2x2 disain\n\n#Jätame alles aastad\ndfls &lt;- dfl   %&gt;% \n  filter(aasta == 2008 | aasta ==2013) %&gt;% \n  mutate(aasta = as.factor(aasta))\n\nmudel &lt;- lm(data = dfls, formula = palk ~ koolituses + aasta + koolituses*aasta)\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta, \n    data = dfls)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.776 -5.279 -1.159  3.224 21.890 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           5.72637    0.12256  46.724  &lt; 2e-16 ***\nkoolituses            0.67266    0.17332   3.881 0.000105 ***\naasta2013            -0.08647    0.17332  -0.499 0.617872    \nkoolituses:aasta2013  0.46385    0.24512   1.892 0.058476 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.869 on 9168 degrees of freedom\nMultiple R-squared:  0.006445,  Adjusted R-squared:  0.006119 \nF-statistic: 19.82 on 3 and 9168 DF,  p-value: 8.386e-13\n\n#Võrrelge nüüd 2009 ja 2012 andmetega\ndfls &lt;- dfl %&gt;% \n  filter(aasta ==2009 | aasta ==2012) %&gt;% \n  mutate(aasta = as.factor(aasta))\n\nmudel &lt;- lm(data = dfls, formula = palk ~ koolituses + aasta + koolituses*aasta)\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta, \n    data = dfls)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.339 -4.644 -1.134  2.971 20.449 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            4.6441     0.1123  41.369  &lt; 2e-16 ***\nkoolituses             0.6534     0.1588   4.116 3.89e-05 ***\naasta2012              0.4910     0.1588   3.092  0.00199 ** \nkoolituses:aasta2012   0.5504     0.2245   2.451  0.01425 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.376 on 9168 degrees of freedom\nMultiple R-squared:  0.01303,   Adjusted R-squared:  0.01271 \nF-statistic: 40.34 on 3 and 9168 DF,  p-value: &lt; 2.2e-16\n\n#Lisame mudelisse muud tegurid\n\n#Andmestik uuesti\ndifdif1 &lt;- dfl %&gt;% \n  filter(aasta == 2008 | aasta ==2013) %&gt;% \n  mutate(aasta = as.factor(aasta)\n         )\n\n#Ja mudel\nmudel &lt;- lm(data = difdif1, formula = palk ~ koolituses + aasta + \n              koolituses*aasta + mees + eestlane + factor(haridus) + vanusgr + factor(seisund))\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta + \n    mees + eestlane + factor(haridus) + vanusgr + factor(seisund), \n    data = difdif1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4026  -3.6984  -0.5935   2.8292  20.9597 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           2.63883    0.26268  10.046  &lt; 2e-16 ***\nkoolituses            0.49975    0.16041   3.115 0.001842 ** \naasta2013            -0.08647    0.15749  -0.549 0.582981    \nmees                  2.39451    0.11512  20.799  &lt; 2e-16 ***\neestlane              0.30816    0.11864   2.597 0.009408 ** \nfactor(haridus)3      0.58185    0.20738   2.806 0.005032 ** \nfactor(haridus)4      0.68067    0.19926   3.416 0.000638 ***\nfactor(haridus)5      1.52820    0.21882   6.984 3.07e-12 ***\nfactor(haridus)6      2.92520    0.21333  13.712  &lt; 2e-16 ***\nvanusgr(25,35]        1.84815    0.18750   9.857  &lt; 2e-16 ***\nvanusgr(35,45]        2.25874    0.18872  11.969  &lt; 2e-16 ***\nvanusgr(45,55]        1.32949    0.19052   6.978 3.20e-12 ***\nvanusgr(55,100]       0.88350    0.22516   3.924 8.78e-05 ***\nfactor(seisund)2     -4.03936    0.16201 -24.933  &lt; 2e-16 ***\nfactor(seisund)3     -2.85658    0.16182 -17.652  &lt; 2e-16 ***\nkoolituses:aasta2013  0.46385    0.22272   2.083 0.037310 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.332 on 9156 degrees of freedom\nMultiple R-squared:  0.1808,    Adjusted R-squared:  0.1795 \nF-statistic: 134.7 on 15 and 9156 DF,  p-value: &lt; 2.2e-16\n\nmudel &lt;- lm(data = difdif1, formula = palk ~ koolituses + aasta + \n              koolituses*aasta + mees + eestlane + factor(haridus) + vanusgr)\n\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta + \n    mees + eestlane + factor(haridus) + vanusgr, data = difdif1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.0784  -4.2239  -0.5918   3.1125  22.1705 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.62852    0.26374   2.383 0.017185 *  \nkoolituses            0.35621    0.16480   2.162 0.030678 *  \naasta2013            -0.08647    0.16424  -0.526 0.598564    \nmees                  2.61807    0.11978  21.858  &lt; 2e-16 ***\neestlane              0.57926    0.12310   4.705 2.57e-06 ***\nfactor(haridus)3      0.80047    0.21600   3.706 0.000212 ***\nfactor(haridus)4      1.07191    0.20718   5.174 2.34e-07 ***\nfactor(haridus)5      1.94470    0.22746   8.550  &lt; 2e-16 ***\nfactor(haridus)6      3.63372    0.22061  16.471  &lt; 2e-16 ***\nvanusgr(25,35]        2.29960    0.19483  11.803  &lt; 2e-16 ***\nvanusgr(35,45]        2.88528    0.19538  14.768  &lt; 2e-16 ***\nvanusgr(45,55]        1.65069    0.19804   8.335  &lt; 2e-16 ***\nvanusgr(55,100]       0.80390    0.23462   3.426 0.000614 ***\nkoolituses:aasta2013  0.46385    0.23227   1.997 0.045850 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.561 on 9158 degrees of freedom\nMultiple R-squared:  0.1089,    Adjusted R-squared:  0.1076 \nF-statistic: 86.05 on 13 and 9158 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n#Leiame erinevuse koolituse aastast. \n# Kõigile koolituses mitteosalejatele paneme selle nulliks\n\ndfl &lt;- dfl %&gt;%  \n  mutate(aegkoolitusest = ifelse(koolituses ==1, \n                                 aasta - koolitusaasta,\n                                 0))\n\n#Joonise jaoks teeme selle faktoriks, et võrdlusrühm oleks null\ndfl &lt;- dfl %&gt;% \n  mutate(aegkoolitusest = factor(aegkoolitusest, levels = c(0, -3:-1, 1:3)))\n\ntable(dfl$aegkoolitusest)\n\n\n    0    -3    -2    -1     1     2     3 \n16051  1102  2293  2293  2293  2293  1191 \n\n#Time event model\n\nmudel &lt;- lm(data = dfl, formula = palk ~ aegkoolitusest + mees + \n              eestlane + factor(haridus) + vanusgr + factor(aasta) + factor(seisund))\n\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta) + factor(seisund), data = dfl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.1467  -3.1984  -0.5901   2.4896  21.2495 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        3.33072    0.15536  21.439  &lt; 2e-16 ***\naegkoolitusest-3   0.61845    0.17385   3.557 0.000375 ***\naegkoolitusest-2   0.67030    0.12333   5.435 5.53e-08 ***\naegkoolitusest-1   0.51922    0.11952   4.344 1.40e-05 ***\naegkoolitusest1    0.86321    0.11950   7.224 5.19e-13 ***\naegkoolitusest2    1.10103    0.12305   8.948  &lt; 2e-16 ***\naegkoolitusest3    1.22460    0.16875   7.257 4.07e-13 ***\nmees               1.99551    0.06044  33.015  &lt; 2e-16 ***\neestlane           0.31287    0.06232   5.020 5.20e-07 ***\nfactor(haridus)3   0.64890    0.10894   5.957 2.61e-09 ***\nfactor(haridus)4   0.74425    0.10466   7.111 1.18e-12 ***\nfactor(haridus)5   1.54188    0.11492  13.417  &lt; 2e-16 ***\nfactor(haridus)6   2.65592    0.11204  23.704  &lt; 2e-16 ***\nvanusgr(25,35]     1.37220    0.09848  13.933  &lt; 2e-16 ***\nvanusgr(35,45]     1.74154    0.09913  17.567  &lt; 2e-16 ***\nvanusgr(45,55]     0.96528    0.10008   9.645  &lt; 2e-16 ***\nvanusgr(55,100]    0.63932    0.11826   5.406 6.50e-08 ***\nfactor(aasta)2009 -1.06512    0.11343  -9.390  &lt; 2e-16 ***\nfactor(aasta)2010 -1.35564    0.11863 -11.427  &lt; 2e-16 ***\nfactor(aasta)2011 -0.95030    0.12090  -7.860 3.98e-15 ***\nfactor(aasta)2012 -0.49641    0.12559  -3.953 7.75e-05 ***\nfactor(aasta)2013 -0.11446    0.13047  -0.877 0.380319    \nfactor(seisund)2  -4.37419    0.08505 -51.433  &lt; 2e-16 ***\nfactor(seisund)3  -3.51146    0.08458 -41.518  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.852 on 27492 degrees of freedom\nMultiple R-squared:  0.2179,    Adjusted R-squared:  0.2173 \nF-statistic: 333.1 on 23 and 27492 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel, intercept = FALSE)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\nLisame mineviku palga enne koolitust sisse ja vaatame muutust võrreldes 2008 aasta palgaga\n\ndfl &lt;- dfl %&gt;% \n  group_by(id) %&gt;% \n  mutate(palk2008 = palk[aasta==2008]) %&gt;% \n  mutate(dpalk2008 = palk - palk2008) %&gt;% \n  ungroup()\n\nmudel2 &lt;- lm(data = dfl, formula = dpalk2008 ~ aegkoolitusest + mees + \n              eestlane + factor(haridus) + vanusgr + factor(aasta) + factor(seisund))\n\nsummary(mudel2)\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta) + factor(seisund), data = dfl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.5388  -1.2891   0.2704   1.6983  25.3013 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.34683    0.12829  18.293  &lt; 2e-16 ***\naegkoolitusest-3   0.25237    0.14356   1.758 0.078759 .  \naegkoolitusest-2   0.24246    0.10184   2.381 0.017289 *  \naegkoolitusest-1   0.14363    0.09869   1.455 0.145587    \naegkoolitusest1    0.48287    0.09867   4.894 9.96e-07 ***\naegkoolitusest2    0.64464    0.10161   6.345 2.27e-10 ***\naegkoolitusest3    0.69184    0.13935   4.965 6.92e-07 ***\nmees              -0.51370    0.04991 -10.292  &lt; 2e-16 ***\neestlane          -0.18885    0.05146  -3.669 0.000244 ***\nfactor(haridus)3  -0.01539    0.08996  -0.171 0.864121    \nfactor(haridus)4  -0.06219    0.08642  -0.720 0.471801    \nfactor(haridus)5   0.03194    0.09490   0.337 0.736445    \nfactor(haridus)6  -0.36442    0.09252  -3.939 8.21e-05 ***\nvanusgr(25,35]    -1.48122    0.08132 -18.214  &lt; 2e-16 ***\nvanusgr(35,45]    -1.85345    0.08186 -22.641  &lt; 2e-16 ***\nvanusgr(45,55]    -1.93637    0.08264 -23.430  &lt; 2e-16 ***\nvanusgr(55,100]   -2.42367    0.09765 -24.819  &lt; 2e-16 ***\nfactor(aasta)2009 -1.06384    0.09367 -11.358  &lt; 2e-16 ***\nfactor(aasta)2010 -1.46447    0.09796 -14.950  &lt; 2e-16 ***\nfactor(aasta)2011 -1.05061    0.09984 -10.523  &lt; 2e-16 ***\nfactor(aasta)2012 -0.48558    0.10371  -4.682 2.85e-06 ***\nfactor(aasta)2013 -0.06551    0.10773  -0.608 0.543116    \nfactor(seisund)2  -0.91739    0.07023 -13.063  &lt; 2e-16 ***\nfactor(seisund)3  -1.53353    0.06984 -21.958  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.006 on 27492 degrees of freedom\nMultiple R-squared:  0.07153,   Adjusted R-squared:  0.07075 \nF-statistic: 92.08 on 23 and 27492 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel2, intercept = FALSE)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\nTeeme mudeli eraldi töötavate, töötute ja mitteaktiivsete jaoks.\n\nlibrary(broom)\n\nresults &lt;- dfl %&gt;%\n  group_by(seisund) %&gt;%\n  group_modify(~ broom::tidy(\n    lm(dpalk2008 ~ aegkoolitusest + mees + eestlane +\n         factor(haridus) + vanusgr + factor(aasta),\n       data = .x)\n  ))\nresults\n\n# A tibble: 66 × 6\n# Groups:   seisund [3]\n   seisund term             estimate std.error statistic  p.value\n     &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1       1 (Intercept)        2.03      0.162     12.6   5.05e-36\n 2       1 aegkoolitusest-3   0.0686    0.181      0.379 7.04e- 1\n 3       1 aegkoolitusest-2   0.251     0.125      2.00  4.54e- 2\n 4       1 aegkoolitusest-1   0.267     0.122      2.19  2.88e- 2\n 5       1 aegkoolitusest1    0.558     0.122      4.56  5.05e- 6\n 6       1 aegkoolitusest2    0.544     0.125      4.35  1.35e- 5\n 7       1 aegkoolitusest3    0.258     0.170      1.52  1.28e- 1\n 8       1 mees              -0.418     0.0615    -6.80  1.05e-11\n 9       1 eestlane          -0.281     0.0640    -4.40  1.10e- 5\n10       1 factor(haridus)3   0.220     0.118      1.86  6.26e- 2\n# ℹ 56 more rows\n\n\nVõi\n\ndfl &lt;- dfl %&gt;% \n  mutate(seisundtext = case_when(\n    seisund == 1 ~ \"Töötab\",\n    seisund == 2 ~ \"Mitteaktiivne\",\n    seisund == 3 ~ \"Töötu\"))\n    \ntable(dfl$seisund, dfl$seisundtext)\n\n   \n    Mitteaktiivne Töötab Töötu\n  1             0  19068     0\n  2          4152      0     0\n  3             0      0  4296\n\nmodels &lt;- lapply(split(dfl, dfl$seisundtext), function(df) {\n  \n  lm(dpalk2008 ~ aegkoolitusest + mees + eestlane +\n       factor(haridus) + vanusgr + factor(aasta),\n     data = df)\n  \n})\n\nsummary(models[[1]])  # results for seisund = 1\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.8540  -0.9882   0.4606   1.6002  21.8434 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        1.45382    0.24216   6.004 2.10e-09 ***\naegkoolitusest-3  -0.06414    0.35509  -0.181  0.85667    \naegkoolitusest-2  -0.41936    0.24689  -1.699  0.08948 .  \naegkoolitusest-1  -0.58676    0.24370  -2.408  0.01610 *  \naegkoolitusest1    0.60835    0.24370   2.496  0.01259 *  \naegkoolitusest2    1.39161    0.24663   5.643 1.79e-08 ***\naegkoolitusest3    1.67315    0.33804   4.949 7.74e-07 ***\nmees              -0.53755    0.11044  -4.867 1.17e-06 ***\neestlane           0.22079    0.11093   1.990  0.04661 *  \nfactor(haridus)3  -0.46576    0.17386  -2.679  0.00741 ** \nfactor(haridus)4  -0.08594    0.17345  -0.495  0.62028    \nfactor(haridus)5  -0.28684    0.19251  -1.490  0.13630    \nfactor(haridus)6  -0.48029    0.19660  -2.443  0.01461 *  \nvanusgr(25,35]    -1.06025    0.16224  -6.535 7.14e-11 ***\nvanusgr(35,45]    -1.09392    0.17827  -6.136 9.23e-10 ***\nvanusgr(45,55]    -0.87006    0.16862  -5.160 2.59e-07 ***\nvanusgr(55,100]   -1.82290    0.16634 -10.959  &lt; 2e-16 ***\nfactor(aasta)2009 -0.96318    0.19760  -4.874 1.13e-06 ***\nfactor(aasta)2010 -1.86286    0.20271  -9.190  &lt; 2e-16 ***\nfactor(aasta)2011 -2.07730    0.20495 -10.136  &lt; 2e-16 ***\nfactor(aasta)2012 -1.69572    0.20979  -8.083 8.24e-16 ***\nfactor(aasta)2013 -1.24303    0.21512  -5.778 8.10e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.41 on 4130 degrees of freedom\nMultiple R-squared:  0.08617,   Adjusted R-squared:  0.08152 \nF-statistic: 18.55 on 21 and 4130 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[2]])  # results for seisund = 2\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.6139  -1.3406   0.2502   1.5351  25.2833 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.03160    0.16179  12.557  &lt; 2e-16 ***\naegkoolitusest-3   0.06861    0.18086   0.379 0.704415    \naegkoolitusest-2   0.25106    0.12547   2.001 0.045407 *  \naegkoolitusest-1   0.26715    0.12220   2.186 0.028815 *  \naegkoolitusest1    0.55766    0.12219   4.564 5.05e-06 ***\naegkoolitusest2    0.54447    0.12510   4.352 1.35e-05 ***\naegkoolitusest3    0.25842    0.16963   1.523 0.127666    \nmees              -0.41810    0.06146  -6.803 1.05e-11 ***\neestlane          -0.28148    0.06399  -4.399 1.10e-05 ***\nfactor(haridus)3   0.21979    0.11802   1.862 0.062574 .  \nfactor(haridus)4   0.03033    0.11240   0.270 0.787312    \nfactor(haridus)5   0.14695    0.12205   1.204 0.228631    \nfactor(haridus)6  -0.10041    0.11735  -0.856 0.392179    \nvanusgr(25,35]    -1.67483    0.10387 -16.124  &lt; 2e-16 ***\nvanusgr(35,45]    -1.94220    0.10325 -18.810  &lt; 2e-16 ***\nvanusgr(45,55]    -2.13732    0.10668 -20.034  &lt; 2e-16 ***\nvanusgr(55,100]   -2.39087    0.12881 -18.561  &lt; 2e-16 ***\nfactor(aasta)2009 -1.07584    0.11400  -9.437  &lt; 2e-16 ***\nfactor(aasta)2010 -1.12759    0.11833  -9.529  &lt; 2e-16 ***\nfactor(aasta)2011 -0.52076    0.12103  -4.303 1.70e-05 ***\nfactor(aasta)2012 -0.01717    0.12514  -0.137 0.890873    \nfactor(aasta)2013  0.43029    0.12966   3.319 0.000906 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.083 on 19046 degrees of freedom\nMultiple R-squared:  0.05172,   Adjusted R-squared:  0.05067 \nF-statistic: 49.47 on 21 and 19046 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[3]])\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.3129  -1.6260   0.3084   2.1003  23.6084 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.5419     0.3245   7.833 5.99e-15 ***\naegkoolitusest-3    0.2090     0.3399   0.615  0.53859    \naegkoolitusest-2    0.2158     0.2577   0.837  0.40240    \naegkoolitusest-1    0.3005     0.2340   1.284  0.19913    \naegkoolitusest1     0.3839     0.2344   1.638  0.10157    \naegkoolitusest2     0.7346     0.2610   2.815  0.00491 ** \naegkoolitusest3     1.7024     0.3605   4.722 2.40e-06 ***\nmees               -0.9696     0.1268  -7.645 2.56e-14 ***\neestlane           -0.2064     0.1268  -1.627  0.10374    \nfactor(haridus)3   -0.1022     0.2069  -0.494  0.62130    \nfactor(haridus)4   -0.1554     0.1970  -0.789  0.43029    \nfactor(haridus)5    0.2983     0.2251   1.325  0.18516    \nfactor(haridus)6   -1.1627     0.2323  -5.006 5.78e-07 ***\nvanusgr(25,35]     -1.2890     0.2022  -6.373 2.04e-10 ***\nvanusgr(35,45]     -2.4755     0.2046 -12.099  &lt; 2e-16 ***\nvanusgr(45,55]     -2.3052     0.1961 -11.756  &lt; 2e-16 ***\nvanusgr(55,100]    -3.5651     0.2628 -13.565  &lt; 2e-16 ***\nfactor(aasta)2009  -1.4256     0.2598  -5.487 4.33e-08 ***\nfactor(aasta)2010  -3.0061     0.2897 -10.375  &lt; 2e-16 ***\nfactor(aasta)2011  -2.8486     0.3003  -9.485  &lt; 2e-16 ***\nfactor(aasta)2012  -1.8581     0.3274  -5.676 1.47e-08 ***\nfactor(aasta)2013  -1.5700     0.3506  -4.478 7.71e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.029 on 4274 degrees of freedom\nMultiple R-squared:  0.1415,    Adjusted R-squared:  0.1373 \nF-statistic: 33.55 on 21 and 4274 DF,  p-value: &lt; 2.2e-16\n\nmultiplot(models) + theme_light() + labs(color = \"Rühm\")\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\n\nmodels &lt;- lapply(split(dfl, dfl$seisundtext), function(df) {\n  \n  lm(palk2008 ~ aegkoolitusest + mees + eestlane +\n       factor(haridus) + vanusgr + factor(aasta),\n     data = df)\n  \n})\n\nsummary(models[[1]])  # results for seisund = 1\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.622 -2.564 -1.081  1.558 20.586 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.08828    0.26678   0.331  0.74073    \naegkoolitusest-3   1.05772    0.39120   2.704  0.00688 ** \naegkoolitusest-2   0.71123    0.27199   2.615  0.00896 ** \naegkoolitusest-1   0.60972    0.26848   2.271  0.02320 *  \naegkoolitusest1    0.60144    0.26848   2.240  0.02514 *  \naegkoolitusest2    0.63325    0.27171   2.331  0.01982 *  \naegkoolitusest3    0.33148    0.37242   0.890  0.37348    \nmees               0.88861    0.12167   7.303 3.35e-13 ***\neestlane          -0.14686    0.12221  -1.202  0.22952    \nfactor(haridus)3   0.91963    0.19153   4.801 1.63e-06 ***\nfactor(haridus)4   0.51133    0.19109   2.676  0.00748 ** \nfactor(haridus)5   0.82674    0.21208   3.898 9.84e-05 ***\nfactor(haridus)6   1.96305    0.21660   9.063  &lt; 2e-16 ***\nvanusgr(25,35]     2.06524    0.17874  11.554  &lt; 2e-16 ***\nvanusgr(35,45]     1.49076    0.19640   7.591 3.91e-14 ***\nvanusgr(45,55]     0.81097    0.18577   4.365 1.30e-05 ***\nvanusgr(55,100]    1.88562    0.18325  10.290  &lt; 2e-16 ***\nfactor(aasta)2009  0.07600    0.21769   0.349  0.72700    \nfactor(aasta)2010  0.20639    0.22332   0.924  0.35545    \nfactor(aasta)2011  0.19472    0.22579   0.862  0.38853    \nfactor(aasta)2012  0.08971    0.23113   0.388  0.69795    \nfactor(aasta)2013  0.14072    0.23699   0.594  0.55270    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.757 on 4130 degrees of freedom\nMultiple R-squared:  0.0829,    Adjusted R-squared:  0.07824 \nF-statistic: 17.78 on 21 and 4130 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[2]])  # results for seisund = 2\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4843  -3.6930  -0.3336   2.7044  17.8494 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.087931   0.207368   0.424 0.671547    \naegkoolitusest-3   0.222973   0.231812   0.962 0.336128    \naegkoolitusest-2   0.300380   0.160813   1.868 0.061794 .  \naegkoolitusest-1   0.270490   0.156622   1.727 0.084179 .  \naegkoolitusest1    0.275049   0.156615   1.756 0.079068 .  \naegkoolitusest2    0.329830   0.160344   2.057 0.039698 *  \naegkoolitusest3    0.408656   0.217418   1.880 0.060180 .  \nmees               3.015865   0.078770  38.287  &lt; 2e-16 ***\neestlane           0.534474   0.082020   6.516 7.38e-11 ***\nfactor(haridus)3   0.498829   0.151267   3.298 0.000977 ***\nfactor(haridus)4   0.862890   0.144061   5.990 2.14e-09 ***\nfactor(haridus)5   1.675925   0.156439  10.713  &lt; 2e-16 ***\nfactor(haridus)6   3.103365   0.150405  20.633  &lt; 2e-16 ***\nvanusgr(25,35]     3.434511   0.133134  25.797  &lt; 2e-16 ***\nvanusgr(35,45]     4.404769   0.132337  33.284  &lt; 2e-16 ***\nvanusgr(45,55]     3.637899   0.136737  26.605  &lt; 2e-16 ***\nvanusgr(55,100]    3.610856   0.165102  21.871  &lt; 2e-16 ***\nfactor(aasta)2009 -0.009002   0.146118  -0.062 0.950874    \nfactor(aasta)2010  0.067422   0.151660   0.445 0.656641    \nfactor(aasta)2011  0.054753   0.155122   0.353 0.724119    \nfactor(aasta)2012 -0.018875   0.160395  -0.118 0.906324    \nfactor(aasta)2013 -0.051106   0.166187  -0.308 0.758452    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.233 on 19046 degrees of freedom\nMultiple R-squared:  0.1409,    Adjusted R-squared:  0.1399 \nF-statistic: 148.7 on 21 and 19046 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[3]])\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.3960 -3.0622 -0.5514  2.1596 20.4849 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -0.93264    0.36192  -2.577 0.010001 *  \naegkoolitusest-3   0.64064    0.37908   1.690 0.091102 .  \naegkoolitusest-2   0.80822    0.28736   2.813 0.004938 ** \naegkoolitusest-1   0.65959    0.26098   2.527 0.011528 *  \naegkoolitusest1    0.72961    0.26143   2.791 0.005280 ** \naegkoolitusest2    1.04000    0.29109   3.573 0.000357 ***\naegkoolitusest3    1.33796    0.40203   3.328 0.000882 ***\nmees               2.06985    0.14143  14.635  &lt; 2e-16 ***\neestlane           0.84338    0.14143   5.963 2.67e-09 ***\nfactor(haridus)3   0.88077    0.23071   3.818 0.000137 ***\nfactor(haridus)4   0.73807    0.21967   3.360 0.000786 ***\nfactor(haridus)5   1.09255    0.25105   4.352 1.38e-05 ***\nfactor(haridus)6   3.31594    0.25903  12.801  &lt; 2e-16 ***\nvanusgr(25,35]     2.12557    0.22555   9.424  &lt; 2e-16 ***\nvanusgr(35,45]     2.81844    0.22818  12.352  &lt; 2e-16 ***\nvanusgr(45,55]     2.92538    0.21868  13.377  &lt; 2e-16 ***\nvanusgr(55,100]    3.68956    0.29309  12.588  &lt; 2e-16 ***\nfactor(aasta)2009 -0.02063    0.28976  -0.071 0.943247    \nfactor(aasta)2010  0.26294    0.32312   0.814 0.415823    \nfactor(aasta)2011  0.29567    0.33493   0.883 0.377403    \nfactor(aasta)2012 -0.11509    0.36508  -0.315 0.752582    \nfactor(aasta)2013 -0.34545    0.39095  -0.884 0.376948    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.493 on 4274 degrees of freedom\nMultiple R-squared:  0.1462,    Adjusted R-squared:  0.142 \nF-statistic: 34.86 on 21 and 4274 DF,  p-value: &lt; 2.2e-16\n\nmultiplot(models) + theme_light() + labs(color = \"Rühm\")\n\n`height` was translated to `width`.\n`height` was translated to `width`.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "05-rdd.html",
    "href": "05-rdd.html",
    "title": "6  Regressiooni katkemise meetod",
    "section": "",
    "text": "6.1 Mudeli seade\nPoolik - arenev\nRegressiooni katkemise disain (Regression Discontinuity Design, RDD) on kvaasieksperimentaalne meetod põhjusliku mõju hindamiseks, kui osalemine programmis või meetmes sõltub mõnest pidevast tunnusest (nt vanus, sissetulek, hinne) ja selgelt määratletud lõikepunktist.:contentReferenceoaicite:0\nTüüpilised näited:\nOluline mõte: me ei saa leida täpselt samasugust osalus- ja võrdlusrühma (puudub ühine tugi, common support), kuid saame võrrelda väga lähedal lõikepunktile olevaid isikuid: nt 64 vs 65 aastat, hinne 4,4 vs 4,6.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#mudeli-seade",
    "href": "05-rdd.html#mudeli-seade",
    "title": "6  Regressiooni katkemise meetod",
    "section": "",
    "text": "pensioniõigus alates vanusest 63 või 65\n\ntasuta hambaravi kuni 19. eluaastani\n\ntoetus, kui käive langeb rohkem kui 30%\n\nstipendium, kui hinne ületab 4,5\n\n\n\nTähistused\nOlgu:\n\n\\((Y_i(1)\\) – isiku \\(i\\) potentsiaalne tulemus, kui ta osaleb programmis (D=1)\n\n\\((Y_i(0)\\) – potentsiaalne tulemus, kui ta ei osale (D=0)\n\n\\(D_i \\in \\{0,1\\}\\) – tegelik osalemine meetmes\n\n\\(X_i\\) – määramismuuttuja (vanus, hinne, sissetulek), mis määrab abikõlblikkuse\n\n\\(c\\) – lõikepunkt, lävend (cutoff)\n\nVaatleme tinglikke keskmisi:\n\\[\nm_1(x) = \\mathbb{E}[Y_i(1)\\mid X_i = x], \\quad\nm_0(x) = \\mathbb{E}[Y_i(0)\\mid X_i = x].\n\\]\nRD meetod põhineb ideel, et vahetult lõikepunkti ümbruses on isikud “peaaegu juhuslikult” jaotatud.\n\n\nJärsk (sharp) disain\nMääramistingimus\nJärsk disain (sharp design) tähendab, et määramismuutuja \\(X_i\\) ja lõikepunkt \\(c\\) määravad osalemise deterministlikult:\n\\[\nD_i = \\mathbf{1}(X_i \\ge c),\n\\]\nkus \\(\\mathbf{1}(\\cdot)\\) on indikaatorfunktsioon.\n\nKui \\(X_i \\ge c\\), siis kõik osalevad: \\(D_i = 1\\)\n\nKui \\(X_i &lt; c\\), siis keegi ei osale: \\(D_i = 0\\)\n\nTe gelikult vaatleme täheldatud tulemust\n\\[\nY_i = D_i Y_i(1) + (1-D_i)Y_i(0).\n\\]\n\n\nMõju hindamise valem (sharp RDD)\nRDD põhiobjekt on lokaalne keskmine mõju lõikepunktis:\n\\[\n\\tau^{SRD} = \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x]\n            - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x].\n\\]\nSõnades:\n– võtame tingliku keskmise väljundi vahetult lõikepunktist paremal (abikõlblikud)\n– lahutame sellest tingliku keskmise väljundi vahetult lõikepunktist vasakul (mitteabikõlblikud).\nKui pidevuse eeldus (vt allpool) kehtib, siis see vahe identifitseerib:\n\\[\n\\tau^{SRD} = \\mathbb{E}\\big[Y_i(1) - Y_i(0) \\,\\big|\\, X_i = c\\big],\n\\]\nehk lokaalse ATE – Local Average Treatment Effect lõikepunkti juures (LATE).\n\n\nHägus (fuzzy) disain\nMääramistingimus\nHägus disain (fuzzy design) tähendab, et lõikepunkt ei määra osalemist deterministlikult:\n\nosalemise tõenäosus hüppab lõikepunktis, kuid\n\nenne lõikepunkti on osa isikuid, kes ikkagi osalevad\n\npärast lõikepunkti on osa, kes ei osale.\n\nFormaalne:\n\\[\np(x) = \\Pr(D_i = 1 \\mid X_i = x)\n\\]\non katkev punktis (c), st\n\\[\n\\lim_{x \\downarrow c} p(x) \\neq \\lim_{x \\uparrow c} p(x),\n\\]\naga kumbki pole 0 ega 1.\nMida see tähendab sisuliselt?\n– reegel on olemas (nt pensioniiga 63)\n– aga osa inimestest läheb pensionile varem või hiljem → reeglit ei järgita täielikult\n– lõikepunkti lähedal on \\(X_i\\) käitumas nagu instrumentmuutuja: mõjutab tugevalt osalemise tõenäosust, mitte otseselt tulemust.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#mõju-hindamise-valem-fuzzy-rdd-wald",
    "href": "05-rdd.html#mõju-hindamise-valem-fuzzy-rdd-wald",
    "title": "6  Regressiooni katkemise meetod",
    "section": "6.2 Mõju hindamise valem (fuzzy RDD, Wald)",
    "text": "6.2 Mõju hindamise valem (fuzzy RDD, Wald)\nHägusa disaini korral võrdleme lisaks \\(Y\\) hüppele ka meetmes osalemise hüpet:\n\\[\n\\Delta Y = \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x]\n         - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x],\n\\]\n\\[\n\\Delta D = \\lim_{x \\downarrow c} \\mathbb{E}[D_i \\mid X_i = x]\n         - \\lim_{x \\uparrow c} \\mathbb{E}[D_i \\mid X_i = x].\n\\]\nLokaalne Waldi hinnang:\n\\[\n\\tau^{FRD} = \\frac{\\Delta Y}{\\Delta D}.\n\\]\nSee on analoogne IV-Waldi hinnanguga: kui lõikepunkti juures oleks tõenäosus muutunud 0-lt 1-le, siis \\(\\Delta Y\\) olekski mõju; kuna muutus on väiksem, skaleerime selle üles jagades \\(\\Delta D\\)-ga.\n\nPidevuse eeldus\nRDD tuum on pidevuse eeldus (continuity assumption). Informaalne mõte:\nKõik muud tegurid peale programmi mõju muutuvad lõikepunkti ümbruses “sujuvalt” (pidevalt). Ainus diskreetne hüpe \\(Y\\)-s lõikepunktis tuleb programmist.\nFormaalne kuju:\n\\[\n\\lim_{x \\downarrow c} \\mathbb{E}[Y_i(0)\\mid X_i=x]\n=\n\\lim_{x \\uparrow c} \\mathbb{E}[Y_i(0)\\mid X_i=x]\n\\]\nja terava disaini korral samamoodi \\(Y_i(1)\\) jaoks, või üldisemalt, et potentsiaalsete tulemuste tinglikud keskmised on pidevad \\(x=c\\) juures.\nLisaks saame kontrollida, kas ka $X£-i tihedusfunktsioon on pidev lõikepunkti juures (vt McCrary test).\nPidevuse rikkumised:\n\ninimesed manipuleerivad oma $X£-i (hinne, sissetulek) üle/alla piiri, et reegliga mängida\n\nsamal lõikepunktil juhtub mõni muu poliitikamuutus (teine reform, teine programm)\n\nlõikepunkt ise on endogeenne (nt “nutikad” ettevõtted planeerivad töötajate arvu täpselt alla piiri, et toetust saada)\n\n\n\nMcCrary test: x-jaotuse pidevus\nKui inimesed saavad määramismuutujat \\(X\\) ise mõjutada (nt taotlusvormi täitmise kuupäeva, sissetuleku deklareerimist), võivad nad “koonduda” lõikepunkti alla või üles. Selle tuvastamiseks kasutatakse McCrary tihedustesti.\n\n\\(H_0\\): \\(X\\) tihedus on lõikepunkti juures pidev (ei ole manipulatsiooni)\n\n\\(H_1\\): tiheduses on hüpe lõikepunkti juures (viitab manipulatsioonile)\n\nIdee:\n\nhinnatakse \\(X\\) tihedust lõikepunkti vasakul ja paremal (nt lokaalse polünoomi abil),\n\ntestitakse, kas hinnatud tihedused erinevad statistiliselt olulisel määral.\n\nKui testi tulemus ei lükka \\(H_0\\) hüpoteesi ümber (puudub oluline hüpe tiheduses), on pidevuse eeldus ja “manipuleerimatuse” eeldus usutavam.\n\n\nPlatseebo test\nPlatseebo test (või “fake cutoff test”) kontrollib, kas meie hinnatud mõju sõltub spetsiifiliselt just tegelikust lõikepunktist.\nIdee:\n\nvalime valed (platseebo) lõikepunktid, mis ei tohiks sekkumisega seotud olla;\njooksutame RDD-analüüsi nende uute lõikepunktide juures;\neeldus: me ei tohiks leida süsteemselt suuri ja statistiliselt olulisi mõjusid.\n\nKui leiame tugevaid “mõjusid” ka mujal, võib see viidata:\n\nmudeli ülesobitamisele (liiga paindlik polünoom)\nandmetes olevale muule mittelineaarsusele, mida tõlgendatakse ekslikult “mõjuna”\nvalesti määratud bandwidth’ile või kernelile.\n\nKui ainult tõelise lõikepunkti juures on selge ja stabiilne mõju, suurendab see usaldust RDD tulemuste suhtes.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#näide-vanaduspensioniiga-pensionide-saamine-ja-tööaeg-eestis-2010.",
    "href": "05-rdd.html#näide-vanaduspensioniiga-pensionide-saamine-ja-tööaeg-eestis-2010.",
    "title": "6  Regressiooni katkemise meetod",
    "section": "6.3 Näide: Vanaduspensioniiga, pensionide saamine ja tööaeg Eestis 2010.",
    "text": "6.3 Näide: Vanaduspensioniiga, pensionide saamine ja tööaeg Eestis 2010.\n\naastal oli meeste seadusjärgne pensioniiga 63 aastat. Selles vanuses võiksid nad saada täispensioni. Nad võivad minna pensionile varem (ja kaotada pensioni suuruses) või hiljem pensionile jääda (ja neil on suurem pension). Neil võib olla ka eripension, mida mõnikord maksti varem, või ka töövõimetuspension.\nPensioniiga annab õiguse vanaduspensionile, väikesele, kuid kindlale lisasissetulekule, mis võib võimaldada vanematel inimestel oma tööaega lühendada.\n\nMeie uurimisküsimus: - kuidas mõjutab pensioni saamist nominaalpensioniikka (63) jõudmine? (Me peame seda järsuks disainiks– sest õigus tekib igal mehel) - kuidas mõjutab pensioni saamine nominaalpensioniea (63) lähedal töötunde. Seda võiks pidada hägusaks disainiks, sest nominaalpensioniikka jõudmine mõjutab pensioni saama hakkamist vaid osadel inimestel.\nProbleem on selles, et vanus ise mõjutab tervist, mis loomulikult vähendab tööaega. Kuidas neid mõjusid eristada – üks tervise ja teine lisatulu kaudu? Meil ei ole tervise jaoks selget mõõdikut, seega kasutame vanust lihtsalt lähendina.\nTeeme oletuse: vanuse mõju tööajale tervise kaudu on pidev, kuid vanuse mõju pensioni saamise õigusele on diskreetne (või hüppeline).\nLaadige paketid.\n\nlibrary(tidyverse)\nlibrary(haven) #Stata failide jaoks\nlibrary(rdrobust)\nlibrary(lmtest) \nlibrary(sandwich)\nlibrary(stargazer)\nlibrary(rdrobust)\nlibrary(ivreg)\n\n\nLaadige andmed\nMeil on järgmised tunnused\n\nage\nppension - 1-0 tunnus, kui inimene saab pensioni (meie meede)\noldage – inimene saab vanaduspensioni\ndisben – inimene saab töövõimetuspensioni\nhours – nädala töötunnid (meie väljund)\nemployed - 1-0 kui inimesel on täisajaga töökoht\ntaustatunnused: estlang (räägib Eesti keelt), haridus (haridustase: 1,2,3)\n\n\ndf &lt;- read_dta(\"https://kodu.ut.ee/~avork/files/oppetoo/micro/pensioners.dta\")\n\n\n\nAlati alusta joonistest\nTee joonis vanuse ja pensioni saamise vahel\n\ndf %&gt;% ggplot(aes(x=age, y = pension)) +\n  geom_point()\n\n\n\n\n\n\n\n\nlisa sammhaaval a) silumine b) värvi vanuse järgi age &gt; 62 c) tee punctid väiksemaks (size = 0.5) ja läbipaistvaks (alpha = 0.5) d) lisa juhuslikku müra punktidele “position = position_jitter(width = 0.2,height = 0.05, seed = 1234)” e) lisa vertikaalne joon 62.5\nVaata, kuidas joonis muutub\n\ndf %&gt;% ggplot(aes(x=age, y = pension, \n                  color = age&gt;62)) +\n  geom_point(size = 0.5, alpha = 0.5, \n             position = position_jitter(width = 0.2,height = 0.05, seed = 1234)) +\n  geom_smooth() +\n  geom_vline(xintercept = 62.5) + theme_bw()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\nKeskmine vanusrühmade järgi\nArvutage pensioni saavate meeste keskmine osakaal (muutuja pension), keskmine tööaeg (muutuja hours) vanuse järgi ja näitaja (over62), kui vanus on üle 62,5\n\ndfmeanprop &lt;- df %&gt;% group_by(age) %&gt;% \n  summarise(pension = mean(pension)*100,\n            hours = mean(hours),\n            over62= as.factor(mean(age&gt;62.5)))\n\nJoonistage igas vanuses pensioni saavate meeste keskmine osakaal, värvige see üle62 võrra. Lisa silutud joon.\n\ndfmeanprop %&gt;% ggplot(aes(x=age, y = pension, color = over62)) +\n  geom_point() +\n  geom_smooth(se= FALSE) +\n  scale_x_continuous(breaks = c(seq(50, 75, 5)))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nKas 63-aastaselt on hüpe?\nKas pensioniea mõju pensioni saamisele on järsk või hägune?\n\n\nVanus ja töötunnid\nJoonistage lähteandmet põhjal seos iganädalaste töötundide ja vanuse järgi. Kasutage sama koodi, mida kasutasite pensioni jaoks, kuid asendage pension töötundidega. Vajadusel muutke position_jitter\n\ndf %&gt;% ggplot(aes(x=age, y = hours, color = age&gt;62)) +\n  geom_point(size = 0.5, alpha = 0.5, \n             position = position_jitter(width = 0.2,height = 1, seed = 1234)) +\n  geom_smooth() +\n  geom_vline(xintercept = 62.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nJoonista samuti grupeeritud andmete järgi\n\ndfmeanprop %&gt;% ggplot(aes(x=age, y = hours, color = over62)) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE) +\n  geom_vline(xintercept = 62.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nTee lõikepunkt ja leia vanus selle suhtes\nTeeme muutuja ‘penage’ = 62.5\n\npenage = 62.5\n\nLooge uus muutuja “agec”, mis on erinevus vanusest 62,5. (Me ei tea täpselt, millal inimene sai 63-aastaseks, seetõttu kasutame 62,5). Looge tsentraliseeritud vanuse ruut ja kuupliige. Genereerige ka näitaja (1-0) muutuja, kui vanus on vanem kui pensioniiga: “overpenage”.\n\ndf &lt;- df %&gt;%  \n  mutate(agec = age-penage,\n         agec2 = agec*agec,\n         agec3 = agec*agec*agec,\n         overpenage = (age&gt;penage)*1)\n\n\n\nJärsk (terav) disain – pensioniea mõju tõenäosusele saada pensioni\nVanaduspensioni ea kättejõudmise mõttes on tegu järsu disainiga (inimestel tekib õigus täispensionile, küll aga mõned valivad või saavad minna varem ja mõned hiljem). Võrdleme pensioni saamist enne ja pärast pensioniiga Võtame u = 2. Võrdleme pensioni saamist vanuses 61-62 ja 63-64.\n\nu = 2\n\nLeia käsitsi osakaalud enne ja pärast pensioniiga\n\nmeanpensbelow &lt;- df %&gt;%  filter(age&gt;penage-u, age &lt;penage) %&gt;% \n  summarise(meanpensbelow = mean(pension)) %&gt;%  as.numeric()\n\nmeanpensabove &lt;- df %&gt;%  filter(age&gt;penage, age &lt;penage+u) %&gt;% \n  summarise(meanpensabove = mean(pension)) %&gt;% as.numeric()\n\nKui suur on erinevus pensioni saamises enne ja pärast pensioniiga?\n\nmeanpensabove - meanpensbelow\n\n[1] 0.3123874\n\n\nVõtke u = 1. Kui palju tulemus muutub?\n\n\nMõju hindamine regressioonimudeliga\nHinnake lineaarne tõenäosusmudel (mudel1), kus pensioni näitaja sõltub näitajast, kui inimene on pensionieas ja vanus. Lisage seejärel vanuse ruutliige (mudel2) ja kuupliige (mudel3)\nMuutuja “overpenage” koefitsient näitab pensioniea mõju pensioni saamise tõenäosusele. Vanus iseloomustab teiste kanalite mõju, nt terviseseisundi ja töövõimetuspensioni saamise.\n\nmodel1 &lt;- lm(pension ~ overpenage + agec, data = df)\nmodel2 &lt;- lm(pension ~ overpenage + agec +  agec2 , data = df)\nmodel3 &lt;- lm(pension ~ overpenage + agec +  agec2 + agec3, data = df)\n\nVõrrelge tulemusi tabelis\n\nstargazer(model1, model2, model3, type = \"text\", no.space = TRUE)\n\n\n===================================================================================================\n                                                  Dependent variable:                              \n                    -------------------------------------------------------------------------------\n                                                        pension                                    \n                                (1)                        (2)                       (3)           \n---------------------------------------------------------------------------------------------------\noverpenage                   0.316***                   0.361***                  0.221***         \n                              (0.028)                    (0.029)                   (0.037)         \nagec                         0.029***                   0.025***                  0.050***         \n                              (0.002)                    (0.002)                   (0.005)         \nagec2                                                   -0.001***                 -0.001***        \n                                                        (0.0002)                  (0.0002)         \nagec3                                                                            -0.0002***        \n                                                                                  (0.00003)        \nConstant                     0.472***                   0.497***                  0.578***         \n                              (0.016)                    (0.016)                   (0.021)         \n---------------------------------------------------------------------------------------------------\nObservations                   2,607                      2,607                     2,607          \nR2                             0.496                      0.503                     0.509          \nAdjusted R2                    0.495                      0.502                     0.509          \nResidual Std. Error      0.354 (df = 2604)          0.352 (df = 2603)         0.350 (df = 2602)    \nF Statistic         1,279.302*** (df = 2; 2604) 877.175*** (df = 3; 2603) 675.659*** (df = 4; 2602)\n===================================================================================================\nNote:                                                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nPensioniea vanuspiiri ületamise efekt tõenäosusele, et mehed saavad pensioni on 31.6 protsendipunkti kui lubame lineaarse liikme mudelisse, 36.1 protsendipunkti ruutliikega mudelis ja 22.1 protsendipunkti kuuliikmega mudelis. Seega see, millist mittelineaarsust me lubame vanuspiiri lähedal, mõjutab meie tulemusi üsna palju.\nSaame lubada ka erinevaid parameetreid lõikepunkti mõlemale poolele. overpenage koefitsient näitab nüüd pensioniea kättejõudmise mõju pensioni saamise tõenäosusele lõikepunktis.\n\nmodel1a &lt;- lm(pension ~ overpenage + agec +  \n                agec*overpenage, data = df)\nmodel2a &lt;- lm(pension ~ overpenage + agec +  agec2 + \n               agec*overpenage +  agec2*overpenage , data = df)\nmodel3a &lt;- lm(pension ~ overpenage + agec +  agec2 + agec3 +\n               agec*overpenage +  agec2*overpenage + agec3*overpenage, data = df)\n\n\nstargazer(model1a, model2a, model3a, type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                       pension                                   \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  0.363***                  0.200***                  0.176***         \n                             (0.028)                   (0.042)                   (0.058)         \nagec                        0.039***                  0.086***                  0.073***         \n                             (0.002)                   (0.010)                   (0.025)         \nagec2                                                 0.004***                    0.001          \n                                                       (0.001)                   (0.004)         \nagec3                                                                            -0.0001         \n                                                                                (0.0002)         \noverpenage:agec             -0.028***                 -0.045***                   0.009          \n                             (0.004)                   (0.016)                   (0.042)         \noverpenage:agec2                                      -0.006***                  -0.012          \n                                                       (0.001)                   (0.008)         \noverpenage:agec3                                                                  0.001          \n                                                                                (0.0004)         \nConstant                    0.535***                  0.640***                  0.625***         \n                             (0.018)                   (0.027)                   (0.038)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.505                     0.511                     0.511          \nAdjusted R2                   0.505                     0.510                     0.510          \nResidual Std. Error     0.351 (df = 2603)         0.349 (df = 2601)         0.349 (df = 2599)    \nF Statistic         885.732*** (df = 3; 2603) 543.685*** (df = 5; 2601) 388.675*** (df = 7; 2599)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nNäeme, et mida suurt mittelineaarsust lubada, seda väiksem mõjuhinnang on. Kuupliikmetega mudelis on pensioniea kättejõudmise mõju 17.6 protsendipunkti.\nEdasijõudnutele: kasutame robustseid standardvigu, mis lubavad heteroskedastiivsust\n\nstargazer(model1a, model2a, model3a, \n          se=list(sqrt(diag(vcovHC(model1a, \"HC1\"))),\n                  sqrt(diag(vcovHC(model2a, \"HC1\"))),\n                  sqrt(diag(vcovHC(model3a, \"HC1\")))),\n          type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                       pension                                   \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  0.363***                  0.200***                  0.176***         \n                             (0.030)                   (0.048)                   (0.068)         \nagec                        0.039***                  0.086***                   0.073**         \n                             (0.003)                   (0.012)                   (0.033)         \nagec2                                                 0.004***                    0.001          \n                                                       (0.001)                   (0.006)         \nagec3                                                                            -0.0001         \n                                                                                (0.0003)         \noverpenage:agec             -0.028***                 -0.045***                   0.009          \n                             (0.004)                   (0.015)                   (0.042)         \noverpenage:agec2                                      -0.006***                  -0.012*         \n                                                       (0.001)                   (0.007)         \noverpenage:agec3                                                                 0.001*          \n                                                                                (0.0003)         \nConstant                    0.535***                  0.640***                  0.625***         \n                             (0.024)                   (0.037)                   (0.053)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.505                     0.511                     0.511          \nAdjusted R2                   0.505                     0.510                     0.510          \nResidual Std. Error     0.351 (df = 2603)         0.349 (df = 2601)         0.349 (df = 2599)    \nF Statistic         885.732*** (df = 3; 2603) 543.685*** (df = 5; 2601) 388.675*** (df = 7; 2599)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\nMitteparameetriline hindamine\nKasutame silumist paketist rdrobust.\n\nrdrobust(y = df$pension, x = df$age, c = 62.5) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$pension, x = df$age, c = 62.5): Mass points detected\nin the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.778        3.778\nBW bias (b)                   5.943        5.943\nrho (h/b)                     0.636        0.636\nUnique Obs.                      13           12\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect     0.185     1.921     0.055    [-0.003 , 0.333]     \n=====================================================================\n\n\nTulemuste tõlgendamisest.\n\nVõib tulla hoiatus: masspunktid (mass points)\n\nSee tähendab, et vanusemuutujal on palju korduvaid väärtusi (meil täisaastad). See on vanusepõhiste RDD-de puhul tavaline – see ei riku disaini, kuid näitab, et jaotus ei ole täiesti sile.\n\nValimi suurus Kokku on vaatlusi 2607 vaatluse. Hinnang tehakse aga lokaalsete lineaarsete regressioonidega, kolmnurkse kerneliga lõikepunkti ümber. Optimaalne ribalaius (mserd) on umbes 3,778 aastat mõlemal pool lävendit, seega kasutatakse enim vanuseid umbes 58–67.\n\n“BW type mserd” – ribalaius või aken (bandwidth) on valitud nn mean squared error optimal for RD (ehk mserd) reegli alusel. See on automaatne optimaalne akna valik, mis püüab tasakaalustada täpsust ja nihet.\n“Kernel Triangular” – kasutatakse kolmnurkset kernelit (tuuma), mis tähendab, et lõikepunktile kõige lähemad vaatlused saavad suurima kaalu ja kaugemad väiksema. See on RDD puhul standardne valik, sest rõhutab just lõikepunkti ümbrust.\nVCE method NN – dispersioonide ja standardvigade arvutamisel on kasutatud nearest-neighbor (NN) meetodit, mis põhineb lähimate punktide võrdlemisel. See on üks võimalikest robustsete standardvigade arvutusviisidest.\n\nEfektiivne vaatlustearv Kuigi kokku on 2607 vaatluse, panustavad tegelikult kõige enam 472 vaatlust enne ja 332 pärast lõikepunkti, sest kaalumine annab rohkem kaalu neile, kes on lõikepunktile lähedal.\n\nOrder est. (p) - lõikepunkti ümbruses on kasutatud esimese astme polünoomi, ehk lokaalset lineaarset regressiooni. See on RDD standardne valik.\nOrder bias (q) = 2 - võimaliku nihke hindamiseks kasutatakse teise astme polünoomi (ruutfunktsiooni). Teisisõnu, nihke parandust hinnatakse natuke paindlikuma mudeliga kui põhihinnangut.\nBW est. (h) = 3.778 - Optimaalne aken hinnangu tegemiseks on 3,78 aastat mõlemal pool lõikepunkti.\nW bias (b) = 5.943 - Nihke hindamiseks kasutatakse laiemat akent, 5,94 aastat mõlemal pool lõikepunkti. See on tavapärane, sest nihke hindamiseks on vaja rohkem andmeid.\nrho (h/b) = 0.636 - See on suhe hinnangu akna ja nihke akna vahel: 3.78 / 5.94 ≈ 0.64. Väärtus alla 1 näitab, et nike hindamiseks kasutatakse suuremat akent kui põhihinnangu jaoks (mis on just õige).\nUnique Obs. = 13 (vasakul), 12 (paremal) - lõikepunkti ümbruses on ainult 13 erinevat vanuseväärtust vasakul ja 12 erinevat vanuseväärtust paremal. Kuna vanus on diskreetne (tavaliselt täisaastad), ei ole lõikepunkti ümber väga palju erinevaid väärtusi, mis võib täpsust piirata.\n\nKoefitsient (mõju)\n\nTavaline hinnang lõikepunkti mõjule on 0,185. See tähendab, et pensioniea ületamine suurendab pensioni saamise tõenäosust 18,5 protsendipunkti võrra. Standardviga: 0,070 z-statistik: 2,64 p-väärtus: 0,008 → statistiliselt oluline 1% tasemel\n\nRobustne (bias-corrected) hinnang on konservatiivsem: z = 1,921, p = 0,055. See on vaid napilt oluline 10% tasemel, sest 95% usaldusvahemik on [−0,003; 0,333] ja hõlmab nulli.\n\nTulemuste usaldusväärsus sõltub seega ka sellest, kas kasutame tavalist või robustset hinnangut: tavalise järgi on efekt kindlalt oluline, robustse järgi piiri peal.\nKommentaar robustsete standardvigade kohta\nTavaline (“Conventional”) punkthinnang on lihtsalt vahe lõikepunkti vasakul ja paremal poolel lokaalse polünoomi ekstrapoleeritud väärtustes, antud akna korral.\nStandardvead põhinevad asümptootilisel teoorial, kuid kipuvat liiga vähe arvestama nihet (bias), eriti väikeste valimite puhul.\n“Robust bias-corrected (RBC) hinnang” - Calonico, Cattaneo ja Titiunik (2014) järgi püüab korrigeerida lõikepunkti lähedal tekkivat hinnangute nihet.\nAlguses hinnatakse nihe kõrgema astme polünoomi abil.\nSeejärel lahutatakse nihe tavalise hinnangu väärtusest ning arvutatakse uued standardvead, mis arvestavad nii valimi juhuslikkust kui ka nihke korrigeerimist.\nPunktihinnang ise tavaliselt palju ei muutu, kuid usaldusvahemikud muutuvad laiemaks, sest standardvead suurenevad.\nSeega on RBC hinnang konservatiivsem ja usaldusväärsem, vähendades riski vale-positiivsete tulemuste jaoks.\nJa ka graafik\n\nrdplot(y = df$pension, x = df$age, c = 62.5)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\n\n\nPensioniea mõju töötundidele\nKäsitleme pensioniea mõju töötundidele nüüd hägusa disainina, sest pensioniiga ei määra täpselt pensioni saamist.\n\nKäsitsi LATE hägusa disaini jaoks\nArvutame käsitsi Waldi kohaliku statistiku (LATE) häguse disaini jaoks. Võtke +/- 2 aastat.\n\nu = 5\n\nOleme juba arvutanud keskmise pensionäride osa, mis jääb alla ja üle piirpunkti intervalli u piiresse. ‘meanpensbelow’ ja ‘meanpensabove’\nSamamoodi arvutame keskmised töötunnid allpool ja kõrgemal: ” meanhoursbelow “meanhoursabove”.\n\nmeanhoursbelow &lt;- df %&gt;%  filter(age&gt;penage-u, age &lt;penage) %&gt;% \n  summarise(meanhourbelow = mean(hours)) %&gt;% as.numeric()\n\nmeanhoursabove &lt;- df %&gt;%  filter(age&gt;penage, age &lt;penage+u) %&gt;% \n  summarise(meanhourabove = mean(hours)) %&gt;% as.numeric()\n\nLeidke muutused\n\n#muutus pensionäride osakaalus\nmeanpensabove-meanpensbelow\n\n[1] 0.3123874\n\n\nEerinevus pensioni saajate osakaalus on seega 0.312\n\n#muutus töötundides \nmeanhoursabove - meanhoursbelow\n\n[1] -9.098265\n\n\nTöötundide vähenemine on samal ajal -9.1 tundi nädalas.\nLATE on suhtarv, mis skaleerib muutuse.\n\nlate = (meanhoursabove - meanhoursbelow) / (meanpensabove-meanpensbelow)\nlate\n\n[1] -29.12494\n\n\nÕigus saada vanaduspensioni vähendaks töötunde ligi -29.1249376 tunni võrra nädalas.\nAga, et paljud on juba varem läinud pensionile ja paljud lükkavad edasi, siis andmetest me näeme pensioniea ligidal vaid vähenemist -9.1 töötundi.\n\n\n\nRegressioonimudel – kui oleks järsk disain\nHindame sarnased regressioonimudelid nagu üleval\n\nmodel1 &lt;- lm(hours ~ overpenage + agec, data = df)\nmodel2 &lt;- lm(hours ~ overpenage + agec +  agec2 , data = df)\nmodel3 &lt;- lm(hours ~ overpenage + agec +  agec2 + agec3, data = df)\n\nstargazer(model1, model2, model3, type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                        hours                                    \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  -3.984***                 -4.002***                  -1.638          \n                             (1.444)                   (1.496)                   (1.934)         \nagec                        -1.101***                 -1.099***                 -1.527***        \n                             (0.098)                   (0.106)                   (0.246)         \nagec2                                                  0.0004                     0.006          \n                                                       (0.008)                   (0.008)         \nagec3                                                                            0.003*          \n                                                                                 (0.002)         \nConstant                    18.005***                 17.995***                 16.636***        \n                             (0.804)                   (0.833)                   (1.091)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.215                     0.215                     0.216          \nAdjusted R2                   0.214                     0.214                     0.215          \nResidual Std. Error    18.326 (df = 2604)        18.330 (df = 2603)        18.320 (df = 2602)    \nF Statistic         355.784*** (df = 2; 2604) 237.099*** (df = 3; 2603) 178.938*** (df = 4; 2602)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nNäeme, et mõju hinnang on palju väiksem ja sõltub kui paindlikku mudelit kasutame. Lineaarse ja ruutliikmetega mudels on mõju vaid 4 tundi. Kui lubame vanuse kuupfunktsiooni, siis ei ole mõju enam statistiliselt oluline.\nTaas, kasutame praktikas robustseid standardvigu.\n\nstargazer(model1, model2, model3, \n          se=list(sqrt(diag(vcovHC(model1, \"HC1\"))),\n                  sqrt(diag(vcovHC(model2, \"HC1\"))),\n                  sqrt(diag(vcovHC(model3, \"HC1\")))),\n          type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                        hours                                    \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  -3.984***                 -4.002***                  -1.638          \n                             (1.528)                   (1.511)                   (2.066)         \nagec                        -1.101***                 -1.099***                 -1.527***        \n                             (0.101)                   (0.097)                   (0.256)         \nagec2                                                  0.0004                     0.006          \n                                                       (0.007)                   (0.007)         \nagec3                                                                            0.003*          \n                                                                                 (0.002)         \nConstant                    18.005***                 17.995***                 16.636***        \n                             (0.861)                   (0.927)                   (1.181)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.215                     0.215                     0.216          \nAdjusted R2                   0.214                     0.214                     0.215          \nResidual Std. Error    18.326 (df = 2604)        18.330 (df = 2603)        18.320 (df = 2602)    \nF Statistic         355.784*** (df = 2; 2604) 237.099*** (df = 3; 2603) 178.938*** (df = 4; 2602)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKui olete vanem kui 63, väheneb tööaeg kõige paindlikumates mudelites vaid 1.64 tundi nädalas.\n\n\nSilumise kasutamine\nJällegi kasutage kohalikku polünoomi silumist käsuga rdrobust, vaata ülalt käsku ja asenda pensioni saamine töötundidega\n\nrdrobust(y = df$hours, x = df$age, c = 62.5) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 62.5): Mass points detected\nin the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.710        3.710\nBW bias (b)                   5.647        5.647\nrho (h/b)                     0.657        0.657\nUnique Obs.                      13           12\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect    -0.134    -0.137     0.891    [-8.467 , 7.364]     \n=====================================================================\n\n\nSeekord näeme, et väga paindlikult hinnates, seos puudub. Saame vaadata seda ka joonisel.\n\nrdplot(y = df$hours, x = df$age, c = 62.5)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\nIseloomustamaks funktsionaalse kuju ja lõikepunkti valiku mõju, siis kui oleksime nõudnud lineaarset seost vanuse ja töötundide vahel ja paneks piiri 63.5 (sest tööturukäitumise kohandamine võtab aega), oleks mõju ca 4 tundi vähem töötunde nädalas, küll pole see statistiliselt oluline:\n\nrdplot(y = df$hours, x = df$age, c = 63.5, p = 1)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\nrdrobust(y = df$hours, x = df$age, c = 63.5, p = 1) %&gt;% \n    summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 63.5, p = 1): Mass points\ndetected in the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1708          899\nEff. Number of Obs.             472          292\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.701        3.701\nBW bias (b)                   5.826        5.826\nrho (h/b)                     0.635        0.635\nUnique Obs.                      14           11\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect    -3.917    -1.207     0.228   [-12.433 , 2.958]     \n=====================================================================\n\n\n\nEdasijõudnutele: instrumentmuutuja kasutamine\nEsimene samm on hinnata pensioni saamise tõenäosus. Kasutage lineaarset tõenäosusmudelit koos overpenage ja lineaarse ja ruudukujul vanusega. Seejärel prognoosige pensioni saamise tõenäosus. Pange nimeks “pensionhat”. Hinnake tundide võrrand, kus pensioni saamise asemel on selgitavaks teguriks prognoositav pensioni saamine “pensionhat”.\n\npensmodel &lt;- lm(pension ~ overpenage + agec +  agec2, data = df)\nsummary(pensmodel)\n\n\nCall:\nlm(formula = pension ~ overpenage + agec + agec2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.01937 -0.21779 -0.01524  0.08558  0.96070 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4970274  0.0159821  31.099  &lt; 2e-16 ***\noverpenage   0.3611695  0.0287180  12.576  &lt; 2e-16 ***\nagec         0.0248456  0.0020332  12.220  &lt; 2e-16 ***\nagec2       -0.0009418  0.0001543  -6.105 1.18e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3519 on 2603 degrees of freedom\nMultiple R-squared:  0.5027,    Adjusted R-squared:  0.5022 \nF-statistic: 877.2 on 3 and 2603 DF,  p-value: &lt; 2.2e-16\n\n\nMeeldetuletus: kui palju pensioniikka jõudmine suurendas tõenäosust pensioni saada? Vaata “overpenage” kordajat.\nPrognoosime pensioni saamise, nimetame muutuja ‘pensionhat’.\n\ndf$pensionhat &lt;- predict(pensmodel)\nsummary(df$pensionhat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0393  0.2178  0.4290  0.5370  0.9509  1.0194 \n\n\nHindame töötundide võrrandi, kus sees on prognoositud tõenäosus pension saada.\n\nmodelf &lt;- lm(hours ~ pensionhat + agec +  agec2, data = df)\nsummary(modelf)\n\n\nCall:\nlm(formula = hours ~ pensionhat + agec + agec2, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.788 -13.444  -2.498  13.743  63.256 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  23.503075   2.745330   8.561  &lt; 2e-16 ***\npensionhat  -11.081325   4.141871  -2.675  0.00751 ** \nagec         -0.823388   0.201762  -4.081 4.62e-05 ***\nagec2        -0.010058   0.007967  -1.263  0.20687    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.33 on 2603 degrees of freedom\nMultiple R-squared:  0.2146,    Adjusted R-squared:  0.2137 \nF-statistic: 237.1 on 3 and 2603 DF,  p-value: &lt; 2.2e-16\n\n\nPensioniikka jõudmise mõju töötundide vähendamisele on ligi 11 tundi. See on sarnane käsitsi hinnatud LATEga (vt üles).\nKäsk ivreg teeb selle kahesammulise hindamise automaatselt.\n\nfuzzyreg &lt;- ivreg(\n  hours ~ pension + agec +  agec2 | overpenage + agec +  agec2,\n  data = df\n)\n\nsummary(fuzzyreg)\n\n\nCall:\nivreg(formula = hours ~ pension + agec + agec2 | overpenage + \n    agec + agec2, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.224 -12.008  -2.667  11.570  67.354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  23.503075   2.490179   9.438  &lt; 2e-16 ***\npension     -11.081325   3.756926  -2.950  0.00321 ** \nagec         -0.823388   0.183010  -4.499 7.12e-06 ***\nagec2        -0.010058   0.007226  -1.392  0.16408    \n\nDiagnostic tests:\n                  df1  df2 statistic  p-value    \nWeak instruments    1 2603    158.17  &lt; 2e-16 ***\nWu-Hausman          1 2602     19.74 9.23e-06 ***\nSargan              0   NA        NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.63 on 2603 degrees of freedom\nMultiple R-Squared: 0.3538, Adjusted R-squared: 0.3531 \nWald test: 288.2 on 3 and 2603 DF,  p-value: &lt; 2.2e-16 \n\n\nvaadake kordajat pension Pensioniikka jõudmise mõju töötundide vähendamisele on ligi 11 tundi.\n\n\nPaindlikum mudel\nVõime kasutada veelgi paindlikumat mudelit, lokaalset lineaarset regressioonimudelit, taas paketist rdrobust.\n\nrdrobust(y = df$hours, x = df$age, c = 62.5, fuzzy = df$pension) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 62.5, fuzzy = df$pension):\nMass points detected in the running variable.\n\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   4.500        4.500\nBW bias (b)                   7.303        7.303\nrho (h/b)                     0.616        0.616\nUnique Obs.                      13           12\n\nFirst-stage estimates.\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n=====================================================================\n     Rd Effect     0.193     2.134     0.033     [0.014 , 0.319]     \n=====================================================================\n\nTreatment effect estimates.\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect     0.930     0.190     0.849   [-33.306 , 40.450]    \n=====================================================================\n\n\nSelle paindliku mudeli järgi ei ole seost pensioniea ja töötundide vahel. Seost ei ole, sest muutus töötundides võib olla mittelineaarse seose tulemus vanuse ja töötundide vahel.\n\n\n\nPlatseebo-test\nVaatame, kas vanuses 63 on hüpe erinev võrreldes teiste lõikepunktidega. Me sooviksime näha, et 63 on hüpe kõrge ja mujal ei ole erinevused statistiliselt olulised.\n\n#Meie väljund\ny &lt;- as.numeric(df$pension)\n#jooksev muutuja\nx &lt;- as.numeric(df$age)\n\n# Võimalikud lõikepunktid\ncuts &lt;- seq(60, 65, by = 0.5)\n\n#Funktsioon võtmaks välja meie hinnangud \nextract_rd &lt;- function(cu) {\n  out &lt;- rdrobust(y = y, x = x, c = cu)\n  est &lt;- out$Estimate\n  # Meie hinnangud\n  tau_us &lt;- est[1, \"tau.us\"]\n  se_us  &lt;- est[1, \"se.us\"]\n  tau_rb &lt;- est[1, \"tau.bc\"]\n  se_rb  &lt;- est[1, \"se.rb\"]\n  #Teeme tabeli\n  data.frame(cutoff = cu, tau_us = tau_us, se_us = se_us, tau_rb = tau_rb, se_rb = se_rb)\n}\n\nJa nüüd rakendame tabelit. Kasutame Ri käsku mapdfr, mis annab tulemustest andmetabeli. Ja funktsiooniks on meie enda tehtud funktsioon extract_rd\n\nres &lt;- map_dfr(cuts, extract_rd) %&gt;%\n  mutate(\n    #Ligilähedased 95% usalduspiirid robustsete hinnangutega \n    lwr_rb = tau_rb - 1.96 * se_rb,\n    upr_rb = tau_rb + 1.96 * se_rb,\n    #Ja tavapärased\n    lwr_us = tau_us - 1.96 * se_us,\n    upr_us = tau_us + 1.96 * se_us\n  )\n\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\n\n\nJa paneme tulemused joonisele. Kasutan praegu tavalisi standardvigu (mitte nihkega- korrigeeritud.)\n\n# \nggplot(res, aes(x = cutoff, y = tau_us)) +\n  geom_ribbon(aes(ymin = lwr_us, ymax = upr_us), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud koos ligilähedase 95% usalduspiiridega\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nJa ka robustsed usalduspiirid.\n\nggplot(res, aes(x = cutoff, y = tau_rb)) +\n  geom_ribbon(aes(ymin = lwr_rb, ymax = upr_rb), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud koos ligilähedase 95% usalduspiiridega\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nJoonistelt näeme, et tõepoolest kas vanus 62.5 või 63 on see, kus on statistiliselt oluline hüpe pensioni saamise tõenäosuses. Samas on mingi kummaline tõenäosuse vähenemine hoopis vanuses 65, mis muidugi ei saa olla tõene, aga viitab metoodika nõrkusele.\n\n\nPlatseebo test ka töötundidele\nNüüd peame muutma funktsiooni keerukamaks, et ta võtaks arvesse meie hägusat disaini\n\n#Meie väljund muutub\ny &lt;- as.numeric(df$hours)\n#meede\nz &lt;- as.numeric(df$pension)\n#jooksev muutuja\nx &lt;- as.numeric(df$age)\n\n#Funktsioon võtmaks välja meie hinnangud \nextract_rd &lt;- function(cu) {\n  #See rida muutub\n  out &lt;- rdrobust(y = y, x = x, c = cu, fuzzy = z)\n  est &lt;- out$Estimate\n  # Meie hinnangud\n  tau_us &lt;- est[1, \"tau.us\"]\n  se_us  &lt;- est[1, \"se.us\"]\n  tau_rb &lt;- est[1, \"tau.bc\"]\n  se_rb  &lt;- est[1, \"se.rb\"]\n  #Teeme tabeli\n  data.frame(cutoff = cu, tau_us = tau_us, se_us = se_us, tau_rb = tau_rb, se_rb = se_rb)\n}\n\nJa taas rakendame\n\nres &lt;- map_dfr(cuts, extract_rd) %&gt;%\n  mutate(\n    #Ligilähedased 95% usalduspiirid robustsete hinnangutega \n    lwr_rb = tau_rb - 1.96 * se_rb,\n    upr_rb = tau_rb + 1.96 * se_rb,\n    #Ja tavapärased\n    lwr_us = tau_us - 1.96 * se_us,\n    upr_us = tau_us + 1.96 * se_us\n  )\n\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\n\n\nNing tulemused\n\n# \nggplot(res, aes(x = cutoff, y = tau_us)) +\n  geom_ribbon(aes(ymin = lwr_us, ymax = upr_us), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud - pensioniea mõju töötundidele\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nNäeme, et mõjud kõiguvad väga palju. Mingeid erilist hüpet või muutust me ei näe pensioniea juures. Pigem on mingid anomaaliad vanuses 64.\nKokkuvõtteks, me tõesti näeme hüpet pensioniea lähedases vanuses pensioni saajate seas. Kuid me ei saa ümber lükata nüll hüpoteesi, et töötundidele otsest pensionieani jõudmine avaldaks mõju. Töötundide vähenemine toimub sujuvalt.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html",
    "href": "06-sobitamine.html",
    "title": "7  Sobitamine",
    "section": "",
    "text": "7.1 Mõistetest\nSobitamine (matching) on vaatlusandmetel põhinev meetod põhjusliku mõju hindamiseks olukorras, kus juhuslikku katset ei ole tehtud ning osalemine programmis (tööpoliitika meede, tervishoiu sekkumine jne) sõltub inimestest endast.\nIdee on lihtne: püüame iga osalusrühma inimese jaoks leida võimalikult sarnase inimese võrdlusrühmast ning võrdleme seejärel nende tulemusi.\nTuginedes potentsiaalsete tulemuste raamistikule tähistame:\nMeid huvitab näiteks keskmine mõju osalejatele (ATT):\n\\[\n\\tau_{ATT} = \\mathbb{E}[Y_i(1) - Y_i(0) \\mid D_i = 1].\n\\]\nProbleem: iga inimese puhul näeme ainult ühte tulemust, kas \\(Y_i(1)\\) või \\(Y_i(0)\\). Sobitamisega püüame iga osaleja jaoks leida sobiva “doppelgängeri” võrdlusrühmast, kellel oleks võimalikult sarnased \\(X\\)-id, ning kasutame tema \\(Y_j(0)\\) ligikaudse asendusena vaatlemata \\(Y_i(0)\\)-le.\nSobitamise tuumeeldus on ligikaudne valikuvabadus tingituna taustatunnustest (Conditional Independence Assumption, CIA):\n\\[\n(Y_i(0), Y_i(1)) \\perp D_i \\mid X_i,\n\\]\nehk pärast piisavalt rikkalike taustatunnuste \\(X\\) arvesse võtmist ei sõltu osalemine enam täiendavatest jälgimata teguritest.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html#mõistetest",
    "href": "06-sobitamine.html#mõistetest",
    "title": "7  Sobitamine",
    "section": "",
    "text": "\\(Y_i(1)\\) – isiku \\(i\\) tulemus, kui ta osaleb meetmes\n\n\\(Y_i(0)\\) – sama isiku tulemus, kui ta ei osale\n\n\\(D_i \\in \\{0,1\\}\\) – indicator, kas isik osales (1) või mitte (0)\n\n\\(X_i4\\) – vektor taustatunnuseid (vanus, sugu, haridus, eelnev töökogemus jne)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html#täpne-ja-ligikaudne-sobitamine",
    "href": "06-sobitamine.html#täpne-ja-ligikaudne-sobitamine",
    "title": "7  Sobitamine",
    "section": "7.2 Täpne ja ligikaudne sobitamine",
    "text": "7.2 Täpne ja ligikaudne sobitamine\n\nTäpne sobitamine\nLihtsaim mõte on täpne sobitamine (exact matching):\n\njagame andmestiku rakkudeks tunnuste \\(X\\) kombinatsioonide järgi (nt sugu, rahvus, haridustase);\n\nigale osalusrühma vaatlusel \\(i\\) otsime võrdlusgrupist need vaatlused, millel on täpselt samad tunnused \\(X\\);\n\nhindame mõju nende sobitatud paaride või gruppide sees.\n\nKui leiame iga osaleja jaoks täpse vaste(d), saame ATT hinnata kujul\n\\[\n\\hat{\\tau}_{ATT}\n= \\frac{1}{N_1} \\sum_{i: D_i = 1} \\left( Y_i - \\bar{Y}_{0}(i) \\right),\n\\]\nkus \\(\\bar{Y}_{0}(i)\\) on sarnaste võrdlusgrupi isikute keskmine tulemus.:contentReferenceoaicite:1\nPraktiline probleem on, et kui:\n\ntunnuseid on palju (suur mõõtmelisus) ja\n\nvalim ei ole väga suur,\n\nsiis jääb enamikul osalejatest täpset vastet leidmata. Seda nimetatakse tihti “mõõtmelisuse needuseks” – ruudustik, kuhu me andmed jaotame, muutub liiga hõredaks.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html#ligikaudne-sobitamine",
    "href": "06-sobitamine.html#ligikaudne-sobitamine",
    "title": "7  Sobitamine",
    "section": "7.3 Ligikaudne sobitamine",
    "text": "7.3 Ligikaudne sobitamine\nLigikaudse sobitamise puhul lubame väikese erinevuse tunnustes \\(X\\). Oluline on defineerida:\n\nmingi kauguse mõõdik vaatluste vahel \\(d(X_i, X_j)\\);\n\nalgoritm, mis valib iga osalusrühma isiku \\(i\\) jaoks “lähimad naabrid” võrdlusrühmast.\n\nTüüpiline näide on lähima naabriga sobitamine (nearest neighbor matching):\n\niga osaleja \\(i\\) jaoks leitakse üks või mitu võrdlusgrupi isikut \\(j\\), kellel on minimaalne kaugus \\(d(X_i, X_j)\\);\n\nmõju üksikule isikule hinnatakse kui erinevus \\(Y_i - \\bar{Y}_j(i)\\);\n\nATT on nende erinevuste keskmine kõigi osalejate seas.\n\nLigikaudse sobitamise kvaliteet sõltub otseselt sellest, kui hea on valitud kaugusmõõdik ja sobitamisalgoritm.\n\nMahalanobise kaugus\nSobitamisel on meil mitmemõõtmeline tunnuste vektor \\(X_i\\). Vajame üht numbrit, mis kirjeldaks, “kui kaugel” kaks inimest teineteisest on. Üks loogiline valik on Mahalanobise kaugus.\nOlgu \\(X_i\\) ja \\(X_j\\) kahe vaatluse tunnuste vektorid ning \\(\\Sigma\\) tunnuste kovariatsioonimaatriks (bediagonaalne, sümmeetriline, positiivselt määratud). Mahalanobise kaugus on:\n\\[\nd_M(i, j)\n  = \\sqrt{ (X_i - X_j)^{\\top} \\Sigma^{-1} (X_i - X_j) }.\n\\]\nIntuitsioon:\n\neukleidiline kaugus käsitleb kõiki tunnuseid sama kaaluga ja eeldab, et tunnused on võrreldavad skaalas;\n\nMahalanobise kaugus standardiseerib tunnused vastavalt nende dispersioonile ja arvestab ka korrelatsioone tunnuste vahel (kovariatsioonimaatriksi kaudu);\n\nkaks inimest on “lähedal”, kui nad on sarnased mitte ainult iga tunnuse osas eraldi, vaid ka nende kombinatsioonide osas, võttes arvesse tüüpilist variatsiooni.\n\nLigikaudse sobitamise puhul sobitame osalejate ja võrdlusgrupi isikuid nii, et Mahalanobise kaugus nende vahel oleks minimaalne. Praktikas kasutatakse tihti pakette (nt MatchIt), kus saab valida distance = \"mahalanobis\", ning funktsioon arvutab kaugused automaatselt.\n\n\nTõenäosusskoori alusel sobitamine (propensity score matching)\nTõenäosusskoor (propensity score) on meetmes osalemise tõenäosus antud tunnuste \\(X\\) korral:\n\\[\np(X_i) = \\Pr(D_i = 1 \\mid X_i).\n\\]\nRosenbaum ja Rubin näitasid, et kui CIA kehtib \\(X\\) suhtes, siis piisab sellest, et CIA kehtiks ka tõenäosusskoori suhtes:\n\\[\n(Y_i(0), Y_i(1)) \\perp D_i \\mid p(X_i).\n\\]\nSee tähendab, et kui sobitame inimesi ainult tõenäosusskoori \\(p(X)\\) alusel, siis tasakaalustame ka kõik \\(X\\)-id, mida kasutati p-skoori hindamisel (eeldusel, et mudel on sobiv).\nPraktiline sammude jada on:\n\nHinda meetmes osalemise tõenäosus \\(p(X)\\) sobiva mudeliga (tihti logit või probit).:contentReferenceoaicite:4\n\nKontrolli, kas osalus- ja võrdlusgrupi tõenäosusskoori jaotused kattuvad piisavalt (ühise toe eeldus).\n\nSobita osalejad ja võrdlusgrupi isikud p-skoori alusel (nt lähim naaber, kalibersobitamine jne).\n\nHinda mõju, kasutades sobitatud paare või alamtunde.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html#sobitamine-tõenäosusskoori-alusel",
    "href": "06-sobitamine.html#sobitamine-tõenäosusskoori-alusel",
    "title": "7  Sobitamine",
    "section": "7.4 Sobitamine tõenäosusskoori alusel",
    "text": "7.4 Sobitamine tõenäosusskoori alusel\nTõenäosusskoori alusel sobitamisel ei mõõdeta enam kaugust otse \\(X\\)-i ruumis, vaid p-skoori vahemikus [0,1]. Näiteks:\n\niga osaleja \\(i\\) jaoks valime võrdlusgrupi isiku(d) \\(j\\), millel \\(|p(X_i) - p(X_j)|\\) on minimaalne;\n\ntihti kasutatakse kalibrit (caliper), st lubatakse ainult neid vasteid, mille p-skoor jääb etteantud kaugusvahemikku (nt 0,01 või 0,05);\n\nvõimalik on üks-ühele (1:1) või üks-mitmele (1:M) sobitamine.\n\nSobitamine tõenäosusskoori alusel vähendab mõõtmelisuse probleemi: kõrged mõõtmed \\(X\\)-is asendame ühe mõõtmega \\(p(X)\\). Samas muutub oluliseks, kui hästi on p-skoori mudel spetsifitseeritud; halb mudel tähendab halba tasakaalu.\n\nSobitamisel tehtavad valikud\nSobitamine ei ole üks meetod, vaid terve perekond meetodeid. Praktikas tuleb teha rida olulisi valikuid.\n\n\n1. Mille alusel sobitada: X vs p(X)\nMõõde, kus sobitatakse, võib olla:\n\notse tunnuste \\(X\\) ruum (täpne sobitamine, Mahalanobise kaugus, standardiseeritud eukleidiline kaugus),\n\ntõenäosusskoor \\(p(X)\\),\n\nmõnikord ka šansside suhe (odds): \\(\\frac{p(X)}{1-p(X)}\\).\n\nValik sõltub sellest, kas meil on:\n\npiisavalt suur võrdlusgrupp, et kasutada Mahalanobise kaugust mitmemõõtmelises ruumis;\n\nhästi spetsifitseeritud mudel, millega hinnata p-skoori.\n\n\n\n2. Sobitamisalgoritm: lähim naaber ja muud\nLevinumad algoritmid:\n\ntäpne sobitamine (exact matching);\n\nlähima naabriga sobitamine (nearest neighbor matching):\n\n1:1 sobitamine,\n\n1:M sobitamine (nt 1:2, 1:4);\n\n\noptimaalne sobitamine (optimal matching), mis valib sobitused nii, et summaarne kaugus kõigi paaride peale oleks minimaalne;\n\ntäielik sobitamine (full matching), kus iga osaleja ja võrdlusgrupi liige kuulub mõnda sobitamisrühma;\n\nsobitamine alamklassides (subclassification, nt jaotame p-skoori kvintiilidesse ja võrdleme nendes);\n\ngeneetiline sobitamine (genetic matching), mis kohandab automaatselt tunnuste kaalud, et tasakaal oleks parem.\n\n\n\n3. Üks-ühele või üks-mitmele, tagasipanekuga või ilma\nOlulised disainivalikud:\n\n1:1 vs 1:M:\n\n1:1 annab väga sarnased paarid, väiksem variatsioon, aga suurem dispersioon hinnangul;\n\n1:M kasutab rohkem infot võrdlusgrupist, vähendades dispersiooni, kuid suurendades võimalikku nihet (kaugemad naabrid).\n\n\ntagasipanekuga (with replacement) vs tagasipanekuta:\n\ntagasipanekuga sobitamisel võib sama võrdlusgrupi isik olla mitme osaleja vaste;\n\nsee lubab leida paremaid vasteid, eriti kui võrdlusgrupp on väike;\n\ntagasipanekuta sobitamisel kasutatakse iga võrdlusgrupi isikut ainult üks kord, mis võib tasakaalu halvendada, kuid vähendab kaalu kontsentreerumist mõnele vähesele vaatlusel.\n\n\nPraktikalised soovitused:\n\nkasuta pigem väikest M-i (nt 1 või 2),\n\nkasuta pigem tagasipanekuga sobitamist, kui võrdlusgrupp ei ole väga suur,\n\nveendu, et võrdlusgrupp oleks piisavalt suur, et sobitada iga osaleja jaoks mõistlik vaste.:contentReferenceoaicite:7\n\n\n\n4. Ühine tugi, kaliiber ja trimming\nSobitamisel on väga oluline ühise toe (common support) eeldus:\n\nosalejate p-skoorid ei tohiks üldiselt olla palju suuremad kui võrdlusgrupil;\n\nkui osaleja p-skoor on 0,95, aga võrdlusgrupi suurim p-skoor 0,6, siis sellele osalejale head vastet ei leia.\n\nSelle tagamiseks kasutatakse:\n\nkaliibersobitamist (caliper): lubame sobitada ainult siis, kui \\(|p_i - p_j|\\) on väiksem kui etteantud piir (nt 0,01 või 0,05);\n\ntrimming’ut: lõikame ära vaatlused, mille p-skoorid on äärmuslikud (nt eemaldame võrdlusgrupist väga väikese p-skooriga vaatlused või osalejad, kelle p-skoorid on suuremad kui võrdlusgrupi maksimum).\n\nÜhise toe tagamine vähendab kalduvust ekstrapoleerida väljapoole tegelikku kattuvat piirkonda.\n\n\n5. Tasakaalu kontroll ja edasine modelleerimine\nPärast sobitamist tuleb alati kontrollida, kui hästi tasakaal on saavutatud:\n\nvõrrelda keskmisi ja jaotusi tunnuste \\(X\\) osalus- ja võrdlusgrupis;\n\njälgida standardiseeritud keskmiste erinevust (Std. Mean Diff.), variatsioonisuhet ja empiirilist jaotust (eCDF).\n\nSageli kasutatakse ka:\n\ntäiendavat regressioonimudelit sobitatud valimil (double robust methods), et eemaldada allesjäänud väikseid erinevusi \\(X\\)-des;\n\nspetsiaalset standardvigade arvutust (Abadie–Imbens), sest klassikaline bootstrapping ei anna sobitamise korral alati korrektseid tulemusi.\n\n\n\nKokkuvõte\nSobitamine on paindlik meetod, mis:\n\nüritab imiteerida juhuslikku eksperimenti, luues iga osaleja jaoks sarnase võrdlusisiku;\n\ntugineb eeldustele CIA (tingimuslik sõltumatus) ja ühine tugi;\n\nvõib toimuda otse tunnuste \\(X\\) ruumis (Mahalanobise kaugus) või tõenäosusskoori \\(p(X)\\) kaudu (propensity score matching);\n\nnõuab mitmeid valikuid: kaugusmõõdik, sobitamisalgoritm, 1:1 vs 1:M, tagasipanek, kaliiber, trimming.\n\nHea praktika hõlmab:\n\nhoolikat mudeli spetsifitseerimist p-skoori hindamiseks;\n\ntasakaalu põhjalikku kontrolli pärast sobitamist;\n\nvajadusel täiendavat regressiooniparandust sobitatud valimil.\n\nSobitamine ei lahenda probleemi jälgimata teguritest (U), kuid korrektsete eelduste korral vähendab oluliselt valikunihet ja annab usutavama hinnangu põhjuslikule mõjule kui lihtne regressioon samade andmete peal.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "06-sobitamine.html#näide-eesti-tööpoliitika-põhjal",
    "href": "06-sobitamine.html#näide-eesti-tööpoliitika-põhjal",
    "title": "7  Sobitamine",
    "section": "7.5 Näide Eesti tööpoliitika põhjal",
    "text": "7.5 Näide Eesti tööpoliitika põhjal\n\nVajaminevad paketid\n\nlibrary(dplyr) #andmete teisendamine\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2) #joonised\nlibrary(stargazer) #regressioonimudeli tabelite kenasti esitamiseks\n\n\nPlease cite as: \n\n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n\n\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\nlibrary(lmtest) #coeftest käsu jaoks\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nlibrary(sandwich) #robustsete standardvigade jaoks\nlibrary(MatchIt) #sobitamise jaoks\nlibrary(margins) #marginaalsed efektid\n\n\n\nAndmed\nAndmed on anonümiseeritud andmed uuringust Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 2003, 108 lk\nVt peatükki XXX andmete kirjelduse kohta eespool.\n\natp &lt;- read.csv(\"http://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\")\nsummary(atp)\n\n       id            training        training1        training2     \n Min.   :   2.0   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.: 477.5   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 888.0   Median :0.0000   Median :0.0000   Median :1.0000  \n Mean   : 901.7   Mean   :0.3282   Mean   :0.2797   Mean   :0.5735  \n 3rd Qu.:1315.0   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1834.0   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                   NA's   :88       NA's   :559     \n   training3        training4        training5           kaal       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.577  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 3.644  \n Median :1.0000   Median :0.0000   Median :0.0000   Median :13.667  \n Mean   :0.5167   Mean   :0.3865   Mean   :0.3227   Mean   :13.102  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:17.925  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :48.930  \n NA's   :647      NA's   :787      NA's   :836                      \n      male             est              age           langest      \n Min.   :0.0000   Min.   :0.0000   Min.   :16.00   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:25.00   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :34.00   Median :1.0000  \n Mean   :0.3191   Mean   :0.3849   Mean   :34.91   Mean   :0.5004  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:43.00   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :62.00   Max.   :1.0000  \n                                                                   \n   emplbefore          educ           county           town       \n Min.   :0.0000   Min.   :1.000   Min.   : 1.00   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:2.000   1st Qu.: 1.00   1st Qu.:1.0000  \n Median :1.0000   Median :3.000   Median :44.00   Median :1.0000  \n Mean   :0.8776   Mean   :2.847   Mean   :32.46   Mean   :0.8921  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:44.00   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :4.000   Max.   :84.00   Max.   :1.0000  \n                                                                  \n    children         marital          nwage           status     \n Min.   :0.0000   Min.   :0.000   Min.   :    0   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:    0   1st Qu.:1.000  \n Median :0.0000   Median :1.000   Median : 1700   Median :1.000  \n Mean   :0.5976   Mean   :1.008   Mean   : 1796   Mean   :1.516  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.: 3000   3rd Qu.:2.000  \n Max.   :8.0000   Max.   :4.000   Max.   :20000   Max.   :3.000  \n                                  NA's   :51                     \n      age2          employed     \n Min.   : 2.56   Min.   :0.0000  \n 1st Qu.: 6.25   1st Qu.:0.0000  \n Median :11.56   Median :1.0000  \n Mean   :13.38   Mean   :0.6289  \n 3rd Qu.:18.49   3rd Qu.:1.0000  \n Max.   :38.44   Max.   :1.0000  \n                                 \n\n\nFailis on toodud järgmised andmed:\n\n\n\n\n\n\n\nMuutuja\nSelgitus\n\n\n\n\nid\nInimese id\n\n\ntraining\nTunnus kas sai tööturukoolitust või ei 2000. aasta esimeses pooles\n\n\ntraining1\nosalusrühm tingimisel, et ei nõutud tõendit hilisema töö saamise kohta - kellelt nõuti, neil puuduv väärtus\n\n\ntraining2\nvõrdlusgrupis, kes soovisid, kuid ei saanud/soovinud osaleda mingil põhjusel\n\n\ntraining3\nKombinatsioon training 2 ja training 3: need osalusgrupist, kellelt ei nõutud töökohta; need võrdlusgrupist, kes uurisid koolitust, kuid ei osalenud\n\n\ntraining4\nkoolituse osalusrühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid\n\n\ntraining5\nkoolituse põhirühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid ja kellelt ei nõutud tõendit\n\n\nweight\nVaatluse statistiline kaal\n\n\nmale\nMeessoost\n\n\nest\nEestlane\n\n\nage\nVanus aastates 2002. aastal\n\n\nlangest\nKas oskab eesti keelt\n\n\nemplbefore\nKas oli töökogemus enne töötuks registreerimist 2000. aastal\n\n\neduc\nHaridustase, 1 ISCED0,1,2 põhiharidus; 2 ISCED3 puhas keskharidus; 3 ISCED3,4 kutsekeskharidus; 4 ISCED5,6 kõrgharidus\n\n\ncounty\nMaakond: Tallinn, Viljandimaa, Tartumaa, Ida-Virumaa\n\n\ntown\nElab linnas vs maal\n\n\nchildren\nLaste arv töötuks registreerimise hetkel\n\n\nmarital\nPerekonna seis töötuks registreerimise hetkel: 0 vallaline; 1 abielus; 2 vabaabielu; 3 lahutatud; 4 lesk\n\n\nnwage\nNetopalk 2002. aasta septembris\n\n\nstatus\nTööturustaatus 2002. aasta septembris (1- hõivatud, 2 – töötu, 3 – mitteaktiivne\n\n\nemployed\nHõivatus 2002. aasta septembris (1- hõivatud, 0 – töötu või mitteaktiivne)\n\n\n\nTunnus meetmes osalemise kohta on training. Teised sama algusega tunnused kitsendavad valimit ja neid kasutati eemaldamaks võimalike mittejälgitavate tegurite mõju.\nPõhilised väljundtunnused on employed ja nwage, mis näitavad hõivatust ja netopalka peale koolitust 2002. aasta septembris.\n\n\nRegressioonimudel\nHindame meeldetuletuseks regressioonimudeli mõlema väljundi kohta.\n\n#töötamise tõenäosus\nlin_employed&lt;-lm(employed ~ training + male + est+ age + age2  + educ + emplbefore, data=atp)\nsummary(lin_employed)\n\n\nCall:\nlm(formula = employed ~ training + male + est + age + age2 + \n    educ + emplbefore, data = atp)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9244 -0.5401  0.2653  0.3765  0.6479 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.150702   0.151243  -0.996 0.319230    \ntraining     0.098164   0.028163   3.486 0.000507 ***\nmale         0.079865   0.028660   2.787 0.005404 ** \nest          0.097111   0.027131   3.579 0.000357 ***\nage          0.029458   0.009727   3.029 0.002506 ** \nage2        -0.040217   0.012640  -3.182 0.001499 ** \neduc         0.052652   0.014820   3.553 0.000395 ***\nemplbefore   0.050641   0.051680   0.980 0.327316    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4721 on 1299 degrees of freedom\nMultiple R-squared:  0.05091,   Adjusted R-squared:  0.0458 \nF-statistic: 9.954 on 7 and 1299 DF,  p-value: 3.735e-12\n\n#robustsed standardvead\ncoeftest(lin_employed, vcov = vcovHC(lin_employed, \"HC1\"))    # robust; HC1 (Stata default)\n\n\nt test of coefficients:\n\n              Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -0.1507018  0.1515159 -0.9946 0.3201030    \ntraining     0.0981644  0.0276483  3.5505 0.0003983 ***\nmale         0.0798648  0.0287212  2.7807 0.0055027 ** \nest          0.0971112  0.0269472  3.6038 0.0003255 ***\nage          0.0294581  0.0097875  3.0098 0.0026649 ** \nage2        -0.0402165  0.0127430 -3.1560 0.0016364 ** \neduc         0.0526515  0.0149605  3.5194 0.0004475 ***\nemplbefore   0.0506414  0.0521807  0.9705 0.3319782    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#palk\nlin_nwage&lt;-lm(nwage ~ training + male + est+ age + age2  + educ + emplbefore, data=atp)\nsummary(lin_nwage)\n\n\nCall:\nlm(formula = nwage ~ training + male + est + age + age2 + educ + \n    emplbefore, data = atp)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3601.6 -1376.4   -65.4  1029.0 17667.7 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1284.89     616.09  -2.086  0.03722 *  \ntraining      254.85     115.55   2.206  0.02760 *  \nmale          871.32     117.29   7.429 2.02e-13 ***\nest           821.64     111.41   7.375 2.99e-13 ***\nage            82.58      39.67   2.082  0.03758 *  \nage2         -133.72      51.46  -2.598  0.00948 ** \neduc          297.94      60.90   4.892 1.13e-06 ***\nemplbefore    540.06     212.94   2.536  0.01133 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1888 on 1248 degrees of freedom\n  (51 observations deleted due to missingness)\nMultiple R-squared:  0.1093,    Adjusted R-squared:  0.1043 \nF-statistic: 21.88 on 7 and 1248 DF,  p-value: &lt; 2.2e-16\n\n#robustsed standardvead\ncoeftest(lin_nwage, vcov = vcovHC(lin_nwage, \"HC1\"))    # robust; HC1 (Stata default)\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -1284.892    687.883 -1.8679   0.06201 .  \ntraining      254.849    111.157  2.2927   0.02203 *  \nmale          871.323    138.002  6.3139 3.775e-10 ***\nest           821.638    127.202  6.4593 1.504e-10 ***\nage            82.575     43.003  1.9202   0.05506 .  \nage2         -133.722     53.949 -2.4786   0.01332 *  \neduc          297.938     61.364  4.8553 1.354e-06 ***\nemplbefore    540.056    220.406  2.4503   0.01441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#esitame ühes tabelis\n#Pane tähele, et \"se = ...\" võtab lihtsalt diagonaalelemendid kovariatsioonimaatriksist\nstargazer(lin_employed, lin_nwage, type=\"text\", se=list(sqrt(diag(vcovHC(lin_employed, type = \"HC1\"))),sqrt(diag(vcovHC(lin_nwage, type = \"HC1\"))) ))\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                           employed                  nwage          \n                              (1)                     (2)           \n--------------------------------------------------------------------\ntraining                   0.098***                254.849**        \n                            (0.028)                (111.157)        \n                                                                    \nmale                       0.080***                871.323***       \n                            (0.029)                (138.002)        \n                                                                    \nest                        0.097***                821.638***       \n                            (0.027)                (127.202)        \n                                                                    \nage                        0.029***                 82.575*         \n                            (0.010)                 (43.003)        \n                                                                    \nage2                       -0.040***               -133.722**       \n                            (0.013)                 (53.949)        \n                                                                    \neduc                       0.053***                297.938***       \n                            (0.015)                 (61.364)        \n                                                                    \nemplbefore                   0.051                 540.056**        \n                            (0.052)                (220.406)        \n                                                                    \nConstant                    -0.151                -1,284.892*       \n                            (0.152)                (687.883)        \n                                                                    \n--------------------------------------------------------------------\nObservations                 1,307                   1,256          \nR2                           0.051                   0.109          \nAdjusted R2                  0.046                   0.104          \nResidual Std. Error    0.472 (df = 1299)     1,888.387 (df = 1248)  \nF Statistic         9.954*** (df = 7; 1299) 21.885*** (df = 7; 1248)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nOle valmis vastama:\n\nKui palju koolituses osalemine suurendas tõenäosust töötada?\nKui palju suurendas palka?\nKas mõju on statistiliselt olulised?\nMõtle: kas mõju on majanduslikult oluline? Kuidas seda analüüsida?\n\n\n\nSobitamine\nSobitamiseks on palju erinevaid pakette Ris. Peamised neist on Matching ja MatchIt.\nKasutame alljärgnevalt paketti MatchIt, vaata ka https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html\nAnalüüs toimub järgmiste sammudena:\n\nSobitamine, sihtrühma määramine: kas hindame mõju osalejatele - ATT - või mitteosalejatele - ATU)\nSobitamise kvaliteedi hindamine: kas osalus- ja võrdlusrühm on piisavalt sarnased peamiste tunnuste osas\nSobitatud andmete väljavõtmine: salvestame sobitatud andmed koos vajaliku lisainfoga (nt mitu korda üks inimene on võrdlusrühmas)\nMõju hindamine sobitatud andmetega: kas lihtne kaalutud keskmine või regressioonimudeli kordaja\n\nSobitamisel on palju erinevai valikuid: täpne sobitamine (exact), lähim naaber, CEM (coarsened exact matching), optimaalne sobitamine, täielik sobitamine, sobitamine alamklassides (“subclass”) või geneetiline sobitamine.\nMeie vaatame siin praktikumis kahte esimest lähenemist: täpne sobitamine ja lähim naaber.\n\n\nTäpne sobitamine\nSobitame esiteks vaid soo, rahvuse, hariduse lõikes.\n\nm.outexact &lt;- matchit(training ~ male + est  + educ, method=\"exact\", data=atp)\n#Informatsioon, mida tegime\nm.outexact\n\nA `matchit` object\n - method: Exact matching\n - number of obs.: 1307 (original), 1307 (matched)\n - target estimand: ATT\n - covariates: male, est, educ\n\n\nVaatame väljundit summary käsuga.\n\nsummary(m.outexact)\n\n\nCall:\nmatchit(formula = training ~ male + est + educ, data = atp, method = \"exact\")\n\nSummary of Balance for All Data:\n     Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\nmale        0.2821        0.3371         -0.1224          .    0.0551   0.0551\nest         0.4289        0.3633          0.1325          .    0.0656   0.0656\neduc        2.9907        2.7768          0.2313     1.0103    0.0535   0.1233\n\nSummary of Balance for Matched Data:\n     Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\nmale        0.2821        0.2821              -0          .         0        0\nest         0.4289        0.4289               0          .         0        0\neduc        2.9907        2.9907               0      1.001         0        0\n     Std. Pair Dist.\nmale               0\nest                0\neduc               0\n\nSample Sizes:\n              Control Treated\nAll            878.       429\nMatched (ESS)  752.91     429\nMatched        878.       429\nUnmatched        0.         0\nDiscarded        0.         0\n\n\nVaadake jaotust “Sample Sizes”.\nKas kõik osalejad (Treated) leidsid endale samasuguse mitte-osaleja (Control)?\nAndmete sarnasust enne sobitamist näitab jaotus: “Summary of Balance for All Data”\nSobitamise kvaliteeti aitab hinnata jaotus: “Summary of Balance for Matched Data”\nVeerud:\n\nMeans Treated - osalusrühma keskmised\nMeans Control - võrdlusrühma keskmised\nStd. Mean Diff. - keskmiste standardiseeritud erinevus\nVar. Ratio - dispersioonide suhe osalus- ja võrdlusrühmas\neCDF Mean - keskmine erinevus empiirilisies kumulatiivses jaotusfunktsioonis (empirical Cumulative Distribution Function)\neCDF Max - suurim erinevus empiirilisies kumulatiivses jaotusfunktsioonis (empirical Cumulative Distribution Function)\nStd. Pair Dist. - standardiseeritud erinevus osalus- ja võrdlusrühma vahel\nMatched (ESS) - “effective sample size” - kui palju tegelikult vaatlusi kasutati.\n\n\n\nSobitatud andmete saamine ja vaatamine\nKui oleme sobitamise kvaliteediga rahul, siis eraldame sobitatud andmed ja teeme edasi analüüsi. Käsuga match.data saame andmed objektist kätte. See sisaldab ka esialgseid tunnuseid.\n\nm.dataexact &lt;- match.data(m.outexact)\n\nVaadake andmeid ja tekkinud lisamuutujad.\nAndmetesse tekkinud tunnus subclass näitab, mis gruppi vaatlus kuulus. Ühte gruppi kuuluvate vaatluste sobitatud tunnused on ühesuguse väärtusega. Tunnust subclass võime võtta arvesse hinnangute standardvigade arvutamisel.\nMuutuja weights annab kaalu igale osalus- ja võrdlusrühma vaatlusele antud grupis. Osalusrühma kaal on 1 ja võrdlusrühma kaal täpse sobitamise korral võrdub osalus- ja võrdlusvaatluste suhtega antud kihis, mida pärast skaleeritakse vastavalt osalus- ja võrdlusrühma suurusele andmetes.\nIga võrdlusvaatluse jaoks \\(i\\), mis kuulub kihti \\(s\\), leitakse kaal, kui\n\\[\nw_i^{(C)} = \\frac{n_T^s}{n_C^s} \\times \\frac{N_C}{N_T},\n\\]\nkus \\[\\begin{align*}\nn_T^s & = \\text{osalusvaatlused kihis } s, \\\\\nn_C^s & = \\text{võrdlusvaatlused kihis } s, \\\\\nN_T   & = \\text{kokku osalusvaatlusi andmetes}, \\\\\nN_C   & = \\text{kokku võrdlusvaatlusi andmetes.}\n\\end{align*}\\]\nOsalusvaatluste jaoks on kaal alati 1.\n\\[\nw_i^{(T)} = 1\n\\]\nKasutame summary käsku, et vaadata kaalude jaotust.\n\n#osalusgrupi kaalude jaotus\nsummary(m.dataexact$weights[m.dataexact$training==1])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       1       1       1       1       1 \n\n#võrdlusgrupi kaalude jaotus sobitatud andmestikus\nsummary(m.dataexact$weights[m.dataexact$training==0])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4309  0.7163  0.8269  1.0000  1.3705  1.8978 \n\n\nVõrdlusrühma kaalud on skaleeritud selliselt, et nende summa annab kokku esialgse valimi suuruse. Vaadake, et kaalude summa on esialgne mitteosalejate arv.\n\nsum(m.dataexact$weights[m.dataexact$training==0])\n\n[1] 878\n\n\n\ntable(m.dataexact$subclass, m.dataexact$training)\n\n    \n       0   1\n  1  112  75\n  2   29   8\n  3   55  51\n  4   61  50\n  5  127  48\n  6  100  35\n  7   45  16\n  8   19   4\n  9   79  37\n  10  53  15\n  11  99  40\n  12  24  20\n  13  19   7\n  14  18   9\n  15  25   8\n  16  13   6\n\n\nVastake küsimustele\n\nMitu sarnaste tunnustega gruppi meil andmetes tekib?\nKuhu gruppi kuulub kõige rohkem osalusvaatlusi?\nKuidas leida, mis selgitava tunnuse väärtused selles grupis on?\n\n\nMõju hindamine sobitatud andmetes\nKui andmed on olemas, siis hindame mõju regressioonimudeliga kasutades sobitamisega saadud kaale vaatlustele.\nMõju palgale:\n\nmudel1 &lt;- lm(nwage ~ training, data = m.dataexact, weights = weights)\nsummary(mudel1)\n\n\nCall:\nlm(formula = nwage ~ training, data = m.dataexact, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-2425.6 -1548.6  -141.4   958.4 17726.8 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1760.74      68.94  25.542   &lt;2e-16 ***\ntraining      280.87     120.51   2.331   0.0199 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1999 on 1254 degrees of freedom\n  (51 observations deleted due to missingness)\nMultiple R-squared:  0.004314,  Adjusted R-squared:  0.00352 \nF-statistic: 5.433 on 1 and 1254 DF,  p-value: 0.01992\n\n\nKui suur on koolituse mõju palgale?\nHnnake sobitatud andmetel ka lineaarne tõenäosusmudel, kus väljundiks on töötamine.\n\nmudel1b &lt;- lm(employed ~ training, data = m.dataexact, weights = weights)\nsummary(mudel1b)\n\n\nCall:\nlm(formula = employed ~ training, data = m.dataexact, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-0.8333 -0.5320  0.2914  0.3475  0.5443 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.60487    0.01614  37.480  &lt; 2e-16 ***\ntraining     0.10376    0.02817   3.683  0.00024 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4782 on 1305 degrees of freedom\nMultiple R-squared:  0.01029,   Adjusted R-squared:  0.009531 \nF-statistic: 13.57 on 1 and 1305 DF,  p-value: 0.0002396\n\n\nMis on mõju töötamise tõenäosusele?\n\n\n\nKui täpselt enam ei saa sobitada\nLisame täpsete tunnuste hulka ka vanuse ja kordame protsessi.\n\nm.outexact2 &lt;- matchit(training ~ male + est  + educ + age,method=\"exact\", data=atp)\nm.outexact2\n\nA `matchit` object\n - method: Exact matching\n - number of obs.: 1307 (original), 878 (matched)\n - target estimand: ATT\n - covariates: male, est, educ, age\n\nsummary(m.outexact2)\n\n\nCall:\nmatchit(formula = training ~ male + est + educ + age, data = atp, \n    method = \"exact\")\n\nSummary of Balance for All Data:\n     Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\nmale        0.2821        0.3371         -0.1224          .    0.0551   0.0551\nest         0.4289        0.3633          0.1325          .    0.0656   0.0656\neduc        2.9907        2.7768          0.2313     1.0103    0.0535   0.1233\nage        34.3636       35.1788         -0.0797     0.8261    0.0253   0.0620\n\nSummary of Balance for Matched Data:\n     Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\nmale        0.2421        0.2421               0          .         0        0\nest         0.3977        0.3977              -0          .         0        0\neduc        3.0231        3.0231               0     0.9998         0        0\nage        33.8329       33.8329               0     0.9998         0        0\n     Std. Pair Dist.\nmale               0\nest                0\neduc               0\nage                0\n\nSample Sizes:\n              Control Treated\nAll            878.       429\nMatched (ESS)  326.18     347\nMatched        531.       347\nUnmatched      347.        82\nDiscarded        0.         0\n\n\nKui palju vaatlusi jäi sobitamata?\nSeega täpne sobitamine ei ole võimalik, kui vaatluste arv on väike ja tunnuste arv on suur.\n\n\nLähima naabriga sobitamine\nLähima naabriga sobitamine toimub, kui valida method = \"nearest\". Valik ratio näitab mitu võrdlusrühma elementi võetakse ühe osalusrühma kohta; vaikimisi ratio = 1. Kui soovitakse üks mitmele sobitamist, nt 1:4, siis peab panema ratio = 4. Kui soovitakse tagasipanekuga sobitamist (vajalik, kui võrdlusgrupp ei ole väga suur), siis peab lisaks panema replace= TRUE.\nKasutame Mahalanobise kaugust: distance=“mahalanobis”. Soovime leida sarnased vaatlused osalusrühma jaoks: estimand = “ATT”.\n\nmnn &lt;- matchit(training ~ male + age + est  + emplbefore + educ,  \n               method=\"nearest\", \n               distance=\"mahalanobis\",  \n               data=atp, \n               ratio = 1, \n               replace = TRUE,\n               estimand = \"ATT\")\n\nmnn\n\nA `matchit` object\n - method: 1:1 nearest neighbor matching with replacement\n - distance: Mahalanobis - number of obs.: 1307 (original), 698 (matched)\n - target estimand: ATT\n - covariates: male, age, est, emplbefore, educ\n\nsummary(mnn)\n\n\nCall:\nmatchit(formula = training ~ male + age + est + emplbefore + \n    educ, data = atp, method = \"nearest\", distance = \"mahalanobis\", \n    estimand = \"ATT\", replace = TRUE, ratio = 1)\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nmale              0.2821        0.3371         -0.1224          .    0.0551\nage              34.3636       35.1788         -0.0797     0.8261    0.0253\nest               0.4289        0.3633          0.1325          .    0.0656\nemplbefore        0.8718        0.8804         -0.0258          .    0.0086\neduc              2.9907        2.7768          0.2313     1.0103    0.0535\n           eCDF Max\nmale         0.0551\nage          0.0620\nest          0.0656\nemplbefore   0.0086\neduc         0.1233\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nmale              0.2821        0.2821           0.000          .    0.0000\nage              34.3636       34.2611           0.010     1.0002    0.0042\nest               0.4289        0.4289           0.000          .    0.0000\nemplbefore        0.8718        0.8718           0.000          .    0.0000\neduc              2.9907        2.9860           0.005     1.0030    0.0012\n           eCDF Max Std. Pair Dist.\nmale         0.0000          0.0000\nage          0.0186          0.0333\nest          0.0000          0.0000\nemplbefore   0.0000          0.0000\neduc         0.0047          0.0050\n\nSample Sizes:\n              Control Treated\nAll            878.       429\nMatched (ESS)  201.14     429\nMatched        269.       429\nUnmatched      609.         0\nDiscarded        0.         0\n\n\nKui palju võrdlusgrupi vaatlustest kasutati seekord lähima naabri leidmisel? Vaata “Sample Sizes:” =&gt; “Control”: =&gt; “Matched”.\nKui sarnased on sobitatud andmed? Millises tunnuses jäi suurim suhteline erinevus? (Std. Mean Diff)\nSama asi ülevaatlikult joonisel.\n\nplot(summary(mnn))\n\n\n\n\n\n\n\n\nPidevate suuruste puhul võime lähemalt vaadata ka jaotuste võrdlust:\n\n#Tihedusfunktsioon\nplot(mnn, type = \"density\", which.xs = ~age + educ)\n\n\n\n\n\n\n\n#Jaotusfunktsioon\nplot(mnn, type = \"ecdf\",  which.xs = ~age + educ)\n\n\n\n\n\n\n\n#QQ-joonis\nplot(mnn, which.xs = ~age + educ)\n\n\n\n\n\n\n\n\nTulemuseks on erinevad joonised, kasutatakse sobitamise kontekstis, et hinnata muutujate tasakaalu enne ja pärast sobitamist.\nVeerus “All” (Kõik vaatlused) - näitab muutujate (vanus ja haridus) jaotusele enne sobitamist nii osalus- kui võrdlusrühmas. Veerus “Matched” (Sobitatud vaatlused) - Siin näidatakse muutujate jaotust pärast sobitamist, kus ideaalis peaksid osalus ja võrdlusrühm olema muutujate lõikes sarnasemad.\nKui valida tüübiks “eQQ plot” ehk empiiriline kvantiil-kvantiil diagramm, siis ideaalne tasakaal on siis, kui punktid (vaatlused) on 45-kraadise joone lähedal. - Enne sobitamist (“All” veerg) võivad punktid olla rohkem hajutatud, mis näitab tasakaalutust nende muutujate vahel osalus- ja võrdlusrühma vahel. - Pärast sobitamist (“Matched” veerg) peaksid punktid ideaalis olema lähemal 45-kraadisele joonele, mis viitab sellele, et sobitusprotseduur on edukalt tasakaalustanud osalus- ja võrdlusrühma nende muutujate lõikes.\nKatkendjooned esindavad piire, mille sees loetakse tasakaalu vastuvõetavaks. Kui enamik punkte jääb nende joonte vahele, tähendab see, et muutujad on hästi tasakaalus pärast sobitamist.\nMeie tulemuste puhul näib sobitamine olevat tasakaalu parandanud, eriti vanuse osas, kuid hariduse osas võib veel olla mõningaid tasakaalustamatuse märke (mõned punktid on “Matched” veerus educ muutuja puhul diagonaalist kaugemal).\n\n\nMõju hindamine sobitatud andmetel\nVõtame andmed taas välja.\n\nmdatann &lt;- match.data(mnn)\n\nJa hindame sobitatud andmetel mõju lineaarse mudeliga palgale ja töötamise tõenäosusele.\n\nmudel2 &lt;- lm(nwage  ~  training, data = mdatann, weights = weights)\nsummary(mudel2)\n\n\nCall:\nlm(formula = nwage ~ training, data = mdatann, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-3454.5 -1551.6   -64.2   965.3 15923.2 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1781.0      117.9  15.106   &lt;2e-16 ***\ntraining       260.6      151.3   1.722   0.0855 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1918 on 671 degrees of freedom\n  (25 observations deleted due to missingness)\nMultiple R-squared:  0.004402,  Adjusted R-squared:  0.002918 \nF-statistic: 2.967 on 1 and 671 DF,  p-value: 0.08546\n\ncoeftest(mudel2, vcov = vcovHC(mudel2, \"HC3\"))    # robustsed standarvead\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1781.01     152.22 11.6999   &lt;2e-16 ***\ntraining      260.60     176.69  1.4749   0.1407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nKüsimus: mis on mõju palgale punkthinnang? Kas see on statistiliselt oluline?\nLeidke iseseisvalt, kui suur on koolituse mõju hilisemale töötamise tõenäosusele?\n\n###\n\n\n\nSobitatud andmete vaatamine\nVõime ka soovi korral vaadata, milliseid vaatlusi sobitati.\n\ngm &lt;- get_matches(mnn, id = \"idmatched\") %&gt;% select(subclass, training, idmatched, id, weights, est, age, male, educ, emplbefore, nwage, employed)\nhead(gm, 10)\n\n   subclass training idmatched   id weights est age male educ emplbefore nwage\n1         1        1         4    9       1   0  31    0    4          1  1650\n2         1        0      1136 1576       1   0  31    0    4          1  1615\n3         2        1        10   17       1   1  31    0    4          1  2500\n4         2        0       810 1085       1   1  31    0    4          1  4000\n5         3        1        12   21       1   1  27    0    1          1     0\n6         3        0      1268 1783       1   1  28    0    1          1     0\n7         4        1        14   25       1   1  51    1    3          1  2500\n8         4        0       831 1108       1   1  51    1    3          1    NA\n9         5        1        22   44       1   0  35    1    1          1  3000\n10        5        0       473  660       1   0  31    1    1          1     0\n   employed\n1         1\n2         1\n3         1\n4         1\n5         0\n6         0\n7         1\n8         1\n9         1\n10        0\n\n\nKontrollküsimus: kellega sobitati kokku inimene esialgse id-ga 44? Kas võrdlusgrupi inimene on identne?\nSageli soovime vaadata, kas mõni võrdlusrühma inimene on korduvalt kasutuses. Kui jah, siis see on pigem halb, sest tulemuse võivad olla tundlikud mõne üksiku vaatluse väärtustele.\n\n#Kood, mis näitab, mitu korda olid võrdlusrühma vaatlused kasutatud\ngm %&gt;%  filter(training ==0) %&gt;% \n  group_by(idmatched) %&gt;% \n  summarise(kordi = n()) %&gt;% \n  group_by(kordi) %&gt;% \n  summarise(ridu = n())\n\n# A tibble: 6 × 2\n  kordi  ridu\n  &lt;int&gt; &lt;int&gt;\n1     1   164\n2     2    70\n3     3    21\n4     4    10\n5     5     2\n6     6     2\n\n#Teeb sama (!)\n#table(table(gm$idmatched[gm$training == 0]))\n\n\nNt 164 vaatlust olid kasutuses 1 korra.\nNt kaks võrdlusrühma vaatlust olid kasutuses 2 korda(!).\n\n\n\nVahelepõige - logistiline mudel\nHinda,e vaikimisi järgmise mudeli\n\nosalemismudellogit &lt;- glm(training ~ male + age + est  + emplbefore + educ, \n                  family=binomial(link=\"logit\"), data=atp)\n\nKordajad - saame tõlgendada märki. Positiivne märk näitab, et see muutuja suurendab tõenäosust meetmes osaleda\n\nsummary(osalemismudellogit)\n\n\nCall:\nglm(formula = training ~ male + age + est + emplbefore + educ, \n    family = binomial(link = \"logit\"), data = atp)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.156763   0.282347  -4.097 4.19e-05 ***\nmale        -0.204959   0.131942  -1.553   0.1203    \nage         -0.012714   0.006431  -1.977   0.0480 *  \nest          0.299359   0.122216   2.449   0.0143 *  \nemplbefore   0.013852   0.205657   0.067   0.9463    \neduc         0.282598   0.067465   4.189 2.80e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1654.5  on 1306  degrees of freedom\nResidual deviance: 1625.6  on 1301  degrees of freedom\nAIC: 1637.6\n\nNumber of Fisher Scoring iterations: 4\n\n\nKeskmised marginaalsed efektid - saame tõlgendada ka suurust. Kui palju suureneb tõenäosus meetmes osaleda, kui selgitav tunnus suureneb ühe ühiku võrra.\n\nsummary(margins(osalemismudellogit))\n\n     factor     AME     SE       z      p   lower   upper\n        age -0.0027 0.0014 -1.9872 0.0469 -0.0054 -0.0000\n       educ  0.0609 0.0142  4.2883 0.0000  0.0331  0.0888\n emplbefore  0.0030 0.0444  0.0674 0.9463 -0.0839  0.0899\n        est  0.0646 0.0261  2.4694 0.0135  0.0133  0.1158\n       male -0.0442 0.0284 -1.5583 0.1192 -0.0998  0.0114\n\n\nNäiteks:\n\nvanuse suurenedes ühe aasta võrra, väheneb meetmes osalemise tõenäosus keskmiselt 0.27 protsendipunkti.\neestlastel on 6.46 protsendipunkti suurem tõenäosus meetmes osaleda kui mitte-eestlastel.\n\nTeha:\n\ntõlgendage muutujate “educ” ja “male” mõju.\nKas mõlemad on statistiliselt olulised?\n\nSiit mudelist leiamegi prognoositud tõenäosused kõigi inimeste jaoks ja nende alusel leitakse osalusrühmale sarnaseim võrdlusrühm.\n\natp$trainingphat &lt;- predict(osalemismudellogit, type = \"response\") #soovime tõenäosust\n\nVaatame ka joonisel tõenäosust jaotust:\n\nggplot(data = atp, aes(x = trainingphat, color = factor(training))) + \n  geom_density() +\n  theme_light()\n\n\n\n\n\n\n\n\nKõrvale ka probit-mudel\n\nosalemismudelprobit &lt;- glm(training ~ male + age + est  + emplbefore + educ, \n                  family=binomial(link=\"probit\"), data=atp)\n\natp$trainingphatprobit &lt;- predict(osalemismudelprobit, type = \"response\") #soovime tõenäosust\n\nJa lineaarne mudel\n\nosalemismudellpm &lt;- lm(training ~ male + age + est  + emplbefore + educ, data=atp)\natp$trainingphatlpm &lt;- predict(osalemismudellpm, type = \"response\") #soovime tõenäosust\n\nVõrdlus tabelis\n\nstargazer(osalemismudellpm, osalemismudellogit, osalemismudelprobit, \n          se=list(sqrt(diag(vcovHC(osalemismudellpm, type = \"HC1\"))), NULL, NULL),\n          type=\"text\", no.space = TRUE)\n\n\n===============================================================\n                                Dependent variable:            \n                    -------------------------------------------\n                                     training                  \n                              OLS           logistic   probit  \n                              (1)              (2)       (3)   \n---------------------------------------------------------------\nmale                        -0.043           -0.205    -0.125  \n                            (0.027)          (0.132)   (0.080) \nage                        -0.003**         -0.013**  -0.008** \n                            (0.001)          (0.006)   (0.004) \nest                         0.065**          0.299**   0.185** \n                            (0.027)          (0.122)   (0.075) \nemplbefore                   0.002            0.014     0.003  \n                            (0.046)          (0.206)   (0.125) \neduc                       0.060***         0.283***  0.173*** \n                            (0.014)          (0.067)   (0.041) \nConstant                   0.237***         -1.157*** -0.701***\n                            (0.061)          (0.282)   (0.171) \n---------------------------------------------------------------\nObservations                 1,307            1,307     1,307  \nR2                           0.022                             \nAdjusted R2                  0.018                             \nLog Likelihood                              -812.786  -812.595 \nAkaike Inf. Crit.                           1,637.571 1,637.190\nResidual Std. Error    0.466 (df = 1301)                       \nF Statistic         5.779*** (df = 5; 1301)                    \n===============================================================\nNote:                               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKeskmiste marginaalsete efektide võrdlus - palju koodi\n\n#make a dataframe of probit coefficients\nmeffs_table = as.data.frame(summary(margins(osalemismudelprobit)))\n#store coefficients\npvec.coeffs &lt;- meffs_table$AME\n#standard errors\npvec.se &lt;- meffs_table$SE\n#and names\nnames(pvec.se) &lt;- names(pvec.coeffs)\n#p-values\npvec.p &lt;- meffs_table$p\n#and names\nnames(pvec.p) &lt;- names(pvec.coeffs)\n#t-values\npvec.t &lt;- meffs_table$z\n#and names\nnames(pvec.t) &lt;- names(pvec.coeffs)\n\n#Similarly logit\nmeffs_table = as.data.frame(summary(margins(osalemismudellogit)))\nlvec.coeffs &lt;- meffs_table$AME\nlvec.se &lt;- meffs_table$SE\nnames(lvec.se) &lt;- names(lvec.coeffs)\nlvec.p &lt;- meffs_table$p\nnames(lvec.p) &lt;- names(lvec.coeffs)\nlvec.t &lt;- meffs_table$z\nnames(lvec.t) &lt;- names(lvec.coeffs)\n\n#Lineaarse mudeli jaoks muutub vaid siis, kui meil on sees polünoomid, mida meil ei ole\nmeffs_table = as.data.frame(summary(margins(osalemismudellpm)))\nlpmvec.coeffs &lt;- meffs_table$AME\nlpmvec.se &lt;- meffs_table$SE\nnames(lpmvec.se) &lt;- names(lpmvec.coeffs)\nlpmvec.p &lt;- meffs_table$p\nnames(lpmvec.p) &lt;- names(lpmvec.coeffs)\nlpmvec.t &lt;- meffs_table$z\nnames(lpmvec.t) &lt;- names(lpmvec.coeffs)\n\n#Nüüd kõik ühes tabelis\nstargazer(osalemismudellpm, osalemismudellogit, osalemismudelprobit, \n          coef=list(lpmvec.coeffs, lvec.coeffs, pvec.coeffs), \n          se=list(lpmvec.se, lvec.se, pvec.se), \n          t=list(lpmvec.t, lvec.t, pvec.t), \n          p=list(lpmvec.p, lvec.p, pvec.p), \n          type = \"text\", \n          omit = c(\"I(exper * exper)\"),\n          #column.labels= c(\"OLS\", \"Logit mfx\", \"Probit mfx\"),\n          dep.var.labels = \"Marginal effects\", no.space = TRUE)\n\n\n===============================================================\n                                Dependent variable:            \n                    -------------------------------------------\n                                 Marginal effects              \n                              OLS           logistic   probit  \n                              (1)              (2)       (3)   \n---------------------------------------------------------------\nmale                        -0.043           -0.044    -0.044  \n                            (0.028)          (0.028)   (0.028) \nage                        -0.003**         -0.003**  -0.003** \n                            (0.001)          (0.001)   (0.001) \nest                         0.065**          0.065**   0.066** \n                            (0.027)          (0.026)   (0.026) \nemplbefore                   0.002            0.003     0.001  \n                            (0.045)          (0.044)   (0.044) \neduc                       0.060***         0.061***  0.061*** \n                            (0.014)          (0.014)   (0.014) \nConstant                                                       \n                                                               \n---------------------------------------------------------------\nObservations                 1,307            1,307     1,307  \nR2                           0.022                             \nAdjusted R2                  0.018                             \nLog Likelihood                              -812.786  -812.595 \nAkaike Inf. Crit.                           1,637.571 1,637.190\nResidual Std. Error    0.466 (df = 1301)                       \nF Statistic         5.779*** (df = 5; 1301)                    \n===============================================================\nNote:                               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\nŠansside suhted\n\n#odds ratios\n(OR=exp(coef(osalemismudellogit)))\n\n(Intercept)        male         age         est  emplbefore        educ \n  0.3145027   0.8146811   0.9873661   1.3489940   1.0139484   1.3265720 \n\n#standard errors = OR*se(b)\n(seOR=OR*sqrt(diag(vcov(osalemismudellogit))))\n\n(Intercept)        male         age         est  emplbefore        educ \n0.088798839 0.107490319 0.006349653 0.164868226 0.208525794 0.089496857 \n\n\nMida näitab šansside suhe?\nTabel tunnusega est\n\ntable(\"training\" = atp$training, \"est\" = atp$est)\n\n        est\ntraining   0   1\n       0 559 319\n       1 245 184\n\n\nLisame ka šansside suhted tabelisse\n\nm1 &lt;- osalemismudellpm \nm2 &lt;- osalemismudellogit \nm3&lt;- osalemismudelprobit \n\n\nstargazer(m1, m2, m2, m3, \n          coef=list(lpmvec.coeffs, lvec.coeffs, OR, pvec.coeffs), \n          se=list(lpmvec.se, lvec.se, seOR, pvec.se), \n          t=list(lpmvec.t, lvec.t, NULL, pvec.t), \n          p=list(lpmvec.p, lvec.p, NULL, pvec.p), \n          type = \"text\", \n          omit = c(\"I(exper * exper)\"),\n          column.labels= c(\"Beta\", \"Marg.effect\", \"OR\", \"Marg. effect\"),\n          #dep.var.labels = \"Marginal effects\", \n          no.space = TRUE)\n\n\n==============================================================================\n                                       Dependent variable:                    \n                    ----------------------------------------------------------\n                                             training                         \n                              OLS                 logistic           probit   \n                             Beta           Marg.effect    OR     Marg. effect\n                              (1)               (2)        (3)        (4)     \n------------------------------------------------------------------------------\nmale                        -0.043            -0.044    0.815***     -0.044   \n                            (0.028)           (0.028)    (0.107)    (0.028)   \nage                        -0.003**          -0.003**   0.987***    -0.003**  \n                            (0.001)           (0.001)    (0.006)    (0.001)   \nest                         0.065**           0.065**   1.349***    0.066**   \n                            (0.027)           (0.026)    (0.165)    (0.026)   \nemplbefore                   0.002             0.003    1.014***     0.001    \n                            (0.045)           (0.044)    (0.209)    (0.044)   \neduc                       0.060***          0.061***   1.327***    0.061***  \n                            (0.014)           (0.014)    (0.089)    (0.014)   \nConstant                                                0.315***              \n                                                         (0.089)              \n------------------------------------------------------------------------------\nObservations                 1,307             1,307      1,307      1,307    \nR2                           0.022                                            \nAdjusted R2                  0.018                                            \nLog Likelihood                               -812.786   -812.786    -812.595  \nAkaike Inf. Crit.                            1,637.571  1,637.571  1,637.190  \nResidual Std. Error    0.466 (df = 1301)                                      \nF Statistic         5.779*** (df = 5; 1301)                                   \n==============================================================================\nNote:                                              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\nVõrdleme tõenäosuste jaotusi\n\nlibrary(tidyr)\natp %&gt;%  \n  rename(logit = trainingphat,\n         probit = trainingphatprobit,\n         lpm =trainingphatlpm ) %&gt;% \nselect(id, logit, probit, lpm) %&gt;% \n  pivot_longer(-id) %&gt;% \n  ggplot(aes(x = value, color = factor(name))) + \n  geom_density() +\n  theme_light() +\n  labs(title =\"Tõenäosuste võrdlus\", color = \"Mudel\")\n\n\n\n\n\n\n\n\n\n\nSobitamine tõenäosuse alusel (propensity score matching)\nPeame märkima meetodiks ikkagi lähim (“nearest”), kuid kauguse mõõduks on nüüd “glm”, mis koos link funktsiooniga “logit” ütleb, et kasutatakse logistilist regressioonimudelit. Kasutame seekord kahte lähimat naabrit.\n\nmpsm &lt;- matchit(training ~ male + age + est  + emplbefore + educ,  \n                method=\"nearest\", \n                distance=\"glm\", \n                link = \"logit\", \n                data=atp, \n                ratio = 2, \n                replace = TRUE)\n\nKui hästi tasakaalustab? Mitte enam nii hästi.\n\nsummary(mpsm)\n\n\nCall:\nmatchit(formula = training ~ male + age + est + emplbefore + \n    educ, data = atp, method = \"nearest\", distance = \"glm\", link = \"logit\", \n    replace = TRUE, ratio = 2)\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.3425        0.3213          0.3260     0.8541    0.0845\nmale              0.2821        0.3371         -0.1224          .    0.0551\nage              34.3636       35.1788         -0.0797     0.8261    0.0253\nest               0.4289        0.3633          0.1325          .    0.0656\nemplbefore        0.8718        0.8804         -0.0258          .    0.0086\neduc              2.9907        2.7768          0.2313     1.0103    0.0535\n           eCDF Max\ndistance     0.1529\nmale         0.0551\nage          0.0620\nest          0.0656\nemplbefore   0.0086\neduc         0.1233\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.3425        0.3424          0.0009     1.0022    0.0007\nmale              0.2821        0.2576          0.0544          .    0.0245\nage              34.3636       34.4604         -0.0095     1.0394    0.0073\nest               0.4289        0.4009          0.0565          .    0.0280\nemplbefore        0.8718        0.8998         -0.0837          .    0.0280\neduc              2.9907        3.0047         -0.0151     1.1325    0.0192\n           eCDF Max Std. Pair Dist.\ndistance     0.0117          0.0026\nmale         0.0245          0.3652\nage          0.0268          0.3204\nest          0.0280          0.1884\nemplbefore   0.0280          0.2719\neduc         0.0338          0.2849\n\nSample Sizes:\n              Control Treated\nAll            878.       429\nMatched (ESS)  358.06     429\nMatched        486.       429\nUnmatched      392.         0\nDiscarded        0.         0\n\nplot(summary(mpsm))\n\n\n\n\n\n\n\n\nMis tunnus on kõige rohkem tasakaalust väljas? (Kus on Std. Mean Diff. kõige erinevam nullist?)\nTõenäosuste jaotus osalus- ja võrdlusrühmas.\n\nplot(mpsm, type = \"jitter\", interactive = FALSE)\n\n\n\n\n\n\n\n\n\n\nAndmete väljavõtt sobitatud objektist ja tulemuste hindamine\nVõtame andmed taas välja\n\nmdatapsm &lt;- match.data(mpsm)\n\nJa tulemused\n\nmudel3 &lt;- lm(employed  ~  training, data = mdatapsm, weights = weights)\nsummary(mudel3)\n\n\nCall:\nlm(formula = employed ~ training, data = mdatapsm, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-1.0709 -0.4789  0.2737  0.2914  0.6120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.63636    0.02129  29.896   &lt;2e-16 ***\ntraining     0.07226    0.03109   2.325   0.0203 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4693 on 913 degrees of freedom\nMultiple R-squared:  0.005883,  Adjusted R-squared:  0.004795 \nF-statistic: 5.403 on 1 and 913 DF,  p-value: 0.02032\n\n\nTõlgendage. Kui palju suurendab koolituses osalemine meetmes hilisemat töötamise tõenäosust?\nIseseisvalt: hinnake ka mõju palgale.\nKui algses sobitamises jääb erinevusi tunnuste vahel, siis lisame need täiendavalt regressioonimudelisse.\n\nmudel3X &lt;- lm(employed  ~  training + male + est+ age + age2  + educ + emplbefore, data = mdatapsm, weights = weights)\nsummary(mudel3X)\n\n\nCall:\nlm(formula = employed ~ training + male + est + age + age2 + \n    educ + emplbefore, data = mdatapsm, weights = weights)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-1.1710 -0.4833  0.2497  0.3211  0.8171 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.144047   0.190201   0.757 0.449042    \ntraining     0.072248   0.030651   2.357 0.018630 *  \nmale         0.075788   0.035598   2.129 0.033523 *  \nest          0.104313   0.031557   3.306 0.000985 ***\nage          0.008126   0.012224   0.665 0.506365    \nage2        -0.010485   0.016190  -0.648 0.517385    \neduc         0.058407   0.018361   3.181 0.001518 ** \nemplbefore   0.122798   0.062237   1.973 0.048791 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4617 on 907 degrees of freedom\nMultiple R-squared:  0.04378,   Adjusted R-squared:  0.0364 \nF-statistic: 5.933 on 7 and 907 DF,  p-value: 9.172e-07\n\n\nTõlgendamine on tavapärane. Meetmes osalemine suurendab hilisemat töötamise tõenäosust 7.2 protsendipunkti.\n\n\nSoovitusi\nSobitamise meetodile saadud hinnangutes jääb alati nihe, sest jäävad erinevused osalus- ja võrdlusgrupi vahel. Nihe on seda suurem, mida suurem on selgitavate tunnuste Xide hulk, mida kasutatakse. Isegi väga suure valimi kasutamine ei pruugi aidata. Selleks, et nihe oleks väiksem, soovitatakse järgmist:\n\nkasuta väikest arvu võrdlusgrupi elemente (nt M=1), sest mida rohkem kasutad võrdlusgrupi vaatlusi, seda suurem on oht, et nad on erinevad;\nkasuta tagasipanekuga sobitamist, sest nii on lootus leida sarnasemaid vaatlusi;\nvõrdlusgrupp, kust võtta vaatlusi, peaks olema suur;\nkontrolli, et sobitamine on täpsem just nende tunnuste osas, millel on uuritavale tunnusele suur mõju; (nt kui töökogemusel on palgale suurem mõju kui haridusel, siis peaks just töökogemus olema täpsemini sobitatud kui haridus);\nkasuta täiendavaid kohandamismeetodeid peale sobitamist (double robust method), et elimineerida allesjäänud Xide erinevuste mõju väljundmuutujale.\nAbadie, Imbens (2006, 2012) pakuvad standardvead hinnangutele, mis sobitavad Xi alusel; Abadie, Imbens (2016) pakuvad standardvead hinnangutele, mis sobitavad hinnatud tõenäosuse p(X) alusel; Abadie sõnul bootstrapping ei tööta üldjuhul.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sobitamine</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html",
    "href": "07-ivmeetod.html",
    "title": "8  Instrumentmuutuja",
    "section": "",
    "text": "8.1 Seade\nInstrumentmuutuja meetod (instrumental variable method, IV) on üks olulisemaid tööriistu olukordades, kus regressioonimudeli selgitav tunnus on endogeenne – st korreleerub vealiikmega. Sellisel juhul on tavalise OLS-regressiooni hinnangud nihkega ja ei ole mõjusad isegi väga suurtes valimites. IV-meetod püüab eraldada selle osa varieeruvusest, mis on “puhas” ja ei ole saastunud jälgimata teguritest.:contentReferenceoaicite:0",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#seade",
    "href": "07-ivmeetod.html#seade",
    "title": "8  Instrumentmuutuja",
    "section": "",
    "text": "Motivatsioon: endogeensus ja väljajäetud muutuja nihe\nOlgu lihtne lineaarne mudel\n\\[\nY_i = \\alpha + \\beta D_i + \\gamma^\\top X_i + u_i,\n\\]\nkus\n\n\\(Y_i\\) – tulemus (nt palk),\n\\(D_i\\) – meede või huvipakkuv selgitaja (nt haridus, tööturukoolitus),\n\\(X_i\\) – kontrollmuutujad (nt vanus, sugu, haridus jne),\n\\(u_i\\) – vealiige, mis sisaldab kõiki muid, mudelisse mitte kaasatud tegureid.\n\nOLS-meetodi põhieelduseks on, et selgitavad tunnused on eksogeensed:\n\\[\n\\mathbb{E}[u_i \\mid D_i, X_i] = 0\n\\quad\\Longleftrightarrow\\quad\n\\operatorname{Cov}(D_i, u_i) = 0.\n\\]\nPaljudes rakendustes see ei kehti:\n\nhariduse ja palga puhul on \\(D_i\\) (haridus) sageli korreleeritud võimekuse, motivatsiooni, perekondliku tausta jms-ga, mis on vealiikmes \\(u_i\\);\ntööturukoolituse ja palga puhul osalevad koolitusel suurema tõenäosusega need, kes on motiveeritumad või kellel on paremad kontaktid;\nlojaalsusprogrammi mõju ostusummale: programmiga liituvad pigem need kliendid, kes nagunii poes käivad.\n\nKui \\(\\operatorname{Cov}(D_i, u_i) \\neq 0\\), tekib väljajäetud muutuja nihe (omitted variable bias) ning OLS-i hinnang \\(\\hat\\beta^{OLS}\\) ei ole põhjuslik mõju.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#mis-on-instrumentmuutuja",
    "href": "07-ivmeetod.html#mis-on-instrumentmuutuja",
    "title": "8  Instrumentmuutuja",
    "section": "8.2 Mis on instrumentmuutuja?",
    "text": "8.2 Mis on instrumentmuutuja?\nIV-meetodi idee on kasutada lisaks instrumenti \\(Z_i\\), mis mõjutab probleemset selgitajat \\(D_i\\), kuid ei mõjuta tulemust \\(Y_i\\) muul viisil kui \\(D_i\\) kaudu.\nInformaalne graafik:\n\n\\(Z_i\\) → mõjutab \\(D_i\\),\n\\(D_i\\) → mõjutab \\(Y_i\\),\ntaustamuutuja \\(A_i\\) (nt võimekus) mõjutab nii \\(D_i\\) kui \\(Y_i\\),\ntahame sulgeda “tagaukse” \\(D_i \\leftarrow A_i \\rightarrow Y_i\\).\n\nInstrumentmuutuja \\(Z_i\\) on sobiv, kui ta täidab kolme põhi-eeldust:\n\nRelevantsus: \\(Z_i\\) on piisavalt tugevasti seotud \\(D_i\\)-ga\n\\[\n\\operatorname{Cov}(Z_i, D_i) \\neq 0.\n\\]\nEksogeensus: \\(Z_i\\) ei korreleeru vealiikmega\n\\[\n\\operatorname{Cov}(Z_i, u_i) = 0.\n\\]\nVäljajätmise eeldus (exclusion restriction): \\(Z_i\\) ei mõjuta \\(Y_i\\) otseselt, vaid ainult läbi \\(D_i\\); st puudub otsene tee \\(Z_i \\to Y_i\\).\n\nRelevantsust saab andmetest testida (nõrgad instrumendid), eksogeensust ja väljajätmise eeldust tuleb enamasti põhjendada teoreetiliselt ja institutsionaalse konteksti abil.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#lihtne-näide-ja-waldi-valem",
    "href": "07-ivmeetod.html#lihtne-näide-ja-waldi-valem",
    "title": "8  Instrumentmuutuja",
    "section": "8.3 Lihtne näide ja Waldi valem",
    "text": "8.3 Lihtne näide ja Waldi valem\nVaatame kõige lihtsamat juhtu, kus:\n\n\\(D_i\\) on binaarne (osales/ei osalenud),\n\\(Z_i\\) on binaarne instrument (nt poliitikamuutus, juhuslik loosimine),\nkontrollmuutujaid ei ole.\n\nMudel:\n\\[\nY_i = \\alpha + \\beta D_i + u_i.\n\\]\nIV loogika:\n\nvõrdleme keskmist tulemust nende vahel, kellel \\(Z_i=1\\) ja \\(Z_i=0\\);\nvõrdleme, kui palju erineb keskmine osalemine \\(D_i\\) nende kahe grupi vahel.\n\nWald-hinnang on:\n\\[\n\\hat\\beta^{IV} =\n\\frac{\\mathbb{E}[Y_i \\mid Z_i = 1] - \\mathbb{E}[Y_i \\mid Z_i = 0]}\n     {\\mathbb{E}[D_i \\mid Z_i = 1] - \\mathbb{E}[D_i \\mid Z_i = 0]}.\n\\]\nTähendused:\n\nnimetaja kirjeldab instrumendi mõju osalus-tõenäosusele;\nlugeja kirjeldab instrumendi mõju tulemusele;\nsuhe ütleb, kui palju \\(Y_i\\) muutub instrumendi poolt esile kutsutud ühikulise muutuse kohta \\(D_i\\)-s.\n\nKui instrument on binaarne ja kontrollmuutujaid ei ole, langeb see kokku klassikalise Waldi hinnanguga.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kahesammuline-vähimruutude-meetod-2sls",
    "href": "07-ivmeetod.html#kahesammuline-vähimruutude-meetod-2sls",
    "title": "8  Instrumentmuutuja",
    "section": "8.4 Kahesammuline vähimruutude meetod (2SLS)",
    "text": "8.4 Kahesammuline vähimruutude meetod (2SLS)\nÜldisemal juhul on:\n\\[\nY_i = \\alpha + \\beta D_i + \\gamma^\\top X_i + u_i,\n\\] \\[\nD_i = \\pi_0 + \\pi_1 Z_i + \\pi_2^\\top X_i + v_i,\n\\]\nkus \\(Z_i\\) võib olla skalaarkomponent või vektor (mitu instrumenti).\nKahesammuline vähimruutude meetod (Two-Stage Least Squares, 2SLS) toimib järgmiselt.\nEsimene samm (esimene etapp):\n\\[\nD_i = \\hat\\pi_0 + \\hat\\pi_1 Z_i + \\hat\\pi_2^\\top X_i + \\hat v_i.\n\\]\n\nHinnatakse regressioon \\(D_i\\)-le instrumendi ja kontrollmuutujate peale.\nSaadakse prognoosid \\(\\hat D_i = \\hat\\pi_0 + \\hat\\pi_1 Z_i + \\hat\\pi_2^\\top X_i\\).\nSisuliselt eraldame \\(D_i\\) selles osas, mida selgitavad \\(Z_i\\) ja \\(X_i\\), ning eemaldame osa, mis on korreleeritud vealiikmega.\n\nTeine samm (teine etapp):\n\\[\nY_i = \\alpha + \\beta \\hat D_i + \\gamma^\\top X_i + \\varepsilon_i.\n\\]\n\nAsendame algses mudelis \\(D_i\\) tema prognoosiga \\(\\hat D_i\\) ning kasutame OLS-i.\nSaadud \\(\\hat\\beta^{2SLS}\\) on IV-hinnang, mis kasutab ainult seda osa $D_i varieeruvusest, mida instrument \\(Z_i\\) ja \\(X_i\\) suudavad selgitada.\n\nR-is saab seda mugavalt teha näiteks paketiga AER:\n\nlibrary(AER)\n\n# Näide: palk sõltub haridusest, kus haridus on endogeenne,\n# instrumentideks näiteks regionaalsed või perekondlikud tunnused\n\niv_mod &lt;- ivreg(wage ~ educ + exper + I(exper^2) |\n                      motheduc + fatheduc + exper + I(exper^2),\n                data = mydata)\n\nsummary(iv_mod)\n\nParempoolsel poolel: vasak pool enne | on struktuurne mudel (Y ~ endogeensed + eksogeensed tunnused), parem pool pärast | on instrumendid ja eksogeensed tunnused.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#sobivate-instrumentide-kriteeriumid",
    "href": "07-ivmeetod.html#sobivate-instrumentide-kriteeriumid",
    "title": "8  Instrumentmuutuja",
    "section": "8.5 Sobivate instrumentide kriteeriumid",
    "text": "8.5 Sobivate instrumentide kriteeriumid\nInstrumentide jaoks kehtivad järgmised põhinõuded.\n\nRelevantsus\nInstrument peab olema piisavalt tugevalt seotud selgitava tunnusega \\(D_i\\):\n\n\\(\\operatorname{Cov}(Z_i, D_i) \\neq 0\\)\n\nEsimeses etapis saab seda hinnata F-statistikuga. Lihtne rusikareegel:\n\nkui \\(F &lt; 10\\), võib instrument olla nõrk;\nnõrkade instrumentide korral on IV-hinnangud väga ebatäpsed (suured standardvead) ja võivad olla tugevalt nihkega.\n\n\n\n\nEksogeensus ja väljajätmise eeldus (exclusion restriction)\n\nInstrument ei tohi korreleeruda vealiikmega \\(u_i\\):\n\n\\(\\operatorname{Cov}(Z_i, u_i) = 0\\).\n\nInstrument ei tohi mõjutada \\(Y_i\\) otse, vaid üksnes läbi \\(D_i\\):\n\npuudub otsene tee \\(Z_i \\to Y_i\\); mõju peab käima ainult \\(Z_i \\to D_i \\to Y_i\\) kaudu.\n\n\nKui instrumente on rohkem kui endogeenseid muutujaid (üleidentifitseeritud mudel), saab eksogeensust osaliselt testida üleidentifitseerimiskatsetega (Sargani või Hansen–J test), kontrollides, kas kõik instrumendid korraga sobituvad mudelisse ilma oluliste vastuoludeta.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#nõrgad-ja-valed-instrumendid",
    "href": "07-ivmeetod.html#nõrgad-ja-valed-instrumendid",
    "title": "8  Instrumentmuutuja",
    "section": "8.6 Nõrgad ja valed instrumendid",
    "text": "8.6 Nõrgad ja valed instrumendid\n\nKui \\(Z_i\\) ei korreleeru \\(D_i\\)-ga, on tegemist ebaoluliste instrumentidega; IV-meetod ei anna lisainfot ja hinnangud käituvad halvasti.\nKui seos on olemas, kuid väga nõrk, on tegemist nõrkade instrumentidega. Siis on IV-hinnangud asümptootiliselt küll mõjusad, kuid väikeses valimis väga ebatäpsed.\nKui instrument korreleerub vealiikmega (nt mõjutab tegelikult otseselt \\(Y_i\\)) või on seotud jälgimata teguritega \\(A_i\\), siis on instrument vigane. Sellisel juhul annab IV-meetod valesuunalise hinnangu.\n\nPraktikas on tihti valik:\n\nkas kasutada nihkega, kuid väiksema variatsiooniga OLS-hinnangut;\nvõi kasutada IV-meetodit, mis põhineb tugevatele eeldustele ja millel võivad olla suured standardvead.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#heterogeensed-mõjud-ja-late",
    "href": "07-ivmeetod.html#heterogeensed-mõjud-ja-late",
    "title": "8  Instrumentmuutuja",
    "section": "8.7 Heterogeensed mõjud ja LATE",
    "text": "8.7 Heterogeensed mõjud ja LATE\nKui mõju \\(\\beta\\) ei ole kõigi jaoks sama (heterogeensed mõjud), ei pruugi IV-hinnang kirjeldada keskmist mõju kõigile. Binaarse instrumendi ja binaarse meetme korral, täiendavate eelduste (näiteks monotoolsuse) all, identifitseerib Waldi/IV-hinnang nn kohaliku keskmise mõju (Local Average Treatment Effect, LATE):\n\nLATE on keskmine mõju nende isikute seas, kelle meedme staatus muutub instrumendi väärtuse muutumise tõttu (compliers ehk “allujad”).\n\nÜlejäänud rühmad:\n\nnever-takers – ei osale kunagi;\nalways-takers – alati osalevad;\ndefiers – käituvad instrumendile vastupidiselt.\n\nNende kohta IV otseselt infot ei anna.\n\nSeos regressiooni katkemise disainiga (RDD)\n\nRDD-s on instrument \\(Z_i\\) tavaliselt “olla üle lõikepunkti” (näiteks \\(Z_i = 1\\), kui \\(X_i \\ge c\\)).\nRDD sharp design vastab olukorrale, kus instrument määrab \\(D_i\\) deterministlikult (kõik üle lõikepunkti osalevad, kõik allpool mitte).\nRDD fuzzy design vastab klassikalisele LATE-olukorrale, kus instrument mõjutab ainult osalemise tõenäosust, mitte ei määra seda täpselt.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kas-iv-meetodit-üldse-vaja-on-hausmani-test",
    "href": "07-ivmeetod.html#kas-iv-meetodit-üldse-vaja-on-hausmani-test",
    "title": "8  Instrumentmuutuja",
    "section": "8.8 Kas IV-meetodit üldse vaja on? Hausmani test",
    "text": "8.8 Kas IV-meetodit üldse vaja on? Hausmani test\nKui kahtleme, kas endogeensus on tõsine probleem, on mitmeid võimalusi seda hinnata.\nÜks levinud lähenemine on Hausmani tüüpi spetsifikatsioonitest:\n\n\\(H_0\\): mudelis ei ole endogeensust; OLS on mõjus ja efektiivne; OLS ja IV annavad sarnased hinnangud.\n\\(H_1\\): esineb endogeensus; OLS on nihkega; IV on mõjus, kui instrumendid on sobivad.\n\nPraktiline mõte:\n\nhinnata OLS-mudel;\nhinnata IV/2SLS-mudel;\nvõrrelda hinnanguid ja statistikat (nt spetsiaalsete testifunktsioonidega).\n\nTeine lähenemine on kontrollfunktsiooni meetod, kus:\n\nEsimeses etapis hinnatakse \\(D_i\\) sõltuvust instrumentidest ja eksogeensetest tunnustest ning saadakse jääk \\(\\hat v_i\\).\nTeises etapis lisatakse \\(\\hat v_i\\) struktuursesse mudelisse lisatunnusena.\n\nKui \\(\\hat v_i\\) kordaja on statistiliselt oluline, on endogeensus probleem.\n\nKui mitte, siis võib OLS olla piisav.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#instrumentide-leidmine",
    "href": "07-ivmeetod.html#instrumentide-leidmine",
    "title": "8  Instrumentmuutuja",
    "section": "8.9 Instrumentide leidmine",
    "text": "8.9 Instrumentide leidmine\nPraktiliselt on suurim probleem leida hea instrument. Mõned tüüpilised allikad:\n\nregionaalne varieeruvus teenuste kättesaadavuses, mis ei sõltu individuaalsetest omadustest\n(näiteks kaugus ülikoolist, haiglast, koolitusasutusest);\npoliitikamuutused ja institutsionaalsed reeglid\n(näiteks muutus toetuse tingimustes, mis sõltub ainult sünniaastast, piirkonnast või mõnest teisest välistunnusest);\najaline varieeruvus: meetmed, mis rakenduvad erineval ajal erinevates piirkondades;\nminevikuväärtused paneelandmetes (lagged variables), kui need on usutavalt eksogeensed;\nrandomiseeritud eksperimendid: ideaalne, “täiuslik” instrument.\n\nIga kord tuleb läbi mõelda:\n\nkas instrument mõjutab selgitavat tunnust piisavalt tugevasti;\nkas on usutav, et instrument ei mõjuta otseselt tulemust;\nkas pole muid kanaleid (väljajätmise eeldus), mille kaudu instrument ja tulemus sõltuda võiksid.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kokkuvõte",
    "href": "07-ivmeetod.html#kokkuvõte",
    "title": "8  Instrumentmuutuja",
    "section": "8.10 Kokkuvõte",
    "text": "8.10 Kokkuvõte\nInstrumentmuutuja meetod:\n\non mõeldud olukordadeks, kus selgitav tunnus on endogeenne ja tavaline regressioon annab nihkega hinnanguid;\nkasutab ainult seda osa varieeruvusest, mis on “tekitatud” instrumendi poolt ja on seetõttu vealiikmest sõltumatu;\ntugineb tugevatele eeldustele instrumendi eksogeensuse ja väljajätmise kohta, mida alati ei saa otseselt testida;\nannab heterogeensete mõjude korral lokaalse keskmise mõjuhinnangu (LATE) just nendele, keda instrument tegelikult “liigutab”.\n\nAnalüütiku ülesanne on leida veenev instrument, põhjendada selle sobivust ning kontrollida esimeses etapis instrumentide tugevust ja teises etapis mudeli kooskõlalisust. Nõrk või vigane instrument on sageli hullem kui lihtne, ausalt nihkega OLS.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#näide",
    "href": "07-ivmeetod.html#näide",
    "title": "8  Instrumentmuutuja",
    "section": "8.11 Näide",
    "text": "8.11 Näide\nSee näide püüab korrata lähenemist, mis kasutati Leenheer jt. artiklis.\nVt Jorna Leenheer, Harald J. van Heerde, Tammo H.A. Bijmolt, Ale Smidts, “Do loyalty programs really enhance behavioral loyalty? An empirical analysis accounting for self-selecting members, International Journal of Research in Marketing,”, Volume 24, Issue 1, 2007, Pages 31-47, ISSN 0167-8116, https://doi.org/10.1016/j.ijresmar.2006.10.005. https://www.sciencedirect.com/science/article/abs/pii/S016781160600084X\nArtikkel uurib ettevõtete lojaalsusprogrammide mõju kliendilojaalsusele, arvestades valikunihet (selection bias). Lojaalsusprogrammi valivad need kliendid, kes juba nagunii kasutavad teenuseid enam. Seega ülehindaksime lojaalsusprogrammide mõju klientide lojaalsusele.\nMeetod hõlmab kahesammulist vähimruutude meetodit (2SLS) koos instrumentmuutujatega, et hinnata lojaalsusprogrammi liikmesuse mõju kulutuste osakaalule (share-of-wallet, SOW).\n\nAndmed\n\nhousehold_id: Unikaalne ID igale majapidamisele.\nloyalty_program_member: Binaarne muutuja, mis näitab liikmesust (1, kui on liige; 0, kui ei ole).\nshare_of_wallet: Majapidamise kulutuste osakaal poes.\neconomic_benefit: Lojaalsusprogrammide tajutud majanduslik kasu (instrumentmuutuja). - üleüldine\nnon_economic_benefit: Tajutud mittemajanduslik kasu (instrumentmuutuja). - üleüldine\nprivacy_concern: Privaatsusega seotud mured lojaalsusprogrammide osas (instrumentmuutuja). - üleüldine\ndiscount_rate: Lojaalsusprogrammi allahindluse määr.\nsaving_rate: Lojaalsusprogrammi säästumäär.\nhh_income: leibkonna sissetulek\n\n\nlibrary(AER) # 2SLS mudeli jaoks\nlibrary(stargazer) # tulemuste esitamiseks\nlibrary(dplyr)\nlibrary(sandwich) #robustsed standardvead\nlibrary(lmtest) #testid",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#avame-andmed",
    "href": "07-ivmeetod.html#avame-andmed",
    "title": "8  Instrumentmuutuja",
    "section": "8.12 Avame andmed",
    "text": "8.12 Avame andmed\n\n#load(file = \"kliendiprogramm.RData\")\nload(url(\"http://kodu.ut.ee/~avork/files/oppetoo/pohjustagajarg/kliendiprogramm.RData\"))\n\nUurige andmed.\n\nKui palju kliente on lojaalsusprogrammis?\nKui suur on keskmine uuritavate toodete osakaal kogu kulutustes?\nKas see on suurem lojaalsusprogrammis osalejatel?\nUurige seoseid muutujate vahel korrelatsioonikordaja abil\n\n\n#1. \ntable(data$loyalty_program_member)\n\n\n  0   1 \n415 585 \n\n#2. \nsummary(data$share_of_wallet)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1815  0.3732  0.4420  0.4268  0.4868  0.5753 \n\nhist(data$share_of_wallet)\n\n\n\n\n\n\n\n#3. \ndata %&gt;% group_by(loyalty_program_member) %&gt;% summarise(mean_sow = mean(share_of_wallet))\n\n# A tibble: 2 × 2\n  loyalty_program_member mean_sow\n                   &lt;int&gt;    &lt;dbl&gt;\n1                      0    0.374\n2                      1    0.464\n\n#4. \npairwise_correlations &lt;- cor(data, use = \"pairwise.complete.obs\")\nround(pairwise_correlations, 3)\n\n                       household_id hh_income economic_benefit\nhousehold_id                  1.000    -0.009            0.020\nhh_income                    -0.009     1.000           -0.017\neconomic_benefit              0.020    -0.017            1.000\nnon_economic_benefit         -0.041    -0.045            0.061\nprivacy_concern              -0.003    -0.026           -0.021\ndiscount_rate                -0.011    -0.013            0.035\nsaving_rate                   0.001    -0.055           -0.022\nloyalty_program_member       -0.009    -0.035            0.134\nshare_of_wallet              -0.041     0.154           -0.002\n                       non_economic_benefit privacy_concern discount_rate\nhousehold_id                         -0.041          -0.003        -0.011\nhh_income                            -0.045          -0.026        -0.013\neconomic_benefit                      0.061          -0.021         0.035\nnon_economic_benefit                  1.000           0.033         0.016\nprivacy_concern                       0.033           1.000         0.058\ndiscount_rate                         0.016           0.058         1.000\nsaving_rate                           0.034          -0.003         0.004\nloyalty_program_member                0.205          -0.212         0.036\nshare_of_wallet                       0.054          -0.069         0.043\n                       saving_rate loyalty_program_member share_of_wallet\nhousehold_id                 0.001                 -0.009          -0.041\nhh_income                   -0.055                 -0.035           0.154\neconomic_benefit            -0.022                  0.134          -0.002\nnon_economic_benefit         0.034                  0.205           0.054\nprivacy_concern             -0.003                 -0.212          -0.069\ndiscount_rate                0.004                  0.036           0.043\nsaving_rate                  1.000                 -0.006          -0.026\nloyalty_program_member      -0.006                  1.000           0.558\nshare_of_wallet             -0.026                  0.558           1.000\n\n\n\nOLS\nHindame seose, kuidas SOW sõltub programmi kuulumisest, leibkonna sissetulekust ja kas programm annab allahindust või kogub raha.\n\n#Eirame valikunihet \n\nolsmudel &lt;- lm(share_of_wallet ~ loyalty_program_member + hh_income + discount_rate + saving_rate, data = data)\nsummary(olsmudel)\n\n\nCall:\nlm(formula = share_of_wallet ~ loyalty_program_member + hh_income + \n    discount_rate + saving_rate, data = data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.224060 -0.037635  0.008201  0.043990  0.169021 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.323877   0.020517  15.786  &lt; 2e-16 ***\nloyalty_program_member  0.090630   0.004146  21.858  &lt; 2e-16 ***\nhh_income               0.024008   0.003558   6.747 2.55e-11 ***\ndiscount_rate           0.098130   0.102266   0.960    0.338    \nsaving_rate            -0.051602   0.104142  -0.495    0.620    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06452 on 995 degrees of freedom\nMultiple R-squared:  0.342, Adjusted R-squared:  0.3394 \nF-statistic: 129.3 on 4 and 995 DF,  p-value: &lt; 2.2e-16\n\n#robustsed standardvead\ncoeftest(olsmudel, vcov. = sandwich)\n\n\nt test of coefficients:\n\n                         Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)             0.3238767  0.0212438 15.2457 &lt; 2.2e-16 ***\nloyalty_program_member  0.0906297  0.0043046 21.0543 &lt; 2.2e-16 ***\nhh_income               0.0240079  0.0035947  6.6788 4.002e-11 ***\ndiscount_rate           0.0981303  0.1042048  0.9417    0.3466    \nsaving_rate            -0.0516023  0.1091160 -0.4729    0.6364    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Meil ei ole heteroskedastiivsust",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kahesammulise-vähimruutude-meetodi-2sls-hinnang",
    "href": "07-ivmeetod.html#kahesammulise-vähimruutude-meetodi-2sls-hinnang",
    "title": "8  Instrumentmuutuja",
    "section": "8.13 Kahesammulise vähimruutude meetodi (2SLS) hinnang",
    "text": "8.13 Kahesammulise vähimruutude meetodi (2SLS) hinnang\n\nEsimene samm: Lojaalsusprogrammi liikmesuse prognoosimine\nEsimeses etapis prognoosime loyalty_program_member instrumentaalmuutujate (economic_benefit, non_economic_benefit ja privacy_concern) ja teiste seotud muutujate (discount_rate ja saving_rate) abil.\nEsimene samm: lojaalsusprogrammi liikmesuse prognoosimine\n\nstage1 &lt;- lm(loyalty_program_member ~ economic_benefit + non_economic_benefit +\n             privacy_concern + discount_rate + saving_rate, data = data)\n\nsummary(stage1)\n\n\nCall:\nlm(formula = loyalty_program_member ~ economic_benefit + non_economic_benefit + \n    privacy_concern + discount_rate + saving_rate, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0748 -0.4791  0.2107  0.4044  0.8670 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.40758    0.13749   2.964 0.003106 ** \neconomic_benefit      0.11333    0.02963   3.825 0.000139 ***\nnon_economic_benefit  0.20501    0.03013   6.803 1.76e-11 ***\nprivacy_concern      -0.21476    0.02959  -7.257 7.98e-13 ***\ndiscount_rate         1.02089    0.74229   1.375 0.169341    \nsaving_rate          -0.27984    0.75413  -0.371 0.710663    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4675 on 994 degrees of freedom\nMultiple R-squared:  0.1051,    Adjusted R-squared:  0.1006 \nF-statistic: 23.35 on 5 and 994 DF,  p-value: &lt; 2.2e-16\n\n\nMis mõjutab lojaalsusprogrammi astumist?\nLojaalsusprogrammi liikmesuse prognoositud väärtused\n\ndata$predicted_loyalty &lt;- predict(stage1)\n\nTeine samm: Prognoositud lojaalsuse kasutamine kulutuste osakaalu mudelis Teises etapis kasutame esimeses etapis saadud prognoositud väärtusi mudelis share_of_wallet jaoks.\nTeine samm: 2SLS hinnang, kasutades lojaalsusprogrammi liikmesuse prognoositud väärtusi\n\nstage2iv &lt;- lm(share_of_wallet ~ predicted_loyalty + hh_income +  discount_rate + saving_rate, data = data)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#testid",
    "href": "07-ivmeetod.html#testid",
    "title": "8  Instrumentmuutuja",
    "section": "9.1 Testid",
    "text": "9.1 Testid\nWu-Hausmani test\n\n#Kas meil on instrumenti vaja?\n#T-test\nsummary(stage2ivcf)$coefficients[\"vhat\",]\n\n    Estimate   Std. Error      t value     Pr(&gt;|t|) \n5.430503e-02 1.347645e-02 4.029623e+00 6.012936e-05 \n\n#F-test\nanova(olsmudel, stage2ivcf)\n\nAnalysis of Variance Table\n\nModel 1: share_of_wallet ~ loyalty_program_member + hh_income + discount_rate + \n    saving_rate\nModel 2: share_of_wallet ~ loyalty_program_member + hh_income + discount_rate + \n    saving_rate + vhat\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    995 4.1421                                  \n2    994 4.0755  1  0.066577 16.238 6.013e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Waldi test\nwaldtest(olsmudel, stage2ivcf, test = \"Chisq\")\n\nWald test\n\nModel 1: share_of_wallet ~ loyalty_program_member + hh_income + discount_rate + \n    saving_rate\nModel 2: share_of_wallet ~ loyalty_program_member + hh_income + discount_rate + \n    saving_rate + vhat\n  Res.Df Df  Chisq Pr(&gt;Chisq)    \n1    995                         \n2    994  1 16.238  5.587e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#See test on esitatud ivreg tulemustest\n\n\nsummary(iv_model, diagnostics = TRUE)\n\n\nCall:\nivreg(formula = share_of_wallet ~ loyalty_program_member + hh_income + \n    discount_rate + saving_rate | economic_benefit + non_economic_benefit + \n    privacy_concern + hh_income + discount_rate + saving_rate, \n    data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.21244 -0.04444  0.01049  0.05093  0.14322 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.352557   0.023195  15.200  &lt; 2e-16 ***\nloyalty_program_member  0.041907   0.013740   3.050  0.00235 ** \nhh_income               0.022527   0.003818   5.901 4.96e-09 ***\ndiscount_rate           0.140825   0.109726   1.283  0.19964    \nsaving_rate            -0.061432   0.111165  -0.553  0.58065    \n\nDiagnostic tests:\n                 df1 df2 statistic  p-value    \nWeak instruments   3 993    38.299  &lt; 2e-16 ***\nWu-Hausman         1 994    16.222 6.06e-05 ***\nSargan             2  NA     2.108    0.349    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06885 on 995 degrees of freedom\nMultiple R-Squared: 0.2507, Adjusted R-squared: 0.2477 \nWald test: 10.99 on 4 and 995 DF,  p-value: 1.003e-08",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kas-instrumendid-on-tugevad",
    "href": "07-ivmeetod.html#kas-instrumendid-on-tugevad",
    "title": "8  Instrumentmuutuja",
    "section": "9.2 Kas instrumendid on tugevad?",
    "text": "9.2 Kas instrumendid on tugevad?\n\nsummary(stage1)\n\n\nCall:\nlm(formula = loyalty_program_member ~ economic_benefit + non_economic_benefit + \n    privacy_concern + discount_rate + saving_rate, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0748 -0.4791  0.2107  0.4044  0.8670 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.40758    0.13749   2.964 0.003106 ** \neconomic_benefit      0.11333    0.02963   3.825 0.000139 ***\nnon_economic_benefit  0.20501    0.03013   6.803 1.76e-11 ***\nprivacy_concern      -0.21476    0.02959  -7.257 7.98e-13 ***\ndiscount_rate         1.02089    0.74229   1.375 0.169341    \nsaving_rate          -0.27984    0.75413  -0.371 0.710663    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4675 on 994 degrees of freedom\nMultiple R-squared:  0.1051,    Adjusted R-squared:  0.1006 \nF-statistic: 23.35 on 5 and 994 DF,  p-value: &lt; 2.2e-16\n\n#F-test - võrdleme meie mudelit ja ilma instrumentideta mudelit\nstage1abi &lt;- lm(loyalty_program_member ~ discount_rate + saving_rate, data = data)\n\nanova(stage1abi, stage1)\n\nAnalysis of Variance Table\n\nModel 1: loyalty_program_member ~ discount_rate + saving_rate\nModel 2: loyalty_program_member ~ economic_benefit + non_economic_benefit + \n    privacy_concern + discount_rate + saving_rate\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    997 242.45                                  \n2    994 217.26  3    25.195 38.423 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#F-test on oluline ja suurem ka kui 10\n\n#Sama oli siin\nsummary(iv_model, diagnostics = TRUE)\n\n\nCall:\nivreg(formula = share_of_wallet ~ loyalty_program_member + hh_income + \n    discount_rate + saving_rate | economic_benefit + non_economic_benefit + \n    privacy_concern + hh_income + discount_rate + saving_rate, \n    data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.21244 -0.04444  0.01049  0.05093  0.14322 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.352557   0.023195  15.200  &lt; 2e-16 ***\nloyalty_program_member  0.041907   0.013740   3.050  0.00235 ** \nhh_income               0.022527   0.003818   5.901 4.96e-09 ***\ndiscount_rate           0.140825   0.109726   1.283  0.19964    \nsaving_rate            -0.061432   0.111165  -0.553  0.58065    \n\nDiagnostic tests:\n                 df1 df2 statistic  p-value    \nWeak instruments   3 993    38.299  &lt; 2e-16 ***\nWu-Hausman         1 994    16.222 6.06e-05 ***\nSargan             2  NA     2.108    0.349    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06885 on 995 degrees of freedom\nMultiple R-Squared: 0.2507, Adjusted R-squared: 0.2477 \nWald test: 10.99 on 4 and 995 DF,  p-value: 1.003e-08",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "07-ivmeetod.html#kas-instrumendid-on-sobivad",
    "href": "07-ivmeetod.html#kas-instrumendid-on-sobivad",
    "title": "8  Instrumentmuutuja",
    "section": "9.3 Kas instrumendid on sobivad?",
    "text": "9.3 Kas instrumendid on sobivad?\nSargani test on võimalik, siis kui instrumente rohkem kui vaja. Meil on 3, vaja on 1.\nH0 - instrumendid ei korreleeru vealiikmega H1 - vähemalt üks instrument korreleerub vealiikmega\nMe ei saa ümber lükata H0. Seega selle koha pealt formaalselt korras",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Instrumentmuutuja</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html",
    "href": "08-synthcontr.html",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "",
    "text": "9.1 Taust\nSynthetic control method (SCM)\nSelles peatükis käsitleme sünteetilise võrdlusobjekti meetodit (synthetic control method), mis on välja töötatud olukordadeks, kus meid huvitab ühe konkreetse agregeeritud objekti – näiteks riigi, regiooni või linna – kokkupuude mingi poliitika või sündmusega ning soovime hinnata selle mõju. Erinevalt klassikalisest erinevuste-vahe (dif-dif) lähenemisest, kus on palju meetmes osalejaid ja kontrollüksusi, on sünteetilise kontrolli meetodi fookuses sageli olukord, kus reaalselt on vaid üks meetmes osalev objekt ja piiratud arv sobivaid võrdlusobjekte.\nMotivatsioon tuleneb tüüpilistest poliitikaküsimustest: mis oli Saksamaa taasühinemise mõju Lääne-Saksamaa majanduskasvule, milline oli California ulatusliku tubakakontrolliprogrammi mõju suitsetamisele või kuidas mõjutas Eesti kogumispensioni vabatahtlikuks muutmine majapidamiste tarbimist ja säästmist. Nendele küsimustele vastamiseks ei piisa sageli üksiku võrdlusriigi või -regiooni valimisest, sest subjektiivne valik võib kallutada tulemusi. Sünteetilise kontrolli meetod pakub süsteemse viisi sellise „võrdlusobjekti” konstrueerimiseks.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#taust-ja-rakenduste-näited",
    "href": "08-synthcontr.html#taust-ja-rakenduste-näited",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.2 Taust ja rakenduste näited",
    "text": "9.2 Taust ja rakenduste näited\nEmpiirilises kirjanduses seostatakse sünteetilise kontrolli meetodit eelkõige Abadie ja kaastööliste töödega. Esimene tuntud rakendus on Abadie ja Gardeazabal (2003), kus hinnatakse Baskimaa konflikti majanduslikku hinda võrreldes sünteetiliselt konstrueeritud kontrollpiirkonnaga, mis on kaalutud kombinatsioon Hispaania teistest provintsidest. Abadie, Diamond ja Hainmueller (2010) meetodit California tubakakontrolliprogrammi mõjude hindamiseks ja Abadie, Diamond ja Hainmueller (2014) Saksamaa taasühinemise mõjude analüüsimiseks, konstrueerides Lääne-Saksamaale võrdluseks sünteetilise OECD riikide kombinatsiooni.\nEestis on meetodit kasutatud näiteks Centari analüüsis, kus hinnati lapsehoiu ja alushariduse projektide mõju koolieelsetes lasteasutustes käivate laste osakaalule ja naiste tööhõivele, moodustades sekkumispiirkondadele sobivad sünteetilised kontrollpiirkonnad. Samuti kasutab Meriküll (2025) sünteetilise dif-dif lähenemist, et hinnata, kuidas kogumispensioni varasem vabatahtlikuks muutmine mõjutas Eesti majapidamiste finantskäitumist ja inflatsiooni, võrreldes Eestit riikidega, kus sellist reformi ei olnud.\nNeed näited illustreerivad, et sünteetilise kontrolli meetod on kasulik just siis, kui mõjutatud üksusi on vähe ja me soovime vältida ad hoc ühe võrdlusriigi või -piirkonna valikut.\n\nSeade ja tähistused\nOlgu meil \\(J + 1\\) agregeeritud objekti: üks käsitletav objekt (näiteks California või Baskimaa) ning \\(J\\) potentsiaalset kontrollobjekti (doonorgrupp). Ajalist dimensiooni tähistame perioodidega \\(t = 1, \\dots, T\\), kus sekkumine toimub alates ajast \\(T_0 + 1\\). Perioodid \\(t \\leq T_0\\) on sekkumiseelsed, perioodid \\(t &gt; T_0\\) sekkumisjärgsed.\nOlgu \\(Y_{it}\\) objekt \\(i\\) tegelik tulemusmuutuja (näiteks sigarettide müük elaniku kohta) perioodil \\(t\\). Huvipakkuv on sekkumise mõju käsitletavale üksusele \\(i = 1\\), mida defineerime kui vahe tegeliku tulemuse ja kontrafaktuaalse tulemuse vahel:\n\\[\n\\alpha_{1t} = Y_{1t}^{I} - Y_{1t}^{N}, \\quad t &gt; T_0,\n\\]\nkus \\(Y_{1t}^{I}\\) on tulemus sekkumisega (täheldatav) ning \\(Y_{1t}^{N}\\) oleks tulemus ilma sekkumiseta (võrdlusseisund), mida otseselt ei näe.\nSünteetilise kontrolli idee seisneb selles, et võrdlusseisundi aegrida \\(Y_{1t}^{N}\\) konstrueeritakse kontrollobjektide kaalutud keskmisena:\n\\[ Y\\_{1t}\\^{N} \\approx \\sum*{j=2}\\^{J+1} w_j Y*{jt}, \\quad t = 1, \\dots, T, \\]\nkus kaalud \\(w_j \\geq 0\\) ja \\(\\sum_{j=2}^{J+1} w_j = 1\\). Need kaalud määravad „sünteetilise kontrolli”, ehk hüpoteetilise objekti, mis on kombinatsioon olemasolevatest võrdlusüksustest ja mille sekkumiseelse dünaamika soovime sobitada käsitletava objektiga võimalikult täpselt.\nSellisel juhul on mõju hinnang ajapunktis \\(t &gt; T_0\\):\n\\[ \\hat{\\alpha}*{1t} = Y*{1t} - \\sum\\_{j=2}\\^{J+1} \\hat{w}*j Y*{jt}. \\]\nGraafiliselt saame võrrelda käsitletava objekti tegelikku rada ning sünteetilise kontrolli rada, ning sekkumisejärgne erinevus nende vahel annab visuaalse ja kvantitatiivse hinnangu sekkumise mõjust.\n\n\nSelgitavad tunnused ja kaalud\nLisaks tulemusmuutujale kasutab meetod sobitamiseks selgitavaid tunnuseid ja sekkumiseelseid tulemusi. Olgu \\(X_1\\) vektor käsitletava objekti tunnustest ja sekkumiseelsete tulemuste kokkuvõtlikest näitajatest (näiteks keskmised väärtused), ning \\(X_0\\) maatriks samade tunnuste kohta kontrollobjektide jaoks:\n$$ X_1 = (x_{11}, , x_{1K})’, X_0 =\n\\[\\begin{pmatrix}\nx_{21} & \\dots & x_{J+1,1} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nx_{2K} & \\dots & x_{J+1,K}\n\\end{pmatrix}\\]\n$$\nLisaks kaaludele objektidele \\(w = (w_2, \\dots, w_{J+1})'\\) kasutatakse ka kaalusid tunnustele \\(V\\), mis on diagonaalmaatriks suhtelise olulisusega tunnuste vahel. Intuitsioon on, et mõni tunnus – näiteks sekkumiseelsed tulemused – võib olla eriti informatiivne tulevase tulemuse kohta ning seetõttu saab suurema kaalu.\nKaalud valitakse nii, et sobitada käsitletava objekti tunnused võimalikult hästi sünteetilisele kontrollile, minimeerides sobituskao:\n\\[ \\min\\_{w} (X_1 - X_0 w)' V (X_1 - X_0 w) \\]\nvõttes arvesse tingimusi \\(w_j \\geq 0\\) ja \\(\\sum_j w_j = 1\\). See miinimumväärtus ongi nn W-kaotus (W-loss), mis näitab, kui hästi suudame valitud \\(V\\) korral sobitada selgitavad tunnused.\nSeejärel valitakse \\(V\\) nii, et minimeerida sekkumiseelsel perioodil sünteetilise kontrolli prognoosivea ruutkeskmine, ehk sekkumiseelne ruutkeskmine prognoosiviga (MSPE, Root Mean Square Prediction Error). See on seotud nn V-kaotusega (V-loss), ehk sellega, kui hästi sekkumiseelse väljundi rada on käsitletava objekti ja sünteetilise kontrolli vahel ühtiv.\n\n\nCalifornia tubakakontrolli programmi näide\nÜks klassikaline sünteetilise kontrolli näide on California tubakakontrolli programmi – Proposition 99 – mõju analüüs. Tegemist oli 1988. aastal vastuvõetud seadusandliku paketiga, mis tõstis sigarettide aktsiisi 25 sendi võrra paki kohta ja suurendas makse ka teistele tubakatoodetele. Osa maksutulust suunati ulatusliku tubakakontrolli programmi rahastamiseks, mille eesmärk oli vähendada suitsetamist ning parandada rahvatervist.\nPaneelandmestik sisaldab 39 USA osariigi andmeid perioodil 1970–2000. California puhul võeti 1988. aastat kui sekkumishetke, seega sekkumiseelne periood hõlmab aastaid 1970–1988. Sünteetiline kontroll konstrueeriti kaalutud kombinatsioonina teistest osariikidest, kus sarnane tubakakontrolli programm puudus. Sobitamisel kasutati mitmeid selgitavaid tunnuseid, näiteks elaniku kohta arvutatavat sissetulekut, sigarettide hinda, vanuselist struktuuri ning varasemate erimaksudega seotud näitajaid.\nKaalud selgitavad, kui suure panuse annab iga doonor-osariik sünteetilise California moodustamisse. Samuti määratakse tunnuste kaalud \\(V\\), mis peegeldavad, millised tunnused on prognoosivõime seisukohast kõige olulisemad.\n\nJoonis kujutab California sigarettide müüki elaniku kohta koos sünteetilise kontrolli müügiga. Sekkumiseelsel perioodil peaksid need kaks aegrida olema üksteisele väga lähedal, mis kinnitab sobituse headust. Pärast sekkumist ilmneb järkjärguline lahknemine, mis näitab tubakakontrolliprogrammi mõju.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#eeldused",
    "href": "08-synthcontr.html#eeldused",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.3 Eeldused",
    "text": "9.3 Eeldused\nSünteetilise kontrolli meetodi korrektne tõlgendamine põhineb mitmel olulisel eeldusegrupil.\n\nEi ole vastastikmõjusid (SUTVA-laadne eeldus)\nEsimene eeldus puudutab vastastikmõjusid ehk üldise tasakaalumõju puudumist. Eeldame, et sekkumine käsitletaval objektil ei mõjuta otseselt kontrollobjektide tulemusi. Näiteks Baskimaa konflikti analüüsis eeldatakse, et konflikt ei mõjuta teiste Hispaania regioonide majanduskasvu. Teine näide oleks Eesti ettevõtte tulumaksumäära langetus, mille puhul eeldaksime, et see ei mõjuta naaberriikide ettevõtete majandusnäitajaid. See on sarnane SUTVA eeldusest tuntud nõudega, et ühe üksuse osalemine meetmes ei mõjuta teise üksuse tulemust.\nKui see eeldus ei kehti ja sekkumine „lekib” kontrollüksustesse, siis sünteetiline kontroll ei esinda enam korralikult võrdlusseisundit ilma sekkumiseta.\n\n\nParalleelsete trendide analoog ja sekkumiseelsed perioodid\nTeine oluliste eelduste rühm puudutab dünaamikat sekkumiseelsel perioodil. Nõuame, et kontrollgrupi tulemusi mõjutab sama struktuurne protsess, mis käsitletavat üksust, ning nii uuritav objekt kui ka kontrollüksused alluvad sarnastele šokkidele. See on analoog paralleelsete trendide eeldusele erinevuste vahe (dif-dif) meetodi puhul, kuid sünteetilise kontrolli korral kontrollime seda sobitamise abil.\nMida rohkem on sekkumiseelseid perioode, seda paremini on võimalik kontrollida nii vaadeldavate kui ka mittevaadeldavate tegurite mõju. Kui suudame sekkumiseelsel perioodil väga täpselt sobitada nii selgitavad tunnused kui ka tulemuste dünaamika, siis on usutav, et sama suhe püsib ka sekkumisjärgsel perioodil.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#platseeboanalüüs-ja-tulemuste-robustsus",
    "href": "08-synthcontr.html#platseeboanalüüs-ja-tulemuste-robustsus",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.4 Platseeboanalüüs ja tulemuste robustsus",
    "text": "9.4 Platseeboanalüüs ja tulemuste robustsus\nSelleks, et veenda lugejat, et leitud tulemused ei ole juhuslikud, kasutatakse sünteetilise kontrolli kontekstis sageli platseeboanalüüse ja RMSPE-suhetega teste.\n\nPlatseebod kontrollüksustele\nPlatseeboanalüüsi põhiidee seisneb selles, et rakendame sünteetilise kontrolli meetodit mitte ainult käsitletavale üksusele, vaid ka igale doonorgrupi üksusele. Iga kontrollüksuse jaoks konstrueerime sünteetilise versiooni, kasutades ülejäänud üksusi doonorina, ning „teeskleme”, et sekkumine toimus samal ajal ka selles kontrollüksuses.\nIga kontrollüksuse puhul võrdleme sekkumisjärgsel perioodil tegelikku tulemust selle sünteetilise kontrolliga. Kui tegelikult mingit mõju ei olnud, peaks nende kahe aegrea vahe jääma väikeseks ning olema sekkumiseelse perioodiga võrreldav. See loob nulljaotuse, millega saame võrrelda käsitletava üksuse kõrvalekallet.\nVisuaalselt võime joonistada kõikide üksuste (käsitletava ja platseebode) trajektoorid ning nende erinevuse sünteetilisest kontrollist. Kui käsitletava üksuse kõrvalekalle on selgelt suurem kui enamikul platseebodel, viitab see tõsiseltvõetavale sekkumise efektile.\n\n\nRMSPE suhted ja p-väärtus\nPlatseeboanalüüsi saab kvantifitseerida ruutkeskmise prognoosivea suhete kaudu. Olgu käsitletava või platseebos üksuse korral:\n\\[ \\text{RMSPE}\\_{\\text{pre}} = \\sqrt{\\frac{1}{T_0} \\sum_{t=1}^{T_0} (Y_{it} - Y_{it}^{\\text{SC}})^2}, \\]\n\\[ \\text{RMSPE}\\_{\\text{post}} = \\sqrt{\\frac{1}{T - T_0} \\sum_{t=T_0+1}^{T} (Y_{it} - Y_{it}^{\\text{SC}})^2}, \\]\nkus \\(Y_{it}^{\\text{SC}}\\) on sünteetilise kontrolli tulemus. Seejärel defineerime suhte:\n\\[ R_i = \\frac{\\text{RMSPE}_{\\text{post}}}{\\text{RMSPE}_{\\text{pre}}}\\]\nSuhe \\(R_i\\) suurem kui 1 viitab sellele, et sekkumisjärgne sobivus on halvem võrreldes sekkumiseelsega, ning suurem suhtarv tähendab suuremat eeldatavat sekkumise mõju. Arvutame selle suhte nii käsitletava üksuse kui ka kõikide platseebode jaoks ning järjestame need kahanevas järjekorras. Käsitletava üksuse positsioon selles jaotuses annabki täpse p-väärtuse:\n\\[ p = \\frac{\\#\\{i : R_i \\geq R_{\\text{treated}}\\}}{\\text{kõigi üksuste arv}}. \\]\nCalifornia näites oli käsitletava üksuse (California) suhe kõige suurem kõigi osariikide seas, mis andis p-väärtuseks ligikaudu \\(1/38 \\approx 0{,}026\\). See tähendab, et vaid ühel juhul 38-st võiksime oodata vähemalt sama suurt kõrvalekallet, kui mõju tegelikult ei oleks.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#tasakaalu-kontroll",
    "href": "08-synthcontr.html#tasakaalu-kontroll",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.5 Tasakaalu kontroll",
    "text": "9.5 Tasakaalu kontroll\nKui kaalud \\(w\\) ja \\(V\\) on õigesti valitud, saavutatakse tasakaal nii selgitavate tunnuste kui ka sekkumiseelse dünaamika osas. See tähendab, et sünteetiline kontroll on iga üksiku selgitava tunnuse osas käsitletavale üksusele võimalikult sarnane ning et ka tulemismuutuja sekkumiseelne aegrida on käsitletava üksuse ja sünteetilise kontrolli vahel võimalikult ühtiv.\nPraktilises rakenduses kontrollitakse tasakaalu tavaliselt nii tabelite kui ka graafikute abil. Tunnuste puhul võrreldakse käsitletava üksuse ja sünteetilise kontrolli keskmisi väärtusi; tulemismuutuja puhul vaadeldakse sekkumiseelse perioodi trajektoore. Hea tasakaal on eelduseks usutavatele mõjuhinnangutele.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#näide",
    "href": "08-synthcontr.html#näide",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.6 Näide",
    "text": "9.6 Näide\nR-keskkonnas on sünteetilise kontrolli rakendamiseks levinud paketid Synth ja SCtools, samuti uuemad paketid, mis realiseerivad üldistatud või augmenteeritud lähenemisi (nt synthdid, augsynth). Alljärgnev näide annab ülevaate klassikalise sünteetilise kontrolli rakendamisest ühe käsitletava ja mitme kontrollüksusega.\nKõigepealt on vajalik, et meil on paneelandmestik, kus igal real on üksus, aasta ja tulemusmuutuja ning tunnused:\n\nlibrary(Synth) \n\n##\n## Synth Package: Implements Synthetic Control Methods.\n\n\n## See https://web.stanford.edu/~jhain/synthpage.html for additional information.\n\nlibrary(SCtools)\n\nLoading required package: future\n\n\nMe kasutame pakette Synth ja SCtools . Vt https://cran.r-project.org/web/packages/Synth/index.html ja https://cran.r-project.org/web/packages/SCtools/index.html\nPõhiviide: Abadie A, Diamond A, Hainmueller J (2011). “Synth: An R Package for Synthetic Control Methods in Comparative Case Studies.” Journal of Statistical Software, 42(13), 1–17. https://www.jstatsoft.org/v42/i13/\nMuud paketid: - kui mitu objekti gsynth, https://cran.r-project.org/web/packages/gsynth/index.htm - kui tahad kombineerida dif-dif analüüsiga\n\nlibrary(tidyverse)\nlibrary(Synth)\nlibrary(SCtools)\nlibrary(foreign)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "08-synthcontr.html#saksamaa-taasühinemine",
    "href": "08-synthcontr.html#saksamaa-taasühinemine",
    "title": "9  Sünteetilise võrdlusobjekti meetod",
    "section": "9.7 Saksamaa taasühinemine",
    "text": "9.7 Saksamaa taasühinemine\nAndmed artiklist A. Abadie, A. Diamond, and J. Hainmueller. 2014. Comparative Politics and the Synthetic Control Method American Journal of Political Science. Viide https://economics.mit.edu/sites/default/files/publications/Comparative%20Politics%20and%20the%20Synthetic%20Control.pdf\nSelles rakendame sünteetilise võrdlusobjekti meetodit, et hinnata 1990. aasta Saksamaa taasühinemise mõju majandusele. Tegu oli ühe olulisema poliitilis sündmusega sõjajärgses Euroopas. Pärast Berliini müüri langemist 9. novembril 1989 ühinesid Saksa Demokraatlik Vabariik ja Saksamaa Liitvabariik ametlikult 3. oktoobril 1990. Sel ajal oli Lääne-Saksamaa SKP elaniku kohta ligikaudu kolm korda kõrgem kui Ida-Saksamaal (Lipschitz ja McDonald 1990).\nMeid huvitab, mis oli ühinemise mõju Lääne-Saksamaa SKP-le.\nLaeme andmed\n\n#Muutke ära andmete kataloog\ndatapath = \"http://kodu.ut.ee/~avork/files/oppetoo/pohjustagajarg/\"\n\n#Lugege sisse andmefail\nd &lt;- read.dta(file = paste0(datapath, \"repgermany.dta\"))\n\nVaatame pisut andmetele sisse.\nKasutame OECD riikide paneelandmeid perioodi 1960–2003 kohta. Saksamaa taasühinemine toimus 1990. aastal, mis annab 30-aastase sekkumiseelse perioodi. Valim lõpeb 2003. aastal, sest ligikaudu kümneaastast perioodi pärast taasühinemist võib pidada mõistlikuks piiriks usutavale prognoosiperioodile. Sünteetiline Lääne-Saksamaa konstrueeritakse doonorriikide hulgast valitud potentsiaalsete võrdlusriikide kaalutud keskmisena. Meie doonorriikide hulgas on valim 16 OECD liikmesriigist.\nTulemusmuutuja on riigi SKP inimese kohta (PPP) järgi korrigeeritud ja mõõdetud 2002. aasta USA dollarites. Taasühinemiseelseid tunnused: SKP elaniku kohta, inflatsioonimäär, tööstuse osakaal loodud lisandväärtusest, investeeringute määr, haridustase ja kaubanduse avatuse mõõdik.\nPeamised tunnused: - index : riigi number - country : riigi nimi - year : aasta - gdp : SKP inimese kohta - infrate : inflatsioon - trade : kaubanduse avatus - schooling : haridustase - industry : tööstuse osakaal - invest60, 70, 80 - kodumaiste investeeringute suhe SKPsse, 5-aastased keskmised. Üks väärtus 1980 aasta kohal.\n\nhead(d)\n\n  index country year  gdp  infrate    trade schooling invest60 invest70\n1     1     USA 1960 2879       NA 9.693181      43.8       NA       NA\n2     1     USA 1961 2929 1.075182 9.444654        NA       NA       NA\n3     1     USA 1962 3103 1.116071 9.429324        NA       NA       NA\n4     1     USA 1963 3227 1.214128 9.470706        NA       NA       NA\n5     1     USA 1964 3420 1.308615 9.725879        NA       NA       NA\n6     1     USA 1965 3667 1.668461 9.730347      43.8       NA       NA\n  invest80 industry\n1       NA       NA\n2       NA       NA\n3       NA       NA\n4       NA       NA\n5       NA       NA\n6       NA       NA\n\n\nMõned joonised\nSKP inimese kohta\n\n#\nd %&gt;% \n  ggplot(aes(x = year, y = gdp, color = country)) +\n  geom_line(aes(linetype=(index!=7))) + #joone tüüp on erinev index = 7 (West Germany jaoks)\n  guides(linetype = \"none\") + #ei taha legendi joone tüübi kohta\n  theme_light() + labs(x = \"\", y = \"GDP per capita\")\n\n\n\n\n\n\n\n\nVaadake ka teisi muutujaid. Asendage gdp teiste näitajatega. Vajadusel lisage geom_point() kui vaatlused on vaid mõne aasta kohta.\n\nd %&gt;% \n  ggplot(aes(x = year, y = schooling, group = country, color = country)) +\n  geom_line(aes(linetype=(index!=7))) + \n  geom_point() +\n  guides(linetype = \"none\") + \n  theme_light()\n\nWarning: Removed 61 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 597 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nKäsud paketis\nTavaline käskude järjekord\n\ndataprep() - valmista ette andmed\nsynth() - leia kaalud, tee sünteetiline võrdlusobjekt\nsynth.tab(), gaps.plot(), and path.plot() - näita tulemusi\npaktist SCtools käsk generate.placebos - tee platseebo analüüs\nvaata tulemusi käskudega plot_placebos, mspe.plot, mspe.test\n\nAndmete ettevalmistamine\n\ndataprep.out &lt;-\n  dataprep(\n           foo = d,\n           predictors    = c(\"gdp\",\"trade\",\"infrate\"),\n           dependent     = \"gdp\", #y variable\n           unit.variable = 1, #first variable is index variable\n           time.variable = 3, #third variable is time variable\n    special.predictors = list(\n      list(\"industry\" ,1981:1990, c(\"mean\")),\n      list(\"schooling\",c(1980,1985), c(\"mean\")),\n      list(\"invest80\" ,1980, c(\"mean\"))\n    ),\n           treatment.identifier = 7, #index = 7 is West Germany\n           controls.identifier = unique(d$index)[-7], #all the rest numbers\n           time.predictors.prior = 1981:1990, #time for normal predictors\n           time.optimize.ssr = 1981:1990, #time period to minimize difference between outcome of treated and synthetic control\n           unit.names.variable = 2, #names\n           time.plot = 1960:2003 #whole time period\n         )\n\n\n Missing data: treated unit; special predictor: special.industry.1981.1990 ; for period: 1990 \n We ignore (na.rm = TRUE) all missing values for predictors.op.\n\n\nVaata üle objekt dataprep.out, mille me salvestasime. See loob lihtsalt kõik vajalikud andmemaatriksid ja vektorid.\n\nstr(dataprep.out)\n\nList of 8\n $ X0               : num [1:6, 1:16] 18029.8 19.2 4.74 30.6 60.15 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"gdp\" \"trade\" \"infrate\" \"special.industry.1981.1990\" ...\n  .. ..$ : chr [1:16] \"1\" \"2\" \"3\" \"4\" ...\n $ X1               : num [1:6, 1] 15808.9 56.78 2.59 34.54 55.5 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:6] \"gdp\" \"trade\" \"infrate\" \"special.industry.1981.1990\" ...\n  .. ..$ : chr \"7\"\n $ Z0               : int [1:10, 1:16] 13533 13940 15008 16549 17600 18439 19407 20711 22047 23064 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:10] \"1981\" \"1982\" \"1983\" \"1984\" ...\n  .. ..$ : chr [1:16] \"1\" \"2\" \"3\" \"4\" ...\n $ Z1               : int [1:10, 1] 12115 12761 13519 14481 15291 15998 16679 17786 18994 20465\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:10] \"1981\" \"1982\" \"1983\" \"1984\" ...\n  .. ..$ : chr \"7\"\n $ Y0plot           : int [1:44, 1:16] 2879 2929 3103 3227 3420 3667 3974 4154 4494 4805 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:44] \"1960\" \"1961\" \"1962\" \"1963\" ...\n  .. ..$ : chr [1:16] \"1\" \"2\" \"3\" \"4\" ...\n $ Y1plot           : int [1:44, 1] 2284 2388 2527 2610 2806 3005 3168 3241 3571 3998 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:44] \"1960\" \"1961\" \"1962\" \"1963\" ...\n  .. ..$ : chr \"7\"\n $ names.and.numbers:'data.frame':  17 obs. of  2 variables:\n  ..$ unit.names  : chr [1:17] \"West Germany\" \"USA\" \"UK\" \"Austria\" ...\n  ..$ unit.numbers: num [1:17] 7 1 2 3 4 5 6 8 9 10 ...\n $ tag              :List of 13\n  ..$ foo                  : chr [1:11] \"c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\"| __truncated__ \"c(\\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"USA\\\", \\\"| __truncated__ \"c(1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1\"| __truncated__ \"c(2879, 2929, 3103, 3227, 3420, 3667, 3974, 4154, 4494, 4805, 4999, 5362, 5838, 6464, 6951, 7519, 8300, 9146, 1\"| __truncated__ ...\n  ..$ predictors           : int [1:3] 4 6 5\n  ..$ predictors.op        : chr \"mean\"\n  ..$ special.predictors   :List of 3\n  .. ..$ :List of 3\n  .. .. ..$ : chr \"industry\"\n  .. .. ..$ : int [1:10] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n  .. .. ..$ : chr \"mean\"\n  .. ..$ :List of 3\n  .. .. ..$ : chr \"schooling\"\n  .. .. ..$ : num [1:2] 1980 1985\n  .. .. ..$ : chr \"mean\"\n  .. ..$ :List of 3\n  .. .. ..$ : chr \"invest80\"\n  .. .. ..$ : num 1980\n  .. .. ..$ : chr \"mean\"\n  ..$ dependent            : int 4\n  ..$ unit.variable        : num 1\n  ..$ time.variable        : num 3\n  ..$ treatment.identifier : num 7\n  ..$ controls.identifier  : num [1:16] 1 2 3 4 5 6 8 9 10 12 ...\n  ..$ time.predictors.prior: int [1:10] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n  ..$ time.optimize.ssr    : int [1:10] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n  ..$ time.plot            : int [1:44] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 ...\n  ..$ unit.names.variable  : num 2\n\n\nX0 – kontrollüksuste ennustajate maatriks. Tavaliselt on need aastate keskmised, vastavalt määratletule. Iga veerg on üks piirkond.\n\ndataprep.out$X0\n\n                                       1            2            3           4\ngdp                         18029.800000 12664.000000 14817.000000 14347.30000\ntrade                          19.199796    52.373944    74.630803   133.61179\ninfrate                         4.740062     6.585358     3.529565     4.58030\nspecial.industry.1981.1990     30.595133    39.061470    35.485312    33.48119\nspecial.schooling.1980.1985    60.150002    34.300001    60.900000    32.10000\nspecial.invest80.1980          22.375999    17.587999    26.642000    21.87600\n                                       5            6            8            9\ngdp                         14857.100000 14293.200000 13869.700000 14462.300000\ntrade                          69.557355    44.736920    42.683143   106.078918\ninfrate                         5.945661     6.368286     9.721693     2.543722\nspecial.industry.1981.1990     27.205048    32.210452    35.912703    32.767722\nspecial.schooling.1980.1985    42.950001    35.400000    29.750000    44.400000\nspecial.invest80.1980          22.217999    27.236000    26.728001    21.840000\n                                      10          12           14         16\ngdp                         14370.200000 19282.90000 13714.800000 9438.40000\ntrade                          74.635595    71.45849    23.042788   43.00722\ninfrate                         7.664475     3.40692     2.058197   19.04085\nspecial.industry.1981.1990     38.716592    31.87100    39.561175   30.26204\nspecial.schooling.1980.1985    40.150000    53.95000    40.900002   21.70000\nspecial.invest80.1980          31.594000    30.96400    34.986000   24.00200\n                                    18          19           20          21\ngdp                         7761.60000 9935.500000 14368.100000 12498.20000\ntrade                         69.97408   39.656889    33.776868    58.87568\ninfrate                       17.30977    9.362696     8.127678    10.87994\nspecial.industry.1981.1990    32.52951   36.403378    32.880581    31.76784\nspecial.schooling.1980.1985   12.15000   15.450000    47.950001    46.35000\nspecial.invest80.1980         26.48800   24.568001    29.695999    25.52200\n\n\nX1 – vaadeldava üksuse andmevektor. Sama ajaperiood.\n\ndataprep.out$X1\n\n                                       7\ngdp                         15808.900000\ntrade                          56.777813\ninfrate                         2.594799\nspecial.industry.1981.1990     34.538488\nspecial.schooling.1980.1985    55.500000\nspecial.invest80.1980          27.017998\n\n\nZ0 – kontrollüksuste väljundmuutuja maatriks sekkumiseelses perioodis.\n\ndataprep.out$Z0\n\n         1     2     3     4     5     6     8     9    10    12    14    16\n1981 13533  9161 11242 11079 11106 10929 10593 11304 10548 15338  9986  7870\n1982 13940  9917 12148 11827 12115 11869 11275 11784 11205 15963 10813  8204\n1983 15008 10669 13048 12334 12822 12518 11812 12419 12022 16611 11346  8388\n1984 16549 11336 13533 13113 13777 13145 12543 13234 13220 17710 12064  8834\n1985 17600 12068 14296 13735 14698 13746 13285 13938 14354 18812 12978  9297\n1986 18439 12795 14921 14292 15608 14308 13896 14613 15184 19458 13590  9525\n1987 19407 13717 15549 15013 16024 14940 14688 15197 15823 20120 14425  9548\n1988 20711 14864 16595 16209 16766 16040 15784 16082 16299 21334 15862 10277\n1989 22047 15716 17768 17345 17418 17193 16875 17387 17043 22965 17269 11036\n1990 23064 16397 19070 18526 18237 18244 17946 18665 18004 24518 18815 11405\n        18    19    20    21\n1981  5812  7447 11513  9736\n1982  6263  7957 11537 10687\n1983  6479  8378 12300 11262\n1984  6570  8812 13120 12141\n1985  6959  9259 14019 12556\n1986  7414  9744 14537 13085\n1987  8126 10542 15554 13402\n1988  9057 11434 16524 13569\n1989 10042 12417 17255 14124\n1990 10894 13365 17322 14420\n\n\nJa vaadeldava üksuse puhul:\n\ndataprep.out$Z1\n\n         7\n1981 12115\n1982 12761\n1983 13519\n1984 14481\n1985 15291\n1986 15998\n1987 16679\n1988 17786\n1989 18994\n1990 20465\n\n\nJoonistamiseks vajalikud andmed on salvestatud objektidesse Y1plot ja Y0plot.\nNüüd saame käivitada käsu synth, et leida optimaalsed kaalud, mis loovad uuritavale üksusele parima võimaliku sünteetilise kontrolli.\n\nsynth.out &lt;- synth(dataprep.out)\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 2780.803 \n\nsolution.v:\n 0.6382063 0.000793192 0.02569357 3.5794e-06 0.005660648 0.3296428 \n\nsolution.w:\n 0.140826 0.0008091836 0.3647215 0.001026341 0.001071105 0.000802521 0.0006526096 0.1809177 0.0006463323 0.171095 0.1346767 0.0004573153 0.0004194751 0.0005437716 0.0007120638 0.0006224255 \n\n\nTulemuste kokkuvõtteks on kolm mugavat funktsiooni.\nKõigi tabelite (V- ja W-kaalud ning sobivus käsitletud ja sünteetilise kontrolli vahel) saamiseks kasutame käsku synth.tab()\n\nsynth.tables &lt;- synth.tab(dataprep.res = dataprep.out,\n                          synth.res = synth.out)\nprint(synth.tables)\n\n$tab.pred\n                              Treated Synthetic Sample Mean\ngdp                         15808.900 15807.581   13669.381\ntrade                          56.778    64.942      59.831\ninfrate                         2.595     3.342       7.617\nspecial.industry.1981.1990     34.538    34.220      33.794\nspecial.schooling.1980.1985    55.500    53.721      38.659\nspecial.invest80.1980          27.018    27.022      25.895\n\n$tab.v\n                            v.weights\ngdp                         0.638    \ntrade                       0.001    \ninfrate                     0.026    \nspecial.industry.1981.1990  0        \nspecial.schooling.1980.1985 0.006    \nspecial.invest80.1980       0.33     \n\n$tab.w\n   w.weights  unit.names unit.numbers\n1      0.141         USA            1\n2      0.001          UK            2\n3      0.365     Austria            3\n4      0.001     Belgium            4\n5      0.001     Denmark            5\n6      0.001      France            6\n8      0.001       Italy            8\n9      0.181 Netherlands            9\n10     0.001      Norway           10\n12     0.171 Switzerland           12\n14     0.135       Japan           14\n16     0.000      Greece           16\n18     0.000    Portugal           18\n19     0.001       Spain           19\n20     0.001   Australia           20\n21     0.001 New Zealand           21\n\n$tab.loss\n           Loss W   Loss V\n[1,] 0.0007521133 2780.803\n\n\n\ntab.pred annab ennustajate väärtused käsitletud üksuse ja sünteetilise kontrolli jaoks, koos valimi keskmisega.\ntab.v annab selgitavate muutujate kaalud.\ntab.w annab piirkondade kaalud.\n\nPane tähele, et tab.loss sisaldab kahte väärtust:\nW–kaotus, mis on seotud ennustajate (X) erinevustega. Mida rohkem X-e lisame, seda suurem see tavaliselt on, sest samad piirkonnakaalud ei pruugi sobida kõigi X-de jaoks. Mida väiksem väärtus, seda paremini on käsitletava X-id sobitatud sünteetilise kontrolli X-idega. See tuleneb w-kaalude optimeerimisest.\nV–kaotus, mis on seotud tulemismuutuja sobivusega. Mida väiksem see väärtus, seda paremini kirjeldame tulemismuutuja varasemaid väärtusi. See on käsitletud üksuse sünteetilise kontrolli sekkumiseelne keskmine ruutprognoosiviga (MSPE). See MSPE tuleneb nii v- kui w-kaalude optimeerimisest.\nTulemismuutuja trajektooride kokkuvõttegraafikute loomiseks (käsitletud ja sünteetiline üksus) kasutame käske path.plot() ja gaps.plot()\nTase:\n\n#to plot in levels (treated and synthetic)\npath.plot(dataprep.res = dataprep.out,synth.res = synth.out)\n\n\n\n\n\n\n\n## plot the gaps (treated - synthetic)\n\nErinevus:\n\ngaps.plot(dataprep.res = dataprep.out,synth.res = synth.out)\n\n\n\n\n\n\n\n\nPlatseebode genereerimiseks kasutame paketti SCtools. See kohtleb iga piirkonda kordamööda kui osalejat ja arvutab mõjud. See võtab mõnevõrra aega.\n\nplacebos &lt;- generate.placebos(dataprep.out, synth.out, Sigf.ipop = 3, strategy = \"multicore\") #multicore - quicker, parallel computing\n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 276080.3 \n\nsolution.v:\n 0.3425308 0.03183171 0.2102354 0.1742354 0.2404496 0.0007171006 \n\nsolution.w:\n 6.55899e-05 0.01197019 0.0001114836 0.04900369 0.0002583561 6.08367e-05 0.0003888953 6.88759e-05 0.7404987 0.0001330694 4.2118e-06 3.04587e-05 3.5365e-05 0.1972425 0.000127783 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 32190.55 \n\nsolution.v:\n 0.8259937 0.01671772 0.07973004 0.06119424 0.01369206 0.002672199 \n\nsolution.w:\n 0.00285441 0.01132922 0.008744401 0.00268481 0.003022315 0.006265804 0.007058692 0.3404279 0.001946773 0.2649984 0.002042414 0.0006367799 0.3416422 0.002869065 0.003476834 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 19980.97 \n\nsolution.v:\n 0.4787951 0.3388293 0.007484978 0.0001112912 0.001652476 0.1731269 \n\nsolution.w:\n 0.02511805 0.03651043 0.2074622 0.03747018 0.03469146 0.03224069 0.08820579 2.90786e-05 0.2403434 0.1099949 0.03441481 0.04039343 0.03636224 0.03532518 0.04143808 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 8117.844 \n\nsolution.v:\n 0.916682 0 0.00348149 0.00806678 0.0717697 1.4e-09 \n\nsolution.w:\n 0.01640006 0.01781232 0.01560508 0.03468132 0.05145937 0.2111343 0.02535471 0.01970952 0.2679103 0.01961133 0.0176838 0.01009594 0.2540115 0.01998526 0.01854523 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 112715 \n\nsolution.v:\n 0.8262578 0.01547729 0.004385314 0.1143318 0.03652118 0.003026596 \n\nsolution.w:\n 0.4923876 2.59848e-05 0.0001332046 3.563e-06 0.0004786393 8.62806e-05 0.001857162 4.37331e-05 0.1162807 1.82499e-05 0.3875314 0.0003444362 5.33549e-05 0.0001491118 0.0006065782 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 16092.44 \n\nsolution.v:\n 0.3407636 5.5175e-06 2.8957e-06 0.5236969 0.007982415 0.1275486 \n\nsolution.w:\n 0.03129486 0.0110189 0.0246643 0.03424982 0.09319681 0.02989769 0.03467728 0.01946296 0.3316389 0.01826013 0.06607518 0.1977095 0.02824211 0.03617838 0.04343317 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 1756.905 \n\nsolution.v:\n 0.8862834 0.07382511 6.5338e-06 0.003065943 0.01429302 0.02252603 \n\nsolution.w:\n 0.1032388 0.07495536 0.01038281 0.005087013 0.01726933 0.048653 0.009855227 1.89334e-05 0.1917291 0.1527632 0.06770593 0.0515878 0.2024148 0.03804321 0.02629549 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 10482.58 \n\nsolution.v:\n 0.9173173 0.06084155 2.86454e-05 0.01783268 0.003979336 4.422e-07 \n\nsolution.w:\n 0.01264816 0.01856447 0.02796183 0.6125783 0.03597383 0.02029793 0.01751268 0.01976776 0.103337 0.01508858 0.02409641 0.02617124 0.01966455 0.0195419 0.02679536 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 195128.4 \n\nsolution.v:\n 0.2765538 0 0.7234462 0 0 0 \n\nsolution.w:\n 0.08630043 0.04834269 0.04707078 0.04816556 0.05366396 0.0525315 0.06465101 0.04451544 0.1911137 0.04290499 0.09486799 0.05829396 0.04827194 0.05969433 0.05961178 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 1782453 \n\nsolution.v:\n 0.8404504 2.14e-08 0.1595494 2.254e-07 2.2e-09 7.9e-09 \n\nsolution.w:\n 0.9980796 0.0001207329 0.00020498 0.0001763683 0.0001824006 0.0001608133 0.0001298709 0.0001991923 0.0001537346 0.0001742107 5.1868e-05 4.30463e-05 7.15177e-05 0.0001505152 0.0001011647 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 139219.8 \n\nsolution.v:\n 0.8057263 0.1604086 0.02487788 0.008692253 0.0002203832 7.46251e-05 \n\nsolution.w:\n 0.4549119 0.02411708 0.00276963 0.0007457149 0.0008276736 0.002419813 0.002383868 0.00123767 0.002303478 0.0005065878 6.10505e-05 0.0005605558 0.5046114 0.001628748 0.0009148221 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 288736.9 \n\nsolution.v:\n 0.855861 1.5425e-06 0.0401323 0.01552743 0.08847763 1.047e-07 \n\nsolution.w:\n 0.009829267 0.003956324 7.9252e-06 0.005603807 0.01602739 0.00783904 0.01448734 0.002618719 0.005273507 0.0007002579 0.002452507 0.6964841 0.006072436 0.007849924 0.2207974 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 3148050 \n\nsolution.v:\n 0.9750653 2.099e-07 1.209e-07 6.39e-08 0.02493344 8.392e-07 \n\nsolution.w:\n 2.5866e-06 2.34944e-05 1.12049e-05 1.40753e-05 1.15981e-05 1.41888e-05 1.64603e-05 1.31223e-05 1.36682e-05 2.361e-07 1.67191e-05 0.9996813 0.0001442919 1.33895e-05 2.3696e-05 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 1992.887 \n\nsolution.v:\n 0.9172637 0.0188953 2.9369e-06 0.01112606 0.0444585 0.008253505 \n\nsolution.w:\n 0.002483156 0.1491128 0.006233539 0.007763327 0.007569434 0.01373196 0.08393888 0.007195305 0.009595813 0.0002568884 0.05700656 0.05077503 0.5824265 0.01020823 0.01170239 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 95139.6 \n\nsolution.v:\n 0.8387851 0.00321895 0.1217191 0.0003357233 0.03587282 6.82912e-05 \n\nsolution.w:\n 0.3206254 0.02761799 0.0420507 0.0142251 0.01990836 0.02238627 0.02181875 0.01868822 0.0209883 0.01676862 0.0308802 0.04531528 0.03342573 0.02871633 0.3365847 \n\n\nX1, X0, Z1, Z0 all come directly from dataprep object.\n\n\n**************** \n searching for synthetic control unit  \n \n\n**************** \n**************** \n**************** \n\nMSPE (LOSS V): 304524.5 \n\nsolution.v:\n 0.4853115 0.0327623 0.3046622 0.1348863 0.01765844 0.02471924 \n\nsolution.w:\n 0.01212527 0.00403598 0.3099178 0.005758418 0.1406064 0.009735317 0.006540916 0.006057046 0.006935646 0.01184047 0.005636344 0.4169481 0.008306444 0.006385719 0.04917005 \n\n\nNew names:\n• `w.weight` -&gt; `w.weight...1`\n• `w.weight` -&gt; `w.weight...2`\n• `w.weight` -&gt; `w.weight...3`\n• `w.weight` -&gt; `w.weight...4`\n• `w.weight` -&gt; `w.weight...5`\n• `w.weight` -&gt; `w.weight...6`\n• `w.weight` -&gt; `w.weight...7`\n• `w.weight` -&gt; `w.weight...8`\n• `w.weight` -&gt; `w.weight...9`\n• `w.weight` -&gt; `w.weight...10`\n• `w.weight` -&gt; `w.weight...11`\n• `w.weight` -&gt; `w.weight...12`\n• `w.weight` -&gt; `w.weight...13`\n• `w.weight` -&gt; `w.weight...14`\n• `w.weight` -&gt; `w.weight...15`\n• `w.weight` -&gt; `w.weight...16`\n\n\nPärast seda saame joonistada platseebomõjud.\n\nplot_placebos(placebos)\n\n\n\n\n\n\n\n\nNäeme, et mõned teisedki riigid kogesid langust alates 1990ndatest. Samuti saame arvutada sekkumisjärgse MSPE ja sekkumiseelse MSPE suhte. Mida suurem on see erinevus, seda keerulisem on tulevikku prognoosida võrreldes minevikuga. Kui paljud riigid saavad suure suhte, võib meie hinnatud mõju olla lihtsalt juhuslik variatsioon.\n\nmspe.plot(placebos)\n\n\n\n\n\n\n\n\nMitte ühelgi riigil ei ole suuremat kasvu MSPEs.\nP-väärtus käsuga\n\n#or with the command\nmspe.test(placebos)\n\n$p.val\n[1] 0.05882353\n\n$test\n    MSPE.ratios         unit\n1    44.5063518          USA\n2    40.6205409           UK\n3    48.8761931      Austria\n4    60.3306156      Belgium\n5    11.2244736      Denmark\n6    43.2482383       France\n7   118.6159461        Italy\n8   203.7017913  Netherlands\n9   171.4798547       Norway\n10    4.5197407  Switzerland\n11   17.5588852        Japan\n12   13.3878627       Greece\n13    0.3159692     Portugal\n14  445.2381197        Spain\n15    7.4450742    Australia\n16   14.1206513  New Zealand\n17 1204.5679685 West Germany\n\n\nKontrolliks käsitsi kaotus sõltuvas tulemuses\n\nY1plot &lt;- dataprep.out$Y1plot\nY0plot &lt;- dataprep.out$Y0plot\ntime &lt;- dataprep.out$tag$time.plot\ntreat.time &lt;- 1991\n#ajad kaalutud kaotuse joaks\npre_idx &lt;- which(time&gt; 1980 & time&lt; treat.time)\n\n#Kontrolliks, mis aastad\ntime[pre_idx]\n\n [1] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n\n#Kaalud\nw &lt;- synth.tables$tab.w$w.weights \n\n#Sünteetiline keskmine\nY_synth_pre &lt;- Y0plot[pre_idx, ] %*% w\n\n#Kontrolliks\nplot(pre_idx, Y_synth_pre, type = \"l\")\n\n\n\n\n\n\n\n#erinevus\ngaps_pre &lt;- Y1plot[pre_idx] - Y_synth_pre\n\n#Kontrolliks\nplot(pre_idx, gaps_pre, type = \"l\")\n\n\n\n\n\n\n\n#Käsitsi kaotus Y-s\nlossV_manual &lt;- mean(gaps_pre^2)\nas.numeric(lossV_manual)\n\n[1] 3702.133\n\n#Meil\nsynth.tables$tab.loss\n\n           Loss W   Loss V\n[1,] 0.0007521133 2780.803",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Sünteetilise võrdlusobjekti meetod</span>"
    ]
  },
  {
    "objectID": "09-mlpuumets.html",
    "href": "09-mlpuumets.html",
    "title": "10  Masinõppemudelid",
    "section": "",
    "text": "10.1 Taust",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Masinõppemudelid</span>"
    ]
  },
  {
    "objectID": "09-mlpuumets.html#näide",
    "href": "09-mlpuumets.html#näide",
    "title": "10  Masinõppemudelid",
    "section": "10.2 Näide",
    "text": "10.2 Näide\nTuleb kunagi",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Masinõppemudelid</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html",
    "href": "10-mllasso.html",
    "title": "11  LASSO mõju hindamisel",
    "section": "",
    "text": "11.1 Seade\nSelles peatükis käsitleme LASSO-regressioonimudelit ja kantregressiooni (ridge), mis kuuluvad regulariseeritud regressioonimeetodite hulka. Need meetodid on kasulikud olukordades, kus meil on palju selgitavaid tunnuseid, sh nende polünoomid ja interaktsioonid, selgitavate tunnuste vahel on tugev multikollineaarsus ning me soovime automatiseerida mudelisse kaasatavate tunnuste valikut. Sellistes tingimustes ei tööta klassikaline vähimruutude meetod (OLS) hästi, eriti kui parameetrite arv on lähedane vaatluste arvule koguni suurem.\nLisaks prognoosimisele pakuvad LASSO ja ridge vahendeid põhjuslike mõjude hindamiseks keerukates olukordades, kus:\nEraldi käsitleme kolme lähenemist:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#seade",
    "href": "10-mllasso.html#seade",
    "title": "11  LASSO mõju hindamisel",
    "section": "",
    "text": "on palju potentsiaalseid kontrollmuutujaid,\neeldame tingimuslikku sõltumatust (CIA),\n\n\n\njääkliikmete meetodit (partialling out),\ntopeltvaliku meetodit (double selection),\ninstrumentmuutuja meetodit koos LASSO-põhise tunnuste valikuga.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#regulaaritud-regressioon-üldine-raamistik",
    "href": "10-mllasso.html#regulaaritud-regressioon-üldine-raamistik",
    "title": "11  LASSO mõju hindamisel",
    "section": "11.2 Regulaaritud regressioon: üldine raamistik",
    "text": "11.2 Regulaaritud regressioon: üldine raamistik\n\nLineaarne mudel ja OLS\nLähtume klassikalisest lineaarsest mudelist:\n\\[\nY_i = X_i'\\beta + \\varepsilon_i,\\quad i = 1,\\dots,n,\n\\]\nkus \\(Y_i\\) on sõltuv muutuja, \\(X_i\\) pikkusega \\(p\\) selgitavate tunnuste vektor, \\(\\beta\\) tundmatu parameetrite vektor ja \\(\\varepsilon_i\\) vealiige. Vektorkujul võime kirjutada:\n\\[\nY = X\\beta + \\varepsilon,\n\\]\nkus \\(Y \\in \\mathbb{R}^n\\), \\(X \\in \\mathbb{R}^{n \\times p}\\), \\(\\beta \\in \\mathbb{R}^p\\) ja \\(\\varepsilon \\in \\mathbb{R}^n\\).\nOLS-hinnang leitakse miinimumruutude põhimõttel:\n\\[\n\\hat{\\beta}^{\\text{OLS}} = \\arg\\min_{\\beta} \\frac{1}{n} \\sum_{i=1}^n (Y_i - X_i'\\beta)^2\n= \\arg\\min_{\\beta} \\frac{1}{n}\\|Y - X\\beta\\|_2^2.\n\\]\nKui \\(p\\) on suur (või koguni \\(p &gt; n\\)), muutub OLS ebastabiilseks:\n\nparameetrite variatsioon on suur,\nmultikollineaarsus tekitab ebakindlust,\nmudel kipub andmetesse üle-sobituma.\n\nRegulaaritud regressiooni idee on lisada optimeerimiskriteeriumile karistustermin, mis surub parameetreid nulli suunas ja vähendab mudeli keerukust.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#regulaaritud-regressiooni-üldkuju",
    "href": "10-mllasso.html#regulaaritud-regressiooni-üldkuju",
    "title": "11  LASSO mõju hindamisel",
    "section": "11.3 Regulaaritud regressiooni üldkuju",
    "text": "11.3 Regulaaritud regressiooni üldkuju\nRegulaaritud regressiooni üldine eesmärk on leida:\n\\[\n\\hat{\\beta} = \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\sum_{i=1}^n (Y_i - X_i'\\beta)^2\n+ \\lambda P(\\beta)\n\\right\\},\n\\]\nkus \\(P(\\beta)\\) on karistusfunktsioon ja \\(\\lambda \\ge 0\\) regulaarimisparameeter, mis kontrollib karistuse tugevust.\n\nKui \\(\\lambda = 0\\), langeb mudel kokku OLS-iga.\nKui \\(\\lambda\\) kasvab, suureneb parameetrite kahanemine nulli suunas ja mudeli keerukus väheneb.\n\nEduka regulaarimise eelduseks on tavaliselt, et tunnused \\(X\\) standardiseeritakse (nullkeskmine ja ühikvariatsioon), et karistus erinevate tunnuste vahel oleks võrreldav.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#mudeli-definitsioon",
    "href": "10-mllasso.html#mudeli-definitsioon",
    "title": "11  LASSO mõju hindamisel",
    "section": "12.1 Mudeli definitsioon",
    "text": "12.1 Mudeli definitsioon\nKantregressioon (ridge-regressioon) kasutab L2-karistust:\n\\[\n\\hat{\\beta}^{\\text{ridge}}\n= \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\sum_{i=1}^n (Y_i - X_i'\\beta)^2\n+ \\lambda \\sum_{j=1}^p \\beta_j^2\n\\right\\}\n= \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\|Y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_2^2\n\\right\\}.\n\\]\nSiin surutakse kõiki koefitsiente nulli suunas, kuid ükski neist ei muutu täpselt nulliks (välja arvatud erijuhtudel). Seetõttu:\n\nridge ei tee otsest tunnuste valikut,\nkuid vähendab multikollineaarsuse mõju ja stabiliseerib hinnanguid.\n\nMaatrikskujuline suletud lahend on\n\\[\n\\hat{\\beta}^{\\text{ridge}} = (X'X + n\\lambda I_p)^{-1} X'Y,\n\\]\nkus \\(I_p\\) on \\(p \\times p\\) ühikmaatriks.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#regulaarimisparameeter-ja-valik",
    "href": "10-mllasso.html#regulaarimisparameeter-ja-valik",
    "title": "11  LASSO mõju hindamisel",
    "section": "12.2 Regulaarimisparameeter ja valik",
    "text": "12.2 Regulaarimisparameeter ja valik\nRegulaarimisparameeter \\(\\lambda\\) kontrollib nihe–dispersioon kompromissi:\n\nväikese \\(\\lambda\\) korral on nihe väike, kuid dispersioon suur,\nsuure \\(\\lambda\\) korral suureneb nihe, kuid dispersioon väheneb.\n\nPrognoosimisel valitakse \\(\\lambda\\) tavaliselt ristvalideerimisega (K-kordne CV):\n\njaga andmed \\(K\\) osaks;\niga kandidaadi \\(\\lambda\\) korral hinda mudel \\(K-1\\) osal andmetest;\narvuta keskmine ruutprognoosiviga järelejäänud osal;\nvali \\(\\lambda\\), mis minimeerib prognoosivea.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#millal-kasutada-ridgei",
    "href": "10-mllasso.html#millal-kasutada-ridgei",
    "title": "11  LASSO mõju hindamisel",
    "section": "12.3 Millal kasutada ridge’i",
    "text": "12.3 Millal kasutada ridge’i\nKantregressiooni kasutatakse eelkõige siis, kui:\n\nselgitavaid tunnuseid on palju (sh polünoomid, interaktsioonid),\nesineb tugev multikollineaarsus,\neesmärk on hea prognoos, mitte üksikute koefitsientide selge interpreteerimine,\nparameetrite arv on lähedane vaatluste arvule.\n\nPõhjusliku mõju hindamise juures kasutatakse ridge’i tavaliselt osana laiendatud meetoditest (nt Augmented Synthetic Control, double machine learning) – harvem iseseisva „mõju hinnanguna“.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#mudeli-definitsioon-1",
    "href": "10-mllasso.html#mudeli-definitsioon-1",
    "title": "11  LASSO mõju hindamisel",
    "section": "13.1 Mudeli definitsioon",
    "text": "13.1 Mudeli definitsioon\nLASSO (Least Absolute Shrinkage and Selection Operator) kasutab L1-karistust:\n\\[\n\\hat{\\beta}^{\\text{LASSO}}\n= \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\sum_{i=1}^n (Y_i - X_i'\\beta)^2\n+ \\lambda \\sum_{j=1}^p |\\beta_j|\n\\right\\}\n= \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\|Y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\n\\right\\}.\n\\]\nOluline omadus: L1-karistus võib seada osa koefitsiente täpselt nulli:\n\nkui tunnus \\(X_j\\) on väheoluline, siis \\(\\hat{\\beta}_j = 0\\),\nkui tunnus on oluline, võib \\(\\hat{\\beta}_j \\neq 0\\).\n\nSeega LASSO kombineerib:\n\nregulaarimise (koefitsientide kahanemine),\ntunnuste valiku (paljud koefitsiendid muutuvad nulliks).\n\nIntuitsioonilt:\n\nkui \\(\\lambda\\) on väike, on tulemus sarnane OLS-iga, paljud koefitsiendid mitnullilised;\nkui \\(\\lambda\\) on suur, jääb mudelisse vähe tunnuseid.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#elastic-net",
    "href": "10-mllasso.html#elastic-net",
    "title": "11  LASSO mõju hindamisel",
    "section": "13.2 Elastic net",
    "text": "13.2 Elastic net\nElastic net ühendab ridge’i ja LASSO karistused:\n\\[\n\\hat{\\beta}^{\\text{EN}}\n= \\arg\\min_{\\beta}\n\\left\\{\n\\frac{1}{n}\\|Y - X\\beta\\|_2^2\n+ \\lambda\n\\left(\n\\alpha \\|\\beta\\|_1 + (1-\\alpha)\\|\\beta\\|_2^2\n\\right)\n\\right\\},\n\\]\nkus \\(0 \\le \\alpha \\le 1\\).\n\n\\(\\alpha = 1\\) korral saame LASSO,\n\\(\\alpha = 0\\) korral ridge’i.\n\nElastic net on kasulik, kui tunnused on tugevalt korreleeritud: puhas LASSO kaldub valima ühe tunnuse grupist ja teised välja jätma, elastic net võimaldab „grupivalikut“.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#post-lasso",
    "href": "10-mllasso.html#post-lasso",
    "title": "11  LASSO mõju hindamisel",
    "section": "13.3 Post-LASSO",
    "text": "13.3 Post-LASSO\nLASSO koefitsiendid on nihkega nulli suunas, kui \\(\\lambda &gt; 0\\). See on prognoosimisel aktsepteeritav, kuid mõju interpreteerimisel võib nihe häirida. Post-LASSO lähenemine:\n\nhinda LASSO mudel ja vali aktiivsete tunnuste hulk \\[\n\\hat{S} = \\{j: \\hat{\\beta}_j^{\\text{LASSO}} \\neq 0\\};\n\\]\nhinda OLS-ga mudel, mis sisaldab ainult tunnuseid \\(X_{\\hat{S}}\\): \\[\nY_i = X_{i,\\hat{S}}'\\beta_{\\hat{S}} + u_i.\n\\]\n\nNii saadud OLS-kordajaid nimetatakse Post-LASSO hinnanguteks. Need on endiselt mõjutatud tunnuste valiku ebastabiilsusest, kuid vähem nihkes kui LASSO koefitsiendid ise.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#tavaline-lasso-glmnet-cv-põhine",
    "href": "10-mllasso.html#tavaline-lasso-glmnet-cv-põhine",
    "title": "11  LASSO mõju hindamisel",
    "section": "14.1 Tavaline LASSO (glmnet, CV-põhine)",
    "text": "14.1 Tavaline LASSO (glmnet, CV-põhine)\nTüüpiline LASSO rakendus prognoosimisel (nt pakett glmnet) kasutab ristvalideerimist:\n\n\\(\\lambda\\) valitakse, et minimeerida prognoosiviga (MSE) ristvalideerimisel;\nkõik tunnused koheldakse karistamisel ühtviisi;\neesmärk: võimalikult hea prognoos.\n\nSee on sobiv, kui:\n\nhuvi pakub eeskätt prognoositäpsus,\nei ole vaja täpseid usalduspiire mõjuhinnangutele,\nmodelleerime „must kast“ seoseid.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#teooriapõhine-lasso-rigorous-lasso-hdmrlasso",
    "href": "10-mllasso.html#teooriapõhine-lasso-rigorous-lasso-hdmrlasso",
    "title": "11  LASSO mõju hindamisel",
    "section": "14.2 Teooriapõhine LASSO (rigorous LASSO, hdm::rlasso)",
    "text": "14.2 Teooriapõhine LASSO (rigorous LASSO, hdm::rlasso)\nTeooriapõhine LASSO (nt R-pakett hdm, funktsioon rlasso) valib \\(\\lambda\\) teoreetiliste piiride alusel, lähtudes:\n\nvaatluste arvust \\(n\\),\ntunnuste arvust \\(p\\),\nvealiikme dispersiooni hinnangust,\nvõimalusest, et olemas on heteroskedastilisus.\n\nEesmärk:\n\nusaldusväärne järeldus põhjusliku seose kohta,\nkorrektsed usaldusvahemikud ja testid.\n\nOmadused:\n\n\\(\\lambda\\) on tavaliselt suurem kui ristvalideerimisel, mudel konservatiivsem;\nvalib vähem tunnuseid (harvem üle-sobitamine);\nstandardvigade hinnangud on kohandatud heteroskedastilisuse suhtes.\n\nTeooriapõhine LASSO sobib kõige paremini mõju hindamise kontekstis, kus peamine on parameetri usaldusväärne järeldus, mitte pelgalt hea prognoos.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#fwl-teoreem-ja-residuaalne-regressioon",
    "href": "10-mllasso.html#fwl-teoreem-ja-residuaalne-regressioon",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.1 FWL-teoreem ja residuaalne regressioon",
    "text": "16.1 FWL-teoreem ja residuaalne regressioon\nVõtame mudeli, kus huvi pakub ravi mõju:\n\\[\nY_i = \\alpha D_i + X_i'\\beta + u_i,\n\\]\nkus \\(D_i\\) on ravi (näiteks koolitus, ravimeede, poliitikameede) ja \\(X_i\\) kontrolltunnuste vektor. Frisch–Waugh–Lovelli (FWL) teoreem ütleb, et OLS-hinnang \\(\\hat{\\alpha}\\), mis saadakse ühisest regressioonist \\(Y\\) peal \\(D\\) ja \\(X\\), võrdub järgmise kolmesammulise protseduuri tulemusena saadud hinnanguga:\n\nregresseeri \\(Y\\) \\(X\\)-ile ja võta jäägid: \\[\n\\tilde{Y}_i = Y_i - \\hat{\\mathbb{E}}[Y_i \\mid X_i];\n\\]\nregresseeri \\(D\\) \\(X\\)-ile ja võta jäägid: \\[\n\\tilde{D}_i = D_i - \\hat{\\mathbb{E}}[D_i \\mid X_i];\n\\]\nregresseeri \\(\\tilde{Y}_i\\) \\(\\tilde{D}_i\\)-le OLS-iga: \\[\n\\tilde{Y}_i = \\alpha \\tilde{D}_i + \\eta_i.\n\\]\n\nSee tähendab, et oleme „partialiseerinud välja“ \\(X\\)-de mõju nii tulemuselt kui ravilt ja hindame seejärel seost nende jääkide vahel.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#tingimusliku-sõltumatuse-eeldus",
    "href": "10-mllasso.html#tingimusliku-sõltumatuse-eeldus",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.2 Tingimusliku sõltumatuse eeldus",
    "text": "16.2 Tingimusliku sõltumatuse eeldus\nMõju hindamisel eeldame sageli:\n\\[\n(Y_i(0), Y_i(1)) \\perp D_i \\mid X_i\n\\]\n(CIA – conditional independence assumption). Kui see eeldus kehtib ja \\(X_i\\) vektor on piisavalt rikas, siis on ravi keskmine mõju identifitseeritud mudelis\n\\[\nY_i = \\alpha D_i + X_i'\\beta + u_i.\n\\]\nKui aga \\(X\\)-e on palju, ei sobi lihtne OLS kontrollimiseks. Jääkide meetod LASSOga asendab OLS-põhise regressiooni \\(Y\\) ja \\(D\\) peal prognoosimismudelitega, mis on hinnatud LASSO abil.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#jääkide-meetod-lassoga-sammud",
    "href": "10-mllasso.html#jääkide-meetod-lassoga-sammud",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.3 Jääkide meetod LASSOga: sammud",
    "text": "16.3 Jääkide meetod LASSOga: sammud\nEeldame, et meil on:\n\n\\(Y\\) – tulemusmuutuja,\n\\(D\\) – ravi muutuja,\n\\(X\\) – suur hulk kandidaattunnuseid (võib olla \\(p &gt; n\\)).\n\nJääkide meetod LASSOga toimib järgmiselt.\n\nsamm – \\(Y\\) prognoosimine \\(X\\)-dega:\n\n\\[\n\\hat{m}_Y(X_i) = \\hat{\\mathbb{E}}[Y_i \\mid X_i]\n\\quad\\text{LASSO abil,}\n\\]\nnäiteks:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#jääkide-meetod-lassoga-sammud-1",
    "href": "10-mllasso.html#jääkide-meetod-lassoga-sammud-1",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.4 Jääkide meetod LASSOga: sammud",
    "text": "16.4 Jääkide meetod LASSOga: sammud\nEeldame, et meil on:\n\n(Y) – tulemusmuutuja,\n(D) – ravi muutuja,\n(X) – suur hulk kandidaattunnuseid (võib olla (p &gt; n)).\n\nJääkide meetodi LASSOga idee on kasutada LASSOt selleks, et „välja võtta” (X)-de mõju nii (Y)-lt kui (D)-lt ja seejärel hinnata ravi mõju nende jääkide vahelise regressiooniga. See põhineb Frisch–Waugh–Lovelli teoreemil, mille kohaselt saab huvipakkuva ravi koefitsiendi () leida regressioonist jääkide peal.\n\n1. samm – (Y) prognoosimine (X)-dega\nKõigepealt prognoosime tulemusmuutujat (Y) kontrolltunnuste (X) abil LASSOga:\n\\[\n\\hat{m}_Y(X_i) = \\hat{\\mathbb{E}}[Y_i \\mid X_i],\n\\]\nja leiame jäägid:\n\\[\n\\tilde{Y}_i = Y_i - \\hat{m}_Y(X_i).\n\\]\nR-is võiks see välja näha näiteks nii:\nSiin kasutab rlasso teooriapõhist () valikut, mis sobib paremini mõju hindamiseks kui puhas ristvalideerimine.\n\n\n2. samm – (D) prognoosimine (X)-dega\nJärgmisena prognoosime ravi (D) samade kontrolltunnuste abil:\n\\[\n\\hat{m}_D(X_i) = \\hat{\\mathbb{E}}[D_i \\mid X_i],\n\\]\nja leiame meetmes osalemise jäägid:\n\\[\n\\tilde{D}_i = D_i - \\hat{m}_D(X_i).\n\\]\nKui (D) on binaarne (nt osales koolitusel vs ei osalenud), kasutab LASSO siin lineaarset tõenäosusmudelit; vajadusel saab kasutada ka logit/probit-mudeleid, kuid klassikalises hdm-raamistikus lähtutakse lineaarse regressiooni loogikast.\n\n\n3. samm – mõju hindamine jääkide regressioonina\nKolmandas sammus regressime jääktulemust (_i) jäigravi (_i) peal:\n\\[ \\tilde{Y}\\_i = \\alpha \\tilde{D}\\_i + \\eta\\_i.\\] OLS-hinnang () on siin LASSO-põhise partialling out -meetodi hinnang ravi keskmisele mõjule (CATE või ATE sõltuvalt seadetest ja laiendustest).\nR-is:\nPaketis hdm saab kogu protseduuri teha ühe käsuga:\nSiin:\n\nmethod = \"partialling out\" ütleb, et kasutatakse jääkide meetodit;\npost = TRUE tähendab, et lõplik regressioon tehakse Post-LASSO-na (tunnuste valiku järel OLS).\n\nJääkide meetodi puhul on võtme-eeldus, et prognoosid (_Y(X_i)) ja (_D(X_i)) on piisavalt täpsed, ning et CIA (tingimuslik sõltumatus) kehtib: pärast (X)-de arvessevõttu ei ole ravi (D) korreleeritud potentsiaalsete tulemustega.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#topeltvaliku-meetod-double-selection",
    "href": "10-mllasso.html#topeltvaliku-meetod-double-selection",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.5 Topeltvaliku meetod (double selection)",
    "text": "16.5 Topeltvaliku meetod (double selection)\n\nMotivatsioon\nJääkide meetod eeldab kaudselt, et samad kontrollmuutujad (X) on olulised nii (Y) kui (D) jaoks, ning et LASSO valib need piisavalt hästi välja prognoosimissammudes. Praktikas võib juhtuda, et:\n\nmõni tunnus mõjutab tugevalt ravi (D), kuid mõjutab (Y)-d vaid nõrgalt;\nLASSO võib selle tunnuse välja jätta, kui prognoosime (Y)-d;\nsee võib omakorda tekitada nihet ravi mõju hinnangus, sest oluline konfundeeriv tunnus puudub.\n\nTopeltvaliku meetod vähendab seda ohtu, kasutades LASSOt nii (Y)- kui (D)-võrrandi jaoks ja kombineerides tulemused.\n\n\nSammud\nAlgne mudel:\n\\[ Y_i = \\alpha D_i + X_i'\\beta + u_i.\\]\nTopeltvaliku meetodi sammud:\n\nLASSO regressioon tulemuse jaoks:\n\\[ Y_i = X_i'\\beta\\_Y + u_i.\\]\nValime tundede hulga:\n\\[ \\hat{S}*Y = { j :* \\hat{\\beta}{Y,j}\\^{\\text{LASSO}} \\neq 0 }.\\]\nLASSO regressioon ravi jaoks:\n\\[ D_i = X_i'\\beta\\_D + v_i.\\]\nValime tundede hulga:\n\\[ \\hat{S}*D = { j :* \\hat{\\beta}{D,j}\\^{\\text{LASSO}} \\neq 0 }.\\]\nÜhendame tulemused:\n\\[ \\hat{S} = \\hat{S}\\_Y \\cup \\hat{S}\\_D.\\]\nHinnang Post-LASSO OLS-iga:\n\\[ Y_i = \\alpha D_i + X\\_{i,\\hat{S}}'\\beta\\_{\\hat{S}} + u_i.\\]\n\nR-s:\nTopeltvaliku meetodi omadused:\n\nkaasab mudelisse nii tunnused, mis on olulised (Y) jaoks, kui need, mis on olulised (D) jaoks;\non robustsem ohu suhtes, et mõni oluline tunnus jääb ühe LASSO-sammu käigus välja;\ntavaliselt toob mudelisse rohkem kontrollmuutujaid kui puhas partialling out;\nstandardvead võivad pisut suureneda (rohkem kontrolle), kuid nihe väheneb.\n\nIntuitsioon: kui mingi (X_j) on oluline ravi (D) jaoks (vältimaks omistatavat seost (D)-le, mis tegelikult tuleneb (X_j)-st), siis jõuab see mudelisse vähemalt ravi-võrrandi kaudu, isegi kui (Y)-võrrandi LASSO teda ei valinud.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#instrumentmuutuja-meetod-lassoga",
    "href": "10-mllasso.html#instrumentmuutuja-meetod-lassoga",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.6 Instrumentmuutuja meetod LASSOga",
    "text": "16.6 Instrumentmuutuja meetod LASSOga\n\nEndogeensus ja IV-raamistik\nKui ravi (D) on endogeenne, st (\\[u_i \\mid D_i\\] ), siis ei ole lihtne kontrollmuutujate lisamine piisav. Kasutame instrumentmuutujat (Z), mis:\n\non korreleeritud ravi (D)-ga (relevantsus),\nei ole korreleeritud vealiikmega (u) (eksogeensus).\n\nKlassikaline IV-mudel:\n\\[ Y_i = \\alpha D_i + X_i'\\beta + u_i,\\] \\[ D_i = Z_i'\\pi + X_i'\\gamma + v_i.\\]\nKui instrumente ja kontrolle on vähe, on standardne kaheastmeline väikseimate ruutude meetod (2SLS) piisav. Kui aga:\n\ninstrumente (Z) on palju (nt kõikvõimalikud interaktsioonid ja polünoomid),\nkontrolle (X) on samuti palju,\n\nsiis muutub klassikaline 2SLS ebastabiilseks. Siin tuleb appi LASSO, mis aitab valida olulised komponendid nii instrumentide kui kontrollide hulgast.\n\n\nJääkide meetod IV-kontekstis\nLASSOga IV-metoodika põhineb samal residualiseerimise ideel, kuid nüüd rakendame seda nii (Y), (D) kui ka (Z) suhtes.\nÜldised sammud:\n\nResidualiseeri (Y) kontrollide (X) suhtes:\n\\[ \\hat{m}\\_Y(X_i) = \\hat{\\mathbb{E}}\\]Y_i X_i\\[, \\quad rY_i = Y_i - \\hat{m}\\_Y(X_i).\\]\nResidualiseeri (D) kontrollide (X) suhtes:\n\\[ \\hat{m}\\_D(X_i) = \\hat{\\mathbb{E}}\\]D_i X_i\\[, \\quad rD_i = D_i - \\hat{m}\\_D(X_i).\\]\nResidualiseeri (Z) kontrollide (X) suhtes:\n\\[ \\hat{m}\\_Z(X_i) = \\hat{\\mathbb{E}}\\]Z_i X_i\\[, \\quad rZ_i = Z_i - \\hat{m}\\_Z(X_i).\\]\nKui instrumente on mitu, tehakse see iga komponendi jaoks eraldi.\nRakenda IV regressiooni jääkide vahel:\n\nesimene samm: regressioon (rD) peal (rZ), mis loob prognoosi (r);\nteine samm: regressioon (rY) peal (r).\n\n\nR-s võib käsitsi teostus välja näha selline:\nPaketis hdm on olemas rlassoIV, mis teeb need etapid automaatselt:\nSiin:\n\nkontrolltunnused (X) sisaldavad erinevaid piirkonna tunnuseid, laiuse ruutu jms ja nende teisendeid;\nLASSO valib välja olulised kontrollid, mis mõjutavad nii (Y) kui (D);\ninstrument logMort (asustajate suremus) jääb mudelisse ilma LASSO-karistuseta, sest teda käsitletakse „põhiinstrumendina“;\ntulemuseks on hinnang (), mis kirjeldab omandiõiguse kaitse (Exprop) mõju SKP-le (GDP), võttes arvesse kõrgedimensioonilisi kontrolle.\n\n\n\nMillal kasutada LASSOga IV-lähenemist\nLASSOga IV-lähenemine sobib eriti siis, kui:\n\ninstrumente ja kontrolle on palju, sh paljud võimalikud interaktsioonid ja polünoomid;\neeldame, et tegelik „tõeline“ mudel on hõre (sparse), st vaid väike osa tunnustest omab olulist mõju;\nsoovime teha ranget põhjuslikku järeldust, mitte ainult leida mõnda prognoosimudelit.\n\nOluline on:\n\nkasutada teooriapõhist () valikut (nagu rlasso vaikeseaded),\nkontrollida instrumentide tugevust (esimese sammu F-statistika jmt),\nmitte tugineda ainult CV-põhisele glmnet-LASSOle, kui eesmärk on põhjuslik mõju.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#double-machine-learning-ja-laiendused",
    "href": "10-mllasso.html#double-machine-learning-ja-laiendused",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.7 Double machine learning ja laiendused",
    "text": "16.7 Double machine learning ja laiendused\nJääkide meetod ja topeltvalik on erijuhud üldisemast double machine learning (DML) raamistikust, kus:\n\n(Y)- ja (D)-seosed (X)-dega modelleeritakse masinõppega (LASSO, juhumetsad, boosting, närvivõrgud),\nravi mõju hinnatakse seejärel regressiooniga jääkide vahel,\nandmed jagatakse sageli osadeks, et vähendada üle-sobitamise nihet (cross-fitting).\n\nÜldine idee:\n\nHinda mudelid (m_Y(x) \\[Y \\mid X=x\\]) ja (m_D(x) \\[D \\mid X=x\\]) masinõppe abil.\nArvuta jäägid (_i = Y_i - _Y(X_i)) ja (_i = D_i - _D(X_i)).\nHinda () regressioonis (_i = _i + _i).\n\nCross-fitting’u korral:\n\njagatakse andmed mitmeks osaks,\nühte osa kasutatakse prognoosimismudelite hindamiseks,\nteist osa mõju hindamiseks,\nseejärel keskmistatakse tulemused osade vahel.\n\nSee vähendab nihet, mis tekib, kui sama paindlik mudel kasutatakse korraga nii seose kui mõju hindamiseks.\nLASSO sobitub DML-raamistikku kui üks võimalik „nuisance“-mudelite (st (_Y, _D)) estimatsiooni meetod, mis on kiirem ja paremini mõistetav kui keerukamad musta kasti masinõppemudelid, kuid juba võimaldab kõrgedimensioonilist käsitlust.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#praktilised-soovitused-lasso-kasutamiseks-mõju-hindamisel",
    "href": "10-mllasso.html#praktilised-soovitused-lasso-kasutamiseks-mõju-hindamisel",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.8 Praktilised soovitused LASSO kasutamiseks mõju hindamisel",
    "text": "16.8 Praktilised soovitused LASSO kasutamiseks mõju hindamisel\nKokkuvõtlikud juhised:\n\nKui eesmärk on prognoos:\n\nkasuta ristvalideeritud LASSOt (näiteks glmnet),\nvali () CV alusel,\ninterpreteeri mudeleid pigem „must kast“ lähenemisena.\n\nKui eesmärk on põhjuslik mõju:\n\nära toetu ainult CV-LASSOle,\nkasuta teooriapõhist LASSOt (nt hdm::rlasso),\nkasuta kas:\n\njääkliikmete meetodit (partialling out),\ntopeltvalikut (double selection),\nvõi nende IV-varianti (rlassoIV).\n\n\nJääkide meetod:\n\nefektiivsem, kui prognoosimismudelid (_Y) ja (_D) on täpsed;\nsobib hästi, kui tõesti usud, et LASSO leiab õiged seosed.\n\nTopeltvalik:\n\nrobustsem, kui seosed on nõrgad ja tunnuseid palju;\nkaasab mudelisse kõik (X)-d, mis on olulised kas (Y) või (D) jaoks;\nväldib olulise konfundeeriva tunnuse väljajätmist.\n\nIV-kontextis:\n\nkasuta LASSOt kontrollide ja instrumentide komponentide valikuks,\njäta peamised instrumendid karistamata (select.Z = FALSE),\nkontrolli instrumentide tugevust ja tõlgenda tulemusi teoreetilise raamistikuga kooskõlas.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#kokkuvõte",
    "href": "10-mllasso.html#kokkuvõte",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.9 Kokkuvõte",
    "text": "16.9 Kokkuvõte\nJääkliikmete meetod, topeltvalik ja LASSOga instrumentmuutuja meetod seovad masinõppe ja klassikalise ökonomeetria, et võimaldada usaldusväärset mõju hindamist kõrgedimensioonilistes seadetes. LASSO mängib seejuures kaht rolli:\n\nprognoosijana, mis aitab modelleerida keerulisi seoseid (Y) ja (D) ning instrumentide ja kontrollide vahel;\ntunnuste valijana, mis vähendab mudeli mõõtmeid ja aitab vältida üle-sobitamist.\n\nKorrektse regulaarimisparameetri valiku (teooriapõhine ()) ning sobiva järeldusmetoodika (partialling out, double selection, IV) korral saame LASSO abil hinnata poliitikate ja sekkumiste põhjuslikke mõjusid ka olukorras, kus traditsioonilised ökonomeetrilised meetodid jäävad suurte tunnustehulkade ja multikollineaarsuse tõttu hätta.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#näide",
    "href": "10-mllasso.html#näide",
    "title": "11  LASSO mõju hindamisel",
    "section": "16.10 Näide",
    "text": "16.10 Näide",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#lihtne-näide-lassoga-prognoosimisel",
    "href": "10-mllasso.html#lihtne-näide-lassoga-prognoosimisel",
    "title": "11  LASSO mõju hindamisel",
    "section": "18.1 Lihtne näide LASSOga prognoosimisel",
    "text": "18.1 Lihtne näide LASSOga prognoosimisel\nKasutame sama andmestikku\n\nload(url(\"http://kodu.ut.ee/~avork/files/oppetoo/micro/atp.RData\"))\n\n#vali siit mida tahad\natp$y= atp$employed12\n\n#Nimetame meetmes osalemise ümber d-ks, lühem\natp$d= atp$training\n\natp2 &lt;- atp %&gt;% select(-training, -starts_with(\"wage\"), -starts_with(\"employed\")) #Kõik, mis algavad wage või employed, jätame välja\n#Muudame ka järjestust\n\natp2 &lt;- atp2 %&gt;% select(y, d, everything())\n\nTeeme andmemaatriksid\n\n#define response variable\ny &lt;- atp2$y\n\n#define matrix of predictor variables\n# - 1 no intercept\nxw &lt;- model.matrix(~ d + year + age + gender + collar + immigrant + rural + region + educ + lastemp + benefit -1, data = atp2)\n#head(xw)\n#drop year2006\n#xw &lt;- xw[, colnames(xw) != \"year2006\", drop = FALSE]\n\ndim(xw)\n\n[1] 7140   19\n\n#18 selgitavat muutujat\n\nglmnet() funktsioon sobitab lasso regressioonimudeli, kui määrata alpha = 1.\nTee k-kordne ristvalideerimine, et leida optimaalne lambda väärtus. Olgu k = 5\n\ncv_model &lt;- cv.glmnet(xw, y, alpha = 1, nfolds = 5)\ncv_model\n\n\nCall:  cv.glmnet(x = xw, y = y, nfolds = 5, alpha = 1) \n\nMeasure: Mean-Squared Error \n\n      Lambda Index Measure       SE Nonzero\nmin 0.001963    42  0.2375 0.001170      16\n1se 0.009543    25  0.2387 0.001072      12\n\n#min - näitab minimaalse MSE väärtusega\n\nLeia optimaalne lambda väärtus, mis minimeerib testandmete ruutkeskmise vea (MSE).\n\nbest_lambda &lt;- cv_model$lambda.min\nbest_lambda\n\n[1] 0.001962509\n\n\nTeeme joonise lambda väärtuse ja testandmestiku MSE vahel\n\nplot(cv_model) \n\n\n\n\n\n\n\n\nParim mudel\n\nbest_model &lt;- glmnet(xw, y, alpha = 1, lambda = best_lambda)\n\nJa kordajad\n\nround(coef(best_model),5)\n\n20 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s0\n(Intercept)       0.36505\nd                 0.03945\nyear2006          0.00139\nyear2007          .      \nage3049          -0.00287\nage5064          -0.08791\ngendermale       -0.02049\ncollarwhite       .      \nimmigrant1       -0.07813\nrural            -0.02917\nregionBludhaven   0.00208\nregionCentral    -0.01090\nregionGotham      0.04110\nregionMetropolis  .      \neducSecondary     0.05102\neducTertiary      0.08711\nlastemp1_2        0.03588\nlastemp2_4        0.05447\nlastempover4      0.03616\nbenefit           0.14823\n\n\nÜllatuslikult jäid kõik alles - post-LASSO\nEt ei peaks käsitsi trükkima\n\nselected_vars &lt;- row.names(coef(best_model))[which(coef(best_model) != 0)][-1]\nformula_str &lt;- paste(\"y ~\", paste(selected_vars, collapse = \" + \"))\n\natp3 &lt;- data.frame(y, xw)\n\n\nolsmodel &lt;- lm(as.formula(formula_str), data = atp3)\nsummary(olsmodel)\n\n\nCall:\nlm(formula = as.formula(formula_str), data = atp3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7622 -0.4580 -0.2355  0.4702  0.8026 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.353265   0.022680  15.576  &lt; 2e-16 ***\nd                0.043209   0.013452   3.212 0.001324 ** \nyear2006         0.005216   0.011580   0.450 0.652421    \nage3049         -0.016039   0.014251  -1.125 0.260421    \nage5064         -0.104547   0.018097  -5.777 7.92e-09 ***\ngendermale      -0.021955   0.011878  -1.848 0.064586 .  \nimmigrant1      -0.081956   0.016572  -4.945 7.78e-07 ***\nrural           -0.032598   0.014815  -2.200 0.027813 *  \nregionBludhaven  0.012030   0.023106   0.521 0.602610    \nregionCentral   -0.011218   0.017666  -0.635 0.525447    \nregionGotham     0.044970   0.015882   2.831 0.004647 ** \neducSecondary    0.063766   0.017014   3.748 0.000180 ***\neducTertiary     0.099545   0.017641   5.643 1.74e-08 ***\nlastemp1_2       0.046207   0.018961   2.437 0.014836 *  \nlastemp2_4       0.065331   0.017073   3.827 0.000131 ***\nlastempover4     0.048027   0.015523   3.094 0.001983 ** \nbenefit          0.150644   0.012398  12.151  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4864 on 7123 degrees of freedom\nMultiple R-squared:  0.05563,   Adjusted R-squared:  0.05351 \nF-statistic: 26.23 on 16 and 7123 DF,  p-value: &lt; 2.2e-16\n\n\nLASSO kordajad peaksid olema nihkega nulli suunas",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#näited-kasutades-paketti-hdm",
    "href": "10-mllasso.html#näited-kasutades-paketti-hdm",
    "title": "11  LASSO mõju hindamisel",
    "section": "18.2 Näited kasutades paketti hdm",
    "text": "18.2 Näited kasutades paketti hdm\nrlasso teeb nii Lasso kui post-Lasso. Lubab nii homoskedastiiseid kui heteroskedastiivseid vigu (default homoscedastic = FALSE)\n\nrequire(hdm)\n\n#tavaline lasso\ncv_model &lt;- cv.glmnet(xw, y, alpha = 1, nfolds = 10)\nbest_lambda &lt;- cv_model$lambda.min\nbest_lambda\n\n[1] 0.0004861285\n\nplot(cv_model) \n\n\n\n\n\n\n\nbest_model &lt;- glmnet(xw, y, alpha = 1, lambda = best_lambda)\ncoef(best_model)\n\n20 x 1 sparse Matrix of class \"dgCMatrix\"\n                           s0\n(Intercept)       0.344699097\nd                 0.042128993\nyear2006          0.004459528\nyear2007          .          \nage3049          -0.012936475\nage5064          -0.101884446\ngendermale       -0.021584370\ncollarwhite      -0.005753881\nimmigrant1       -0.078547303\nrural            -0.032935249\nregionBludhaven   0.021113776\nregionCentral     .          \nregionGotham      0.055425473\nregionMetropolis  0.017704494\neducSecondary     0.061692726\neducTertiary      0.099017957\nlastemp1_2        0.044320275\nlastemp2_4        0.063197320\nlastempover4      0.046263605\nbenefit           0.151101177\n\n\nKäsk rlasso\n\nlasso.reg = rlasso(y ~ xw, post = FALSE) # use lasso, not-Post-lasso\nsum.lasso &lt;- summary(lasso.reg, all = FALSE)\n\n\nCall:\nrlasso.formula(formula = y ~ xw, post = FALSE)\n\nPost-Lasso Estimation:  FALSE \n\nTotal number of variables: 19\nNumber of selected variables: 12 \n\nResiduals: \n    Min      1Q  Median      3Q     Max \n-0.6797 -0.4524 -0.3246  0.4742  0.7154 \n\n              Estimate\n(Intercept)      0.408\nd                0.025\nage5064         -0.057\ngendermale      -0.013\ncollarwhite      0.002\nimmigrant1      -0.055\nrural           -0.014\nregionGotham     0.037\neducSecondary    0.001\neducTertiary     0.045\nlastemp2_4       0.018\nlastempover4     0.003\nbenefit          0.145\n\nResidual standard error: 0.4876\nMultiple R-squared:  0.04909\nAdjusted R-squared:  0.04749\nJoint significance test:\n the sup score statistic for joint significance test is 3.753 with a p-value of     0",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#meetme-mõju-hindamine-lassoga",
    "href": "10-mllasso.html#meetme-mõju-hindamine-lassoga",
    "title": "11  LASSO mõju hindamisel",
    "section": "18.3 Meetme mõju hindamine LASSOga",
    "text": "18.3 Meetme mõju hindamine LASSOga\nOLS-ga ette võrdluseks\n\nfmla = as.formula(paste(\"y ~ \", paste(colnames(xw), collapse = \"+\")))\nfmla\n\ny ~ d + year2006 + year2007 + age3049 + age5064 + gendermale + \n    collarwhite + immigrant1 + rural + regionBludhaven + regionCentral + \n    regionGotham + regionMetropolis + educSecondary + educTertiary + \n    lastemp1_2 + lastemp2_4 + lastempover4 + benefit\n\n#OLS\nfull.fit = lm(fmla, data = atp3)\n#Koolituse mõju on4.8 protsendipunkti\nsummary(full.fit)\n\n\nCall:\nlm(formula = fmla, data = atp3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7597 -0.4573 -0.2346  0.4716  0.7989 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       0.334523   0.031092  10.759  &lt; 2e-16 ***\nd                 0.042997   0.013459   3.195 0.001406 ** \nyear2006          0.005558   0.011618   0.478 0.632365    \nyear2007                NA         NA      NA       NA    \nage3049          -0.016288   0.014262  -1.142 0.253475    \nage5064          -0.106782   0.018210  -5.864 4.72e-09 ***\ngendermale       -0.021911   0.011889  -1.843 0.065383 .  \ncollarwhite      -0.008810   0.013776  -0.639 0.522521    \nimmigrant1       -0.077865   0.018121  -4.297 1.75e-05 ***\nrural            -0.034460   0.014907  -2.312 0.020826 *  \nregionBludhaven   0.030854   0.031133   0.991 0.321695    \nregionCentral     0.007689   0.027158   0.283 0.777104    \nregionGotham      0.063473   0.024808   2.559 0.010531 *  \nregionMetropolis  0.027074   0.029516   0.917 0.359037    \neducSecondary     0.065434   0.017116   3.823 0.000133 ***\neducTertiary      0.103454   0.018363   5.634 1.83e-08 ***\nlastemp1_2        0.047213   0.019009   2.484 0.013026 *  \nlastemp2_4        0.066187   0.017134   3.863 0.000113 ***\nlastempover4      0.049855   0.015697   3.176 0.001499 ** \nbenefit           0.152305   0.012566  12.120  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4865 on 7121 degrees of freedom\nMultiple R-squared:  0.0558,    Adjusted R-squared:  0.05341 \nF-statistic: 23.38 on 18 and 7121 DF,  p-value: &lt; 2.2e-16\n\n#Eraldi soovi korral\nsummary(full.fit)$coef[\"d\", 1:2]\n\n  Estimate Std. Error \n0.04299741 0.01345912",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "10-mllasso.html#partialling-out-method---jääkliikmete-meetod",
    "href": "10-mllasso.html#partialling-out-method---jääkliikmete-meetod",
    "title": "11  LASSO mõju hindamisel",
    "section": "18.4 Partialling out method - jääkliikmete meetod",
    "text": "18.4 Partialling out method - jääkliikmete meetod\nTehniline eeltöö. Leiame selgitavate muutujate nimed ilma training muutujata\n\nx &lt;- model.matrix(~ year + age + gender + collar + immigrant + rural + region + educ + lastemp + benefit - 1, data = atp2)\nhead(x)\n\n  year2006 year2007 age3049 age5064 gendermale collarwhite immigrant1 rural\n1        1        0       1       0          0           1          0     0\n2        1        0       1       0          0           1          0     0\n3        1        0       0       0          0           0          0     0\n4        1        0       1       0          0           1          0     0\n5        1        0       1       0          0           1          0     0\n6        1        0       0       1          0           0          1     0\n  regionBludhaven regionCentral regionGotham regionMetropolis educSecondary\n1               0             0            0                0             0\n2               0             0            1                0             1\n3               0             0            0                0             0\n4               0             1            0                0             0\n5               0             0            1                0             0\n6               0             0            1                0             0\n  educTertiary lastemp1_2 lastemp2_4 lastempover4 benefit\n1            1          1          0            0       1\n2            0          0          0            1       1\n3            0          0          0            0       0\n4            1          0          0            0       1\n5            1          0          1            0       1\n6            1          0          0            1       1\n\nxnames &lt;- colnames(x)\n\nTeeme valemid, et ei peaks käsitsi trükkima\n\n#Y võrrand\nfmla.y = as.formula(paste(\"y ~ \", paste(xnames, collapse = \"+\")))\n#D võrrand\n\nfmla.d = as.formula(paste(\"d ~ \", paste(xnames, collapse = \"+\")))\n\n\nJa nüüd esimesed sammud OLSga.\nLeiame jääkliikmed\n\n# partial fit via ols\n\n#väljund\nmudelyjax = lm(fmla.y, data = atp3)\nsummary(mudelyjax)\n\n\nCall:\nlm(formula = fmla.y, data = atp3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7278 -0.4589 -0.2356  0.4748  0.7899 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       0.339102   0.031079  10.911  &lt; 2e-16 ***\nyear2006          0.005563   0.011625   0.478  0.63232    \nyear2007                NA         NA      NA       NA    \nage3049          -0.015162   0.014267  -1.063  0.28794    \nage5064          -0.108447   0.018214  -5.954 2.74e-09 ***\ngendermale       -0.020094   0.011883  -1.691  0.09089 .  \ncollarwhite      -0.008197   0.013783  -0.595  0.55208    \nimmigrant1       -0.077598   0.018132  -4.280 1.90e-05 ***\nrural            -0.033885   0.014916  -2.272  0.02313 *  \nregionBludhaven   0.033445   0.031143   1.074  0.28289    \nregionCentral     0.009097   0.027172   0.335  0.73780    \nregionGotham      0.061740   0.024818   2.488  0.01288 *  \nregionMetropolis  0.029592   0.029524   1.002  0.31623    \neducSecondary     0.068455   0.017101   4.003 6.32e-05 ***\neducTertiary      0.108364   0.018311   5.918 3.41e-09 ***\nlastemp1_2        0.047588   0.019021   2.502  0.01238 *  \nlastemp2_4        0.067030   0.017143   3.910 9.31e-05 ***\nlastempover4      0.050303   0.015706   3.203  0.00137 ** \nbenefit           0.154204   0.012560  12.277  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4868 on 7122 degrees of freedom\nMultiple R-squared:  0.05445,   Adjusted R-squared:  0.05219 \nF-statistic: 24.12 on 17 and 7122 DF,  p-value: &lt; 2.2e-16\n\nrY = mudelyjax$res\n\n#Sama meetmes osalemisega\n#Teeme otse\nrD = lm(fmla.d, data = atp3)$res\n\n#Ja nüüd seos jääkliimete vahel\npartial.fit.ls = lm(rY ~ rD)\nsummary(partial.fit.ls)$coef[\"rD\", 1:2]\n\n  Estimate Std. Error \n0.04299741 0.01344309 \n\n#Täpselt sama, mis oli (!)\nsummary(full.fit)$coef[\"d\", 1:2]\n\n  Estimate Std. Error \n0.04299741 0.01345912 \n\n\n\n\nAga nüüd teeme selle LASSOga\nPost-LASSO\n\n# partial fit via post-lasso\nrY = rlasso(fmla.y, data = atp3)$res\nrD = rlasso(fmla.d, data = atp3)$res\npartial.fit.postlasso = lm(rY ~ rD)\nsummary(partial.fit.postlasso)$coef[\"rD\", 1:2]\n\n  Estimate Std. Error \n0.04568989 0.01344290 \n\n\nMõju hinnang sarnane\n\n\nFunktsioon rlassoEffect teeb selle kõik ise!\n\n#We have Xs, Y, D as parameters\nEff = rlassoEffects(xw, y, index = c(1), method = \"partialling out\")  #indeks 1 ütleb, et meede on esimeses veerus\nsummary(Eff)$coef[, 1:2]\n\n Estimate. Std. Error \n0.04568989 0.01344290 \n\n\n\n\nTopelt selektsiooni meetod (double selection method)\n\nVali Lasso abil kontrollmuutujad x_{ij}, mis ennustavad y_i.\nVali Lasso abil kontrollmuutujad x_{ij}, mis ennustavad d_i.\nTeosta tavaruutude meetod (OLS), kus y_i regresseeritakse d_i ja kontrollmuutujate ühisosa (!) suhtes, mis valiti sammudes 1 ja 2.\n\n\nEff = rlassoEffects(xw, y, index = c(1), method = \"double selection\") \nsummary(Eff)$coef[, 1:2]\n\n Estimate. Std. Error \n0.04569497 0.01356472 \n\n\nSarnased efektid",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>LASSO mõju hindamisel</span>"
    ]
  },
  {
    "objectID": "11-tehajaideed.html",
    "href": "11-tehajaideed.html",
    "title": "12  Teha",
    "section": "",
    "text": "Lisada peatükid:\n\nInterrupted time series\nRDD peatükki alapunktid\n\nRegression Discontinuity in Time - seos interrupted time series meetodiga\nRegression Discontinuity in Space\n\nStruktuursete võrranditega mudelid (SEM), seos DAGiga",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Teha</span>"
    ]
  }
]