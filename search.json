[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Põhjuslike seoste hindamine majanduses",
    "section": "",
    "text": "Eessõna\nKäesolev lühikonspekt on mõeldud tutvustamaks mõju hindamise meetodeid majandustudengitele.\nSiia hakkan panema aines “Põhuse ja tagajärje seosed” kasutatud õppematerjale.\nKonspekt on jooksvalt täienev.",
    "crumbs": [
      "Eessõna"
    ]
  },
  {
    "objectID": "01-sissejuhatus.html",
    "href": "01-sissejuhatus.html",
    "title": "1  Sissejuhatus",
    "section": "",
    "text": "Tuleb kunagi",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sissejuhatus</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html",
    "href": "pohimoistedkordamiseks.html",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "2.1 Potentsiaalse tulemuse mudel (POM)\nTudengid peaksid teadma järgmisi põhimõisteid.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "href": "pohimoistedkordamiseks.html#potentsiaalse-tulemuse-mudel-pom",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "",
    "text": "Mõiste\nSelgitus\n\n\nPõhjuslik mõju (Causal Effect)\nMõju on defineeritud kui kahe oleku (sekkumine \\(D=1\\) ja võrdlusseisund \\(D=0\\)) tulemuse võrdlus. See on see, mida püütakse hinnata.\n\n\nPotentsiaalne tulemus (\\(Y_{i1}, Y_{i0}\\))\nTulemus, mis võiks realiseeruda isikule \\(i\\). \\(Y_{i1}\\) on tulemus (nt palk), kui isik osales meetmes (\\(D=1\\), osalusseisund); \\(Y_{i0}\\) on tulemus, kui isik ei osalenud meetmes (\\(D=0\\), võrdlusseisund). Me saame vaadelda vaid ühte neist.\n\n\nKeskmine mõju (ATE) (Average Treatment Effect)\nPoliitikameetme keskmine mõju kogu üldkogumile. See näitab, milline oleks programmi keskmine mõju, kui see tehtaks kohustuslikuks, või mis oleks oodatav mõju, kui võtaksime juhuslikult ühe inimese üldkogumist.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult osalesid. Tavaliselt erineb ATE-st, kuna mõju (\\(\\delta_i\\)) on inimeste jaoks erinev.\n\n\nKeskmine mõju osalejatele (ATT) (Average Treatment Effect for the Treated)\nProgrammi keskmine mõju nendele, kes tegelikult ei osalenud.\n(See on hüpoteetiline mõju. Me leiame selle nende põhjal, kes tegelikult osalesid)\n\n\nOsalusrühm / Osalusgrupp (Treatment Group)\nObjektid (isikud, ettevõtted, piirkonnad), mis saavad meetme või mida mõjutab poliitikamuutus.\n\n\nVõrdlusrühm/\nKontrollgrupp (Control Group)\nÜhikud (isikud, ettevõtted, piirkonnad), mis ei saa meedet või mida ei mõjuta poliitikamuutus. Selle rühma püüame enamasti teha võimalikult sarnaseks osalusrühmaga.\n\n\nLihtne keskmiste erinevus (SDO) (Simple Difference of Outcomes)\nVaadeldud osalusgrupi ja võrdlusgrupi keskmiste tulemuste lihtne erinevus. See annab üldjuhul nihkega tulemuse: \\(\\text{SDO} = \\text{ATE} + \\text{Valikunihe} + \\text{Nihe heterogeense mõju tõttu}\\)\n\n\nValikunihe (Selection Bias)\nViga hinnangus, mis tekib, kuna osalenud (\\(D=1\\)) ja mitteosalenud (\\(D=0\\)) inimesed või ettevõtted erinevad üksteisest (nt võimekuse või motivatsiooni poolest). Valikunihke elimineerimine või selle vähendamine on mõju hindamisel üks peamine ülesanne.\n\n\nSUTVA eeldus (Stable Unit Treatment Value Assumption)\nEeldus, mis koosneb järgmistest tingimusest: meetmes osalemine on selgelt defineeritud (osaled või ei osale), üksikisiku osalemine ja tulemus sõltuvad ainult tema enda osalemise otsusest, mitte teiste omast (puuduvad välismõjud, general equilibrium effects).\nSeega on vaatlused sõltumatud ja meetmed peaks olema väikesed.\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nTuntud ka kui Unconfoundedness või Selection on Observables. Eeldus, et potentsiaalne tulemus (\\(Y\\)) ja meetmes osalemine (\\(D\\)) on sõltumatud pärast seda, kui oleme arvesse võtnud kõik olulised jälgitavad tunnused (X).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "href": "pohimoistedkordamiseks.html#graafiline-mõju-modelleerimine-dag",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.2 Graafiline mõju modelleerimine (DAG)",
    "text": "2.2 Graafiline mõju modelleerimine (DAG)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSuunatud atsükliline graaf (DAG) (Directed Acyclic Graph)\nGraafiline vahend, mis kirjeldab muutujate vahelisi põhjuslikke seoseid. Noolteta jooned tähendavad, et seost ei ole. Põhjuslikkus on ühesuunaline ja ei sisalda tsükleid.\n\n\nSegaja (Confounder)\nMuutuja (nt \\(X\\)), mis on seotud nii meetmega (\\(D\\)) kui ka tulemusega (\\(Y\\)). (\\(D \\leftarrow X \\rightarrow Y\\)) Segaja kaudu kulgeb tagauks (backdoor path), mis tuleb sulgeda, et hinnang \\(D\\) mõju kohta \\(Y\\)-le oleks nihketa.\n\n\nTagauks (Backdoor Path)\nPõhjuslik tee meetme (\\(D\\)) ja tulemuse (\\(Y\\)) vahel, mis kulgeb läbi segaja(te). See teeb tuleb sulgeda, kas regressioonimudeli, sobitamise, eksperimendi või muu viisi abil. .\n\n\nOmitted Variable Bias (Nihe välja jäetud muutuja tõttu)\nNihkega hinnang, mis tekib, kui oluline segaja (\\(X\\)) jäetakse analüüsist välja.\n\n\nKollaider / Põrguti (Collider)\nMuutuja (nt \\(X\\)), mis on põhjustatud meetme (\\(D\\)) ja tulemuse (\\(Y\\)) poolt (\\(D \\rightarrow X \\leftarrow Y\\)). Kui kollaider pannakse mudelisse, luuakse uus (nihkega) seos (avatakse tagauks), mistõttu neid ei tohi mudelitesse lisada.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "href": "pohimoistedkordamiseks.html#mõju-hindamise-meetodid",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.3 Mõju hindamise meetodid",
    "text": "2.3 Mõju hindamise meetodid\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nHomogeenne efekt (Homogeneous Effect)\nRegressioonimudeli eeldus (kui ristkorrutised puuduvad), et põhjuslik mõju (\\(\\delta\\)) on kõigi jaoks ühesugune. Sellisel juhul \\(\\text{ATE} = \\text{ATT} = \\text{ATU}\\).\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus, et põhjuslik mõju erineb isikuti või alamrühmade kaupa. Seda saab modelleerida, lisades regressioonivõrrandisse ristkorrutised (nt \\(D_i \\cdot X_i\\))\n\n\nInstrument-muutuja (Instrumental Variable, Z)\nRegressioonianalüüsis kasutatav muutuja, mis on seotud meetmega (\\(D\\)), aga seos tulemusega (\\(Y\\)) tekib ainult \\(D\\) kaudu34. Aitab vähendada mittejälgitavate segajate (u) mõju.\n\n\nSobitamine (Matching)\nMeetod valikunihke vähendamiseks, kus osalenud isikutele leitakse sarnased mitteosalenud isikud (nt haridustaseme, vanuse vms \\(X\\) väärtuste alusel).\n\n\nPaneelandmete kasutamine\nMeetod, mis aitab elimineerida ajas muutumatute mittejälgitavate segajate (\\(u\\)) mõju (nt kaasasündinud võimekust).\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus loodus või institutsionaalne muutus (nt seaduse muutus) eraldab juhuslikult kaks rühma, andes uurijale peaaegu samaväärse tingimuse kui juhuslik eksperiment, vähendades mittejälgitava segaja (\\(u\\)) mõju\n\n\nÜhine tugi (Common Support)\nTingimus, mis peab olema täidetud CIA eelduse ja sobitamismeetodite korral. See tähendab, et antud \\(X\\) väärtuste juures peavad olema esindatud nii osalejad (\\(D=1\\)) kui ka mitteosalejad (\\(D=0\\)).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "href": "pohimoistedkordamiseks.html#juurdekasvude-erinevus-did",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.4 Juurdekasvude erinevus (DiD)",
    "text": "2.4 Juurdekasvude erinevus (DiD)\nDifference-in-differences method\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nJuurdekasvude erinevus (DiD)\nMeetod paneelandmete (või korduvate ristandmete) abil põhjusliku mõju hindamiseks. Eeldab, et meil on osalusgrupp (saab meetme) ja võrdlusgrupp (ei saa) ning andmed nii enne kui ka pärast meetme rakendamist.\n\n\nParalleelsete trendide eeldus (Parallel Trends Assumption)\nKõige olulisem eeldus DiD-meetodis. See nõuab, et kui osalusgrupp ei oleks meedet saanud, oleks nende tulemuse trend ajas olnud sama kui võrdlusgrupil.\n\n\nLoomulik eksperiment (Natural Experiment)\nOlukord, kus DiD-meetodit sageli kasutatakse. Tekib, kui väline (eksogeenne) muutus, näiteks uus seadus, mõjutab ühte rühma, aga mitte teist.\n\n\nKolmekordne erinevus (Triple Difference)\nDiD-meetodi edasiarendus. Võrdleb DiD hinnangut (nt mõjutatud rühma ja kontrollrühma vahel) teise DiD hinnanguga (nt sarnase, kuid vähem mõjutatud rühma vahel). Kasutatakse potentsiaalsete väliste segajate eemaldamiseks.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "href": "pohimoistedkordamiseks.html#regressiooni-katkemise-disain",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.5 Regressiooni katkemise disain",
    "text": "2.5 Regressiooni katkemise disain\n(Regression Discontinuity Design, RDD)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegressiooni katkemise disain (RDD)\nMõju hindamise meetod, mida kasutatakse, kui meetmes osalemine on määratud täpse lävendi (cut-off) alusel pideva muutuja (running variable) väärtusel. Näiteks vanus (lävend: 65 eluaastat pensionile jäämiseks).\n\n\nLõikepunkt / Lävend (Cut-off / Threshold)\nTäpne väärtus määravas muutujas (X), mis määrab, kas isik saab meetme (D=1) või mitte (D=0).\n\n\nMäärav muutuja (Running Variable / Assignment Variable)\nPidev muutuja (nt vanus, sissetulek, eksami tulemus), mille lävend määrab meetmes osalemise.\n\n\nLokaalne keskmine mõju (Local Average Treatment Effect, LATE)\nRDD-ga saadud hinnang näitab meetme põhjuslikku mõju ainult lävendi piiril olevatele isikutele, mitte kogu elanikkonnale.\n\n\nTäpne RDD (Sharp RDD)\nRDD vorm, kus lävendi ületamine määrab täielikult meetmes osalemise (st \\(P(D=1 \\vert X) = 1\\) lävendist paremal, ja \\(P(D=1 \\vert X) = 0\\) lävendist vasakul).\n\n\nHägune RDD (Fuzzy RDD)\nRDD vorm, kus lävendi ületamine muudab järsult tõenäosust meetmes osaleda, kuid ei määra seda täielikult (st \\(0 &lt; P(D=1 \\vert X) &lt; 1\\)).\n(Sarnane instrument-muutuja meetodile).\n\n\nPidevuse eeldus (Continuity Assumption)\nOluline eeldus RDD puhul. Nõuab, et potentsiaalsed tulemused (\\(Y_0, Y_1\\)) oleks pidevad lävendi juures. Tähendab, et lävendi lähedal ei tohi olla muid järske muutusi (nt manipuleerimist) peale meetme (\\(D\\)) osalemise muutuse.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sobitamine",
    "href": "pohimoistedkordamiseks.html#sobitamine",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.6 Sobitamine",
    "text": "2.6 Sobitamine\n(Matching)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSobitamine (Matching)\nMõju hindamise meetod, mille eesmärk on leida igale osalusrühmas olevale isikule (kes sai meetme) võimalikult sarnane isik võrdlusrühmast (kes meedet ei saanud).\n\n\nTingimuslik sõltumatuse eeldus (CIA) (Conditional Independence Assumption)\nSobitamise põhi-eeldus: \\(Y_0\\) ja \\(Y_1\\) on sõltumatud \\(D\\)-st tingimusel, et on arvesse võetud kõik jälgitavad segajad \\(X\\). See tähendab, et sobitamine tegeleb vaid valikunihkega, mis tuleb jälgitavatest tunnustest.\n\n\nÜhine tugi (Common Support)\nEeldus, mis peab kehtima: Iga osalusrühmas oleva isiku jälgitavate tunnuste \\(X\\) väärtuste (või tõenäosusskoori) läheduses peab olema piisavalt vaatlusi ka võrdlusrühmas.\n\n\nTõenäosuse skoor (PS) (Propensity Score, \\(P(X)\\))\nTõenäosus, et isik kuulub osalusrühma, arvestades tema jälgitavaid tunnuseid \\(X\\). See on tavaliselt logit- või probit regressioonimudeli abil hinnatud väärtus: \\(P(D_i = 1 \\mid X_i)\\).\n\n\nSobitamine tõenäosuse skoori alusel (PSM) (Propensity Score Matching)\nSagedasti kasutatud sobitamismeetod, mis kasutab mitme muutuja \\(X\\) asemel ühte mõõdikut: tõenäosuse skoori meetmes osaleda. Osalusrühma isikutele sobitatakse võrdlusrühma isikud, kelle \\(P(X)\\) väärtused on väga lähedal.\n\n\nLähima naabri sobitamine (Nearest Neighbor Matching)\nMeetod, kus igale osalusrühma vaatlusele leitakse kõige lähima kaugusega (nt \\(P(X)\\) alusel või Mahalanobise kauguse alusel) vaste võrdlusrühmast. Kasutada saab tagasipanekuga (või ilma).\n\n\nKaliiber (Caliper)\nMääratud maksimaalne lubatud kaugus (\\(P(X)\\) erinevus) paari sobitamisel. Aitab tagada kvaliteetsemad vasted, isegi kui see vähendab sobitatud isikute arvu.\n\n\nTasakaalu test (Balance Test)\nOluline samm sobitamise järel. Kontrollitakse, kas jälgitavate tunnuste \\(X\\) keskmised väärtused on sobitatud osalus- ja võrdlusrühmas piisavalt sarnased (statistiliselt oluliselt ei erine).\n\n\nOtste lõikamine (Trimming)\nSobitamise-eelne või -järgne tegevus, millega eemaldatakse analüüsist vaatlused, millel puudub ühine tugi (nt liiga väike või liiga suur \\(P(X)\\) väärtus).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "href": "pohimoistedkordamiseks.html#instrumentmuutuja-meetod-iv",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.7 Instrumentmuutuja meetod (IV)",
    "text": "2.7 Instrumentmuutuja meetod (IV)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nInstrumentmuutuja (Z) (Instrumental Variable, IV)\nMuutuja, mida kasutatakse regressioonimudelis, et saada nihketa hinnang meetme (\\(D\\)) mõjule tulemusele (\\(Y\\)). Peab vastama kahele tingimusele (vt allpool).\n\n\nEndogeensus / Nihe (Endogeneity / Bias)\nProbleem, kus meetme muutuja (\\(D\\)) on korreleeritud regressioonimudeli vealiikmega (\\(u\\)). See tekib valikunihke või kahesuunalise põhjuslikkuse tõttu ning viib OLS-i puhul nihkega hinnanguni.\n\n\nIV Tingimus 1: Relevantsus (Relevance)\nEsimene ja testitav eeldus: instrumentmuutuja (\\(Z\\)) peab olema tugevalt korreleeritud meetme muutujaga (\\(D\\)). St, \\(Z\\) peab mõjutama \\(D\\)-d.\n\n\nIV Tingimus 2: Väline kehtivus / Eksogeensus (Exclusion Restriction / Exogeneity)\nTeine ja mittetestitav eeldus: Instrumentmuutuja (\\(Z\\)) tohib mõjutada tulemust (\\(Y\\)) ainult meetme muutuja (\\(D\\)) kaudu. St, \\(Z\\) ei tohi olla korreleeritud vealiikmega (\\(u\\)).\n\n\nKaheetapiline vähimruutude meetod (2SLS) (Two-Stage Least Squares)\nIV-meetodi rakendamise viis. 1. etapp: regresseeritakse \\(D\\) \\(Z\\)-i ja \\(X\\)-ide suhtes. 2. etapp: regresseeritakse \\(Y\\) \\(D\\) ennustatud väärtuse ja \\(X\\)-ide suhtes.\n\n\nLokaalne keskmine mõju (LATE) (Local Average Treatment Effect)\nIV-meetodi puhul saadud põhjuslik mõju hinnang. See mõju kehtib vaid allujatele (compliers) – neile, kelle osalemisotsus (\\(D\\)) oli mõjutatud instrumentmuutujast (\\(Z\\)).\nKui eeldame, et mõju on kõigi jaoks ühesugune (homogeenne), siis rühmade eristus ei ole vajalik.\n\n\nNõrk instrument (Weak Instrument)\nOlukord, kus instrumentmuutuja (\\(Z\\)) ei ole piisavalt tugevalt seotud meetme muutujaga (\\(D\\)). Viib nihkega (OLS-i poole kaldu) ja ebatäpsete IV-hinnanguteni.\n\n\nHausman-Wu test (Hausman-Wu Test)\nTest, millega kontrollitakse endogeensuse olemasolu meetme muutuja (\\(D\\)) ja vealiikme (\\(u\\)) vahel. Kui test on oluline, näitab see, et \\(D\\) on endogeenne ja IV-meetodi kasutamine on vajalik.\n\n\nSargani test (Sargan Test)\nTest, millega kontrollitakse eksogeensuse eelduse paikapidavust (Exclusion Restriction), kui meil on rohkem instrumente kui endogeenseid muutujaid (üleidentifitseeritud juht).\n\n\nWaldi hinnang binaarse meetme ja binaarse instrumendi korral",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "href": "pohimoistedkordamiseks.html#sünteetilise-võrdlusobjekti-meetod",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.8 Sünteetilise võrdlusobjekti meetod",
    "text": "2.8 Sünteetilise võrdlusobjekti meetod\n(Synthetic Control Method)\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nSünteetiline Võrdlusobjekt (SCM) (Synthetic Control Method), sünteetilise kontrollgrupi meetod\nMeetod, mida kasutatakse ühe meetmes osaleja puhul (nt ühe riigi) mõju hindamiseks, luues teistest, mitteosalevatest objektidest (doonorrühmast) kaalutud kombinatsioon.\n\n\nSihtobjekt (Treated Unit)\nAinus uuritav ühik (nt linn, riik), mis on saanud sekkumise (meetme). SCM eesmärk on leida sellele veenev võrdlusobjekt.\n\n\nDoonorrühm, võrdlusobjektid (Donor Pool / Control Units)\nMeetmest mitte mõjutatud ühikute kogum, mille kaalutud keskmisest tehakse sünteetiline võrdlusobjekt. Nende kaalude summa peab olema 1 ja kaalud ei tohi olla negatiivsed.\n\n\nKaalud (\\(\\mathbf{W}\\)) (Weights)\nPositiivsed väärtused, mis määratakse võrdlusrobjektidele. Need kaalud minimeerivad sihtobjekti ja sünteetilise võrdlusobjekti erinevust meetmele eelneval perioodil.\n\n\nSobitamisperiood / Eelperiood (Pre-intervention Period)\nAjavahemik enne meedet, mida kasutatakse kaalude \\(\\mathbf{W}\\) leidmiseks. Kaalud valitakse nii, et sihtobjekti ja sünteetilise võrdlusobjekti tulemused \\(\\mathbf{Y_t}\\) ja ka selgitavad tunnused \\(\\mathbf{X_{mt}}\\) oleksid selles perioodis võimalikult lähedased.\n\n\nMõju hinnang (Treatment Effect Estimate)\nSCM-iga saadud põhjuslik mõju, mis leitakse sihtobjekti ja sünteetilise võrdlusobjekti tulemuste vahe alusel pärast meetme rakendamist.\n\n\nPlatseebotest / Permutatsioonitest (Placebo Test / Permutation Test)\nEelduste ja järelduste statistiline testimismeetod SCM-is. Leitakse sama arvutuse tulemus ka teistele võrdlusrühma liikmetele ja hinnatakse, kas meid huvitava objekti tulemus on ebatavaliselt suur võrreldes teistega. Kui meie tulemus on eriline, siis see viitab, et tegemist on tegeliku mõjuga.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "href": "pohimoistedkordamiseks.html#masinõppemeetodid---puud-ja-mets",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.9 Masinõppemeetodid - puud ja mets",
    "text": "2.9 Masinõppemeetodid - puud ja mets\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nOtsustuspuu (Decision Tree), Regressioonipuu (Regression Tree)\nMasinõppe algoritm, mis jaotab andmestiku samm-sammuliselt alamhulkadeks, et leida prognoosimise reeglid tulemuse (\\(Y\\)) või meetmes osalemise (\\(D\\)) kohta. Moodustab aluse juhumetsale.\nOtsustuspuu - väljund on diskreetne (nt kas töötab või osaleb meetmes)\nRegressioonipuu - väljund on pidev (nt palk)\n\n\nJuhumets (Random Forest)\nAnsambelmeetod, mis kombineerib mitu puud. Iga puu on ehitatud juhusliku valimiga (bootstrapping) ja kasutades juhuslikku alamhulka tunnustest igas harus. Kasutatakse peamiselt täpseks prognoosimiseks (\\(E[Y\\vert X]\\) või \\(P[D\\vert X]\\)).\n\n\nPõhjuslik mets / Kausaalmets\n(Causal Forest)\nJuhumetsa edasiarendus, mis on loodud spetsiaalselt heterogeense põhjusliku mõju (CATE) hindamiseks. Eraldab andmed kaheks: üks osa puude ehitamiseks ja teine osa mõju hindamiseks, et vältida üle-sobitamist (overfitting).\nKui tavaline puu maksimeerib prognooside erinevust igas lehes, siis kausaalpuu maksimeerib mõju erinevust igas lehes.\n\n\nHeterogeenne mõju (Heterogeneous Effect)\nEeldus või tulemus, et põhjuslik mõju (\\(\\delta\\)) on erinevatel inimestel (alamrühmadel) erinev (st sõltub \\(X\\) väärtustest). Masinõppemeetodid on selle tuvastamisel eriti võimsad.\n\n\nKõrge-dimensiooniline andmestik (High-Dimensional Data)\nAndmestik, kus on väga palju jälgitavaid tunnuseid (\\(X\\)), mida peab arvesse võtma valikunihke korrigeerimiseks. Masinõpe aitab neist olulised leida.\n\n\nDouble Machine Learning (DML)\nÜks juhtivaid lähenemisi põhjusliku mõju hindamiseks masinõppe abil. Kasutab kaheetapilist meetodit (nagu 2SLS või AIPW), kus mõlemad etapid viiakse läbi (regressiooni vealiikmed leitakse) paindlike masinõppe meetodite (nt juhumets) abil.\n\n\nIPW (Inverse Probability Weighting)\nMeetod, kus mõju arvutamisel vaatlusi kaalutakse pöördvõrdeliselt nende tõenäosuse skooriga (\\(P(D=1 \\mid X)\\)). See annab osalejatele, kelle \\(P(X)\\) on väike, suurema kaalu, ja mitte-osalejatele, kelle \\(P(X)\\) on suur, suurema kaalu.\n\n\nAIPW (augmented inverse probability weighting)\nMeetod kus mõjuhinnangut korrigeeritakse tõenäosuskooridega korrigeeritud",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "href": "pohimoistedkordamiseks.html#lasso-mõju-hindamisel",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.10 LASSO mõju hindamisel",
    "text": "2.10 LASSO mõju hindamisel\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nRegulariseerimine (Regularized Regression)\nÜldnimetus meetoditele (nagu LASSO ja Ridge), mis lisavad regressioonimudeli eesmärgile (RSS minimeerimine) karistusliikme koefitsientide suuruse eest. See aitab vähendada üle-sobitamist (overfitting) ja teeb mudelid lihtsamaks.\n\n\nLASSO (Least Absolute Shrinkage and Selection Operator)\nRegulariseeriv regressioonimeetod, mis karistab suurte koefitsientide eest, lisades jääkliikmete ruutude summale (RSS) koefitsientide absoluutväärtuste summa (L1-norm). See sunnib paljusid väheolulisi tunnuseid \\(X\\) olema täpselt null – teeb automaatse tunnuste valiku.\n\n\nTunnuste valik (Feature Selection)\nLASSO peamine kasulik omadus ökonomeetrias. See suudab automaatselt tuhandete võimalike tunnuste (\\(X\\)) hulgast leida need, mis on põhjusliku mõju nihketa hindamiseks kõige olulisemad.\n\n\nRegulatsiooniparameeter (\\(\\lambda\\)) (Regularization Parameter, \\(\\lambda\\))\nParameeter LASSO ja Ridge mudelites, mis määrab karistuse tugevuse. Mida suurem \\(\\lambda\\), seda rohkem koefitsiente sunnitakse nulliks (LASSO puhul) ja seda suurem on koefitsientide kokkutõmbumine (mõlema puhul). \\(\\lambda\\) valitakse tavaliselt ristvalideerimise abil.\n\n\nRistvalideerimine (Cross-Validation)\nStatistiline tehnika \\(\\lambda\\) (regulatsiooniparameetri) optimaalse väärtuse leidmiseks. Andmestik jagatakse alamhulkadeks. \\(\\lambda\\) valitakse nii, et see minimeeriks prognoosivea (nt mean squared error) valimi-välisel andmestiku osal. See sobib hästi, kui eesmärk on prognoosimine\n\n\nTeoreetiline \\(\\lambda\\) valik (`rlasso` meetod)\nPakett `rlasso` (Belloni jt.) kasutab teoorial põhinevat, andmepõhist regulatsiooniparameetri \\(\\lambda\\) valikut\n\n\nPost-LASSO\nMeetod, kus kõigepealt kasutatakse LASSO-t, et valida välja olulised tunnused (koefitsiendiga \\(\\neq 0\\)). Seejärel hintakse seos tavalise OLSiga (vähimruutude) regressiooni, kasutades ainult valitud tunnuseid.\n\n\nDouble Selection LASSO (DS-LASSO)\nMeetod, mille eesmärk on leida kõik olulised segajad (\\(X\\)), mis võivad mõjutada nihet (\\(D \\leftrightarrow Y\\) seose puhul). Viib läbi kaks LASSO-valikut: 1) \\(Y\\) seos \\(X\\)-idega 2) \\(D\\) seos \\(X\\)-idega. Mudelisse jäetakse kõik tunnused, mis valiti kas 1. või 2. etapis. Saadud mudel hinnatakse post-LASSO meetodiga.\n\n\nResidualisation (Jääkliikmete meetod)\nAlternatiivne lähenemine, mida kasutatakse LASSO-ga. See toimub kahes etapis: 1) \\(Y \\sim X\\) abil ja leitakse jääkliikmed \\(r_Y\\). 2) Modelleeritakse \\(D \\sim X\\) abil ja leitakse jääkliikmed \\(r_D\\). Lõpuks hinnatakse mõju regressiooniga: \\(r_Y \\sim r_D\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "pohimoistedkordamiseks.html#muud",
    "href": "pohimoistedkordamiseks.html#muud",
    "title": "2  Põhimõisted eksamiks kordamiseks",
    "section": "2.11 Muud",
    "text": "2.11 Muud\n\n\n\n\n\n\n\nMõiste\nSelgitus\n\n\nROC-kõver, AUC (Area under curve)\nReceiver operating characteristic (ROC) kõver kujutab sensitiivsuse (õigesti prognoositud sündmuste osakaal) and 1- spetsiifilisus (valepositiivsete osakaalu sündmust mitte omanud juhtudest) erinevates lõikepunktides. Selle joonie alune pindala on AUC – area under curve\n\n\nSensitiivsus\nPrognoositud toimumiste osakaal kokku tegelikest toimumistest\n\n\nSpetsiifilisus\nPrognoositud mitte-toimumiste osakaal kokku tegelikest mitte-toimumistest",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Põhimõisted eksamiks kordamiseks</span>"
    ]
  },
  {
    "objectID": "02-pohimoisted.html",
    "href": "02-pohimoisted.html",
    "title": "3  Potentsiaalse tulemuse mudel",
    "section": "",
    "text": "Poolik - arenev",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Potentsiaalse tulemuse mudel</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html",
    "href": "03-regressioon.html",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "4.1 Mudeli seade\nPoolik - arenev\nVaatame mõju (nt meetmes osalemise \\(D\\) mõju tulemile \\(Y\\)) hindamise meetodeid, kasutades regressioonimudeleid ja eeldust tingimuslikust sõltumatusest (Conditional Independence Assumption, CIA).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#mudeli-seade",
    "href": "03-regressioon.html#mudeli-seade",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "",
    "text": "Tingimusliku sõltumatuse eeldus (CIA)\nPõhjusliku mõju leidmiseks regressiooniga peab kehtima tingimusliku sõltumatuse eeldus (CIA - conditional independence assumption).\n\\[E[Y_0 | D=1, \\mathbf{X}] = E[Y_0 | D=0, \\mathbf{X}]\\]\nSee tähendab, et pärast kõigi oluliste segavate tegurite \\(\\mathbf{X}\\) (eelkõige \\(X \\rightarrow D\\) ja \\(X \\rightarrow Y\\)) arvesse võtmist ei ole potentsiaalsel tulemusel \\(Y_0\\) ja meetmes osalemisel \\(D\\) enam seost. Seega, tingimuslikult sarnased osalejad ja mitte-osalejad on võrreldavad.\n\n\nRegressioonimudelid mõju hindamiseks\nKui CIA kehtib ja eeldame aditiivset (lineaarset) mudelit, saame regressiooniga hinnata erinevaid keskmisi mõjusid.\n\nTavaline regressioonimudel (ATE hinnang)\nKõige lihtsam mudel eeldab, et mõju \\(\\delta\\) on homogeenne (sama kõigi \\(\\mathbf{X}\\) väärtuste korral) ja aditiivne.\n\\[Y_i = \\alpha + \\delta D_i + \\mathbf{X}_i \\beta + \\epsilon_i\\]\nVõi üldjuhul, kui on selgitavaid tegureid rohkem:\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\dots + \\epsilon_i\\)\nMõju hinnang: \\(\\hat{\\delta}\\) on hinnang ATE-le (Average Treatment Effect), st keskmisele mõjule kõigile.\n\n\n\nRegressioonimudel interaktsiooniga (heterogeenne mõju)\nKui on alust arvata, et meetme mõju \\(D\\) sõltub mõnest tunnusest \\(X_k\\) (st mõju on heterogeenne), lisatakse mudelisse interaktsiooniliige.\n\\[Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\mathbf{X}_i \\beta + \\epsilon_i\\]\n\nValem: \\(Y_i = \\alpha + \\delta D_i + \\gamma (D_i \\cdot X_{ki}) + \\beta_1 X_{1i} + \\dots + \\epsilon_i\\)\nMõju \\(X_{ki}\\) väärtusel: \\(\\text{Mõju} = \\hat{\\delta} + \\hat{\\gamma} X_{ki}\\).\nKasutamine: Seda mudelit kasutades saab hinnata CATE-t (Conditional Average Treatment Effect), st keskmist mõju alamrühmas, ja leida seejärel kaalutud keskmist leides ATE või ATT.\n\n\n\n\nKaks eraldi eegressioonimudelit (G-Computation)\nSee meetod hinnatakse regressioonimudeleid eraldi osalejate (\\(D=1\\)) ja mitte-osalejate (\\(D=0\\)) andmetel, mis võimaldab arvestada heterogeenset funktsionaalset seost \\(Y_0\\) ja \\(Y_1\\) vahel.\n\nMudel osalejatel (\\(D=1\\)): \\[Y_i = \\alpha_1 + \\mathbf{X}_i \\beta_1 + \\epsilon_{i1} \\quad \\text{kui } D_i=1\\] Prognoosime tulemuse \\(Y_{i1}\\) kõigile vaatlustele: \\(\\hat{Y}_{i1} = \\hat{\\alpha}_1 + \\mathbf{X}_i \\hat{\\beta}_1\\).\nMudel mitte-osalejatel (\\(D=0\\)):\n\n\\[Y_i = \\alpha_0 + \\mathbf{X}_i \\beta_0 + \\epsilon_{i0} \\quad \\text{kui } D_i=0\\]\nPrognoosime tulemuse \\(Y_{i0}\\) kõigile vaatlustele: \\(\\hat{Y}_{i0} = \\hat{\\alpha}_0 + \\mathbf{X}_i \\hat{\\beta}_0\\).\n\nMõju arvutamine (G-Computation): Mõju on igal isikul prognooside vahe: \\(\\hat{\\Delta}_i = \\hat{Y}_{i1} - \\hat{Y}_{i0}\\).\n\nATE (kogu populatsioon): \\(\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^N \\hat{\\Delta}_i\\)\nATT (meetmes osalejatele): \\(\\text{ATT} = \\frac{1}{N_T} \\sum_{i: D_i=1} \\hat{\\Delta}_i\\)\nATU (võrdlusrühmale): \\(\\text{ATU} = \\frac{1}{N_C} \\sum_{i: D_i=0} \\hat{\\Delta}_i\\)\n\n\nSee meetod on regressiooni mudeliga hindamise erijuht ja annab paindlikumad hinnangud, kuna võimaldab funktsionaalsel seosel \\(Y \\sim \\mathbf{X}\\) olla erinev osalejatel ja mitte-osalejatel.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "03-regressioon.html#näide-tööpoliitikast",
    "href": "03-regressioon.html#näide-tööpoliitikast",
    "title": "4  Regressioonimudeli kasutamine",
    "section": "4.2 Näide tööpoliitikast",
    "text": "4.2 Näide tööpoliitikast\nMe kasutame näidisandmetena Poliitikauuringute Keskuse Praxis 2002. aastal läbiviidud uuringut aktiivse tööpoliitika mõju hindamise kohta. (Vt Leetmaa, R., Võrk, A., Eamets, R., Sõstra, K. (2003) Aktiivse tööpoliitika tulemuslikkuse analüüs Eestis. Tallinn: Praxis, 108 lk. Vt ka: Praxis töö ja Leetmaa & Võrk (2004))\nAnonümiseeritud andmestik asub failis:\nhttp://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\n\nMuutujate selgitused\n\n\n\n\n\n\n\nMuutuja\nSelgitus\n\n\n\n\ntraining\nReceived labour market training in 2000 / Tunnus kas sai tööturukoolitust või ei 2000. aasta esimeses pooles\n\n\nnwage\nNetopalk 2002. aasta septembris\n\n\nemployed\nEmployed in September 2002 / Hõivatus 2002. aasta septembris (1 – hõivatud, 0 – töötu või mitteaktiivne)\n\n\nstatus\nTööturustaatus 2002. aasta septembris (1 – hõivatud, 2 – töötu, 3 – mitteaktiivne)\n\n\nkaal\nSample weight / Vaatluse statistiline kaal\n\n\nmale\nmale / Meessoost\n\n\nest\nEstonian / Eestlane\n\n\nage\nVanus aastates 2002. aastal\n\n\nlangest\nKas oskab eesti keelt\n\n\nemplbefore\nKas oli töökogemus enne töötuks registreerimist 2000. aastal\n\n\neduc\nHaridustase: 1 – ISCED 0,1,2 (põhiharidus); 2 – ISCED 3 (keskharidus); 3 – ISCED 3,4 (kutsekeskharidus); 4 – ISCED 5,6 (kõrgharidus)\n\n\ncounty\nMaakond: Tallinn, Viljandimaa, Tartumaa, Ida-Virumaa\n\n\ntown\nElab linnas vs maal\n\n\nchildren\nLaste arv töötuks registreerimise hetkel\n\n\nmarital\nPerekonna seis töötuks registreerimise hetkel: 0 – vallaline; 1 – abielus; 2 – vabaabielu; 3 – lahutatud; 4 – lesk\n\n\ntraining1\nOsalusrühm tingimusel, et ei nõutud tõendit hilisema töö saamise kohta – kellelt nõuti, neil puuduv väärtus\n\n\ntraining2\nVõrdlusgrupp, kes soovisid, kuid ei saanud/soovinud osaleda mingil põhjusel\n\n\ntraining3\nKombinatsioon training2 ja training3: need osalusgrupist, kellelt ei nõutud töökohta; need võrdlusgrupist, kes uurisid koolitust, kuid ei osalenud\n\n\ntraining4\nKoolituse osalusrühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid\n\n\ntraining5\nKoolituse põhirühmas ja võrdlusrühmas mõlemas ainult need, kes ise uurisid ja kellelt ei nõutud tõendit\n\n\n\n\n\nVajalikud paketid\n\nlibrary(dplyr)\nlibrary(stargazer)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(boot)\nlibrary(ggplot2)\n\n\n\nAndmestiku lugemine\n\natp &lt;- read.csv(\"http://kodu.ut.ee/~avork/files/oppetoo/micro/atp.csv\")\n\n\n\nKirjeldav analüüs\nLeidke, mitu inimestest osales 2000. aastal koolituses ja mitu ei osalenud\n\ntable(atp$training)\n\n\n  0   1 \n878 429 \n\n\nKui suur osakaal koolituses osalejatest ja mitte-osalejatest töötas 2002. aasta septembris? Tabuleerige muutujad “training” ja “employed” ning leidke protsendid.\n\ntab &lt;- table(atp$training, atp$employed)\nprop.table(tab, margin = 1)\n\n   \n            0         1\n  0 0.4100228 0.5899772\n  1 0.2913753 0.7086247\n\n\nMilline oli keskmine palk koolituses osalejatel ja mitte-osalejatel 2002. aasta septembris?\n\natp %&gt;% group_by(training) %&gt;% summarise(mean_wage = mean(nwage, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  training mean_wage\n     &lt;int&gt;     &lt;dbl&gt;\n1        0     1678.\n2        1     2042.\n\n\n\n\nRegressioonimudel\nHinnake regressioonimudel, kus väljundid employed ja nwage sõltuvad ainult koolituses osalemisest.\n\nm1 &lt;- lm(employed ~ training, data = atp)\nm2 &lt;- lm(nwage ~ training, data = atp)\nstargazer(m1, m2, type = \"text\")\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                            employed                  nwage         \n                              (1)                      (2)          \n--------------------------------------------------------------------\ntraining                    0.119***               363.850***       \n                            (0.028)                 (119.754)       \n                                                                    \nConstant                    0.590***              1,677.766***      \n                            (0.016)                 (68.337)        \n                                                                    \n--------------------------------------------------------------------\nObservations                 1,307                    1,256         \nR2                           0.013                    0.007         \nAdjusted R2                  0.013                    0.007         \nResidual Std. Error    0.480 (df = 1305)      1,988.834 (df = 1254) \nF Statistic         17.591*** (df = 1; 1305) 9.231*** (df = 1; 1254)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nHinnake mudelid koos teiste selgitavate teguritega\n\natp$age2 &lt;- atp$age^2\nlin_employed &lt;- lm(employed ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_employed, vcov = vcovHC(lin_employed, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -0.15070176  0.15151587 -0.9946 0.3201030    \ntraining     0.09816437  0.02764834  3.5505 0.0003983 ***\nmale         0.07986481  0.02872120  2.7807 0.0055027 ** \nest          0.09711124  0.02694719  3.6038 0.0003255 ***\nage          0.02945808  0.00978750  3.0098 0.0026649 ** \nage2        -0.00040217  0.00012743 -3.1560 0.0016364 ** \neduc         0.05265150  0.01496051  3.5194 0.0004475 ***\nemplbefore   0.05064137  0.05218072  0.9705 0.3319782    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHinnake samasugune mudel ka palga kohta ja tõlgendage tulemusi.\n\nlin_nwage &lt;- lm(nwage ~ training + male + est + age + age2 + educ + emplbefore, data = atp)\ncoeftest(lin_nwage, vcov = vcovHC(lin_nwage, \"HC1\"))\n\n\nt test of coefficients:\n\n               Estimate  Std. Error t value  Pr(&gt;|t|)    \n(Intercept) -1284.89226   687.88260 -1.8679   0.06201 .  \ntraining      254.84877   111.15732  2.2927   0.02203 *  \nmale          871.32268   138.00166  6.3139 3.775e-10 ***\nest           821.63833   127.20240  6.4593 1.504e-10 ***\nage            82.57500    43.00273  1.9202   0.05506 .  \nage2           -1.33722     0.53949 -2.4786   0.01332 *  \neduc          297.93783    61.36353  4.8553 1.354e-06 ***\nemplbefore    540.05556   220.40577  2.4503   0.01441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTõlgendage tulemusi!\nLubage võimalikku heteroskedastiivsust.\nLeiame robustsed standarvead.\n\nrobust_se1 &lt;- sqrt(diag(vcovHC(lin_employed, type = \"HC1\")))\nrobust_se2 &lt;- sqrt(diag(vcovHC(lin_nwage, type = \"HC1\")))\nstargazer(lin_employed, lin_nwage, se = list(robust_se1, robust_se2), type = \"text\", no.space = TRUE)\n\n\n====================================================================\n                                  Dependent variable:               \n                    ------------------------------------------------\n                           employed                  nwage          \n                              (1)                     (2)           \n--------------------------------------------------------------------\ntraining                   0.098***                254.849**        \n                            (0.028)                (111.157)        \nmale                       0.080***                871.323***       \n                            (0.029)                (138.002)        \nest                        0.097***                821.638***       \n                            (0.027)                (127.202)        \nage                        0.029***                 82.575*         \n                            (0.010)                 (43.003)        \nage2                      -0.0004***                -1.337**        \n                           (0.0001)                 (0.539)         \neduc                       0.053***                297.938***       \n                            (0.015)                 (61.364)        \nemplbefore                   0.051                 540.056**        \n                            (0.052)                (220.406)        \nConstant                    -0.151                -1,284.892*       \n                            (0.152)                (687.883)        \n--------------------------------------------------------------------\nObservations                 1,307                   1,256          \nR2                           0.051                   0.109          \nAdjusted R2                  0.046                   0.104          \nResidual Std. Error    0.472 (df = 1299)     1,888.387 (df = 1248)  \nF Statistic         9.954*** (df = 7; 1299) 21.885*** (df = 7; 1248)\n====================================================================\nNote:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKas robustsete standardvigade kasutamine muudab statistilist parameetrite statistilist olulisust?\n\n\nEraldi mudelid osalejatele ja mitteosalejatele\n\nNäide - meetme mõju palgale vanuse lõikes\n\natpj &lt;- atp %&gt;% filter(!is.na(nwage)) %&gt;% \n  filter(nwage&lt;5000, nwage&gt;0)\n\nggplot(atpj,\n       aes(x = age, y = nwage, color = \"Palk\")) +\n  geom_point() +\n  geom_smooth(data = atpj %&gt;% filter(training ==1), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 1\")) +\n  geom_smooth(data = atpj %&gt;% filter(training ==0), method = \"lm\", \n              #              formula = y ~ poly(x, 2),\n              se = FALSE, \n              aes(color = \"Prognoos, D = 0\")) +\n  scale_color_manual(name = \"\", values = c(\"Palk\" = \"grey\",\n                                           \"Prognoos, D = 1\" = \"blue\",\n                                           \"Prognoos, D = 0\" = \"green\")) +\n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Palk\", color = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\natpj$ate &lt;-\n  predict(lm(nwage ~ age, data=atpj[atpj$training==1,]), new=atpj) - \n           predict(lm(nwage ~ age, data=atpj[atpj$training==0,]), new=atpj)\n\nSee joonis näitab, kuidas vanus mõjutab palka kahes erinevas grupis (osalejad vs mitte-osalejad). Kasutame valemi \\(Y \\sim X\\) seost vanuse osas.\nMõju sõltub vanusest. Mida noorem, seda suurem efekt.\n\nggplot(atpj,\n       aes(x = age, y = ate)) +\n  geom_line() +\n  #geom_rug(sides = \"b\") +\n  #geom_histogram(aes(y = ..count..), \n  #               binwidth = 1, alpha = 0.9, fill = \"grey\", position = \"identity\") +\n  geom_histogram(aes(fill = as.factor(training), y = ..count..), \n                 binwidth = 1, alpha = 0.5, position = \"identity\") +  # Colored histogram by gender\n  scale_fill_manual(values = c(\"green\", \"blue\")) +\n  \n  theme_minimal() +\n  labs(x = \"Vanus\", y = \"Meetme mõju\", fill = \"Meetmes\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nLisame täiendavad selgitavad tunnused\nTöötamise jaoks\nHindame mudeli osalejate andmete põhjal ja prognoosime tulemused kõigile.\n\nlin_employed_ra1 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$pemployed_1 &lt;- predict(lin_employed_ra1, newdata = atp)\n\nHinnake samasugune mudel ka mitteosalejate põhjal  training==0 ja prognoosige tulemused kõigile\n\nlin_employed_ra0 &lt;- lm(employed ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$pemployed_0 &lt;- predict(lin_employed_ra0, newdata = atp)\n\nLeiame individuaalsed erinevused prognoositud hinnangutes\n\natp$demployed &lt;- atp$pemployed_1 - atp$pemployed_0\n\nKeskmised mõjuhinnangud (ATE) ja eraldi ka osalejatele ning mitteosalejatele\n\nate_empl &lt;- mean(atp$demployed)\natt_empl &lt;- mean(atp$demployed[atp$training == 1])\natu_empl &lt;- mean(atp$demployed[atp$training == 0])\n\nate_empl\n\n[1] 0.1063243\n\natt_empl\n\n[1] 0.0926108\n\natu_empl\n\n[1] 0.1130248\n\n\nKas tulemused muutusid võrreldes ühise regressioonimudeliga?\nSama palgaga\n\nlin_nwage_ra1 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 1, ])\natp$nwage_1 &lt;- predict(lin_nwage_ra1, newdata = atp)\n\nlin_nwage_ra0 &lt;- lm(nwage ~ male + est + age + age2 + educ + emplbefore, data = atp[atp$training == 0, ])\natp$nwage_0 &lt;- predict(lin_nwage_ra0, newdata = atp)\n\natp$dnwage &lt;- atp$nwage_1 - atp$nwage_0\nate_nwage &lt;- mean(atp$dnwage)\natt_nwage &lt;- mean(atp$dnwage[atp$training == 1])\natu_nwage &lt;- mean(atp$dnwage[atp$training == 0])\n\nate_nwage\n\n[1] 259.2266\n\natt_nwage\n\n[1] 254.2755\n\natu_nwage\n\n[1] 261.6458\n\n\nKas koolituse mõju on suurem osalejatele või oleks olnud suurem mitte-osalejatele? Kas mõju on statistiliselt oluline?\n\n\n\nBootstrapping hinnangute standardvea leidmiseks - fännidele\nTeeme funktsiooni\n\nf &lt;- formula(employed ~ male + est + age + age2 + educ + emplbefore)\n\nmybs = function(data, indices, formula =f) {\n  dat = data[indices, ]\n  dify = predict(lm(formula, data = dat[dat$training == 1, ]), newdata = dat) -\n         predict(lm(formula, data = dat[dat$training == 0, ]), newdata = dat)\n  c(ate = mean(dify), att = mean(dify[dat$training == 1]))\n}\n\nja rakendame seda\n\nset.seed(1632)\nresults &lt;- boot(data = atp, statistic = mybs, R = 50, stype = \"i\")\nboot.ci(results)\n\nWarning in norm.inter(t, adj.alpha): extreme order statistics used as endpoints\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 50 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic             Studentized     \n95%   ( 0.0528,  0.1499 )   ( 0.0510,  0.1590 )   ( 0.0621,  0.1969 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.0536,  0.1617 )   ( 0.0503,  0.1415 )  \nCalculations and Intervals on Original Scale\nSome basic intervals may be unstable\nSome studentized intervals may be unstable\nSome percentile intervals may be unstable\nWarning : BCa Intervals used Extreme Quantiles\nSome BCa intervals may be unstable",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Regressioonimudeli kasutamine</span>"
    ]
  },
  {
    "objectID": "04-difdif.html",
    "href": "04-difdif.html",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "",
    "text": "5.1 Mudeli seade\nPoolik - arenev\nJuurdekasvude erinevuse (DiD) meetod on üks populaarsemaid kvaasi-eksperimentaalseid meetodeid põhjusliku mõju hindamiseks. See eemaldab ajas muutumatud erinevused gruppide vahel ja ajas muutuvad tegurid, mis mõjutavad mõlemaid gruppe ühtemoodi.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#mudeli-seade",
    "href": "04-difdif.html#mudeli-seade",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "",
    "text": "Klassikaline 2x2 DiD disain\nKõige lihtsamal kujul on meil kaks rühma ja kaks ajahetke:\n\nGrupid (\\(D\\)):\n\n\\(D=1\\): Osalusrühm (Treatment), kes saab mingil hetkel sekkumise.\n\\(D=0\\): Võrdlusrühm (Control), kes sekkumist ei saa.\n\nAeg (\\(T\\)):\n\n\\(T=1\\): Pärast sekkumist (Post).\n\\(T=0\\): Enne sekkumist (Pre).\n\n\n\n\nDiD hinnang Valemina\nDiD hinnang (\\(\\hat{\\delta}_{DiD}\\)) leitakse kui erinevus osalejate ajas toimunud muutuse ja võrdlusrühma ajas toimunud muutuse vahel:\n\\[\n\\hat{\\delta}_{DiD} = \\underbrace{(\\bar{Y}_{T=1}^{D=1} - \\bar{Y}_{T=0}^{D=1})}_{\\text{Muutus osalejatel}} - \\underbrace{(\\bar{Y}_{T=1}^{D=0} - \\bar{Y}_{T=0}^{D=0})}_{\\text{Muutus võrdlusrühmal}}\n\\] Kus \\(\\bar{Y}_{T}^{D}\\) on tulemuse keskmine vastavas grupis ja ajahetkel.\n\n\nDiD Regressioonimudelina\nSeda sama hinnangut saab leida lineaarse regressioonimudeli abil, kasutades interaktsiooniliiget:\n\\[Y_{it} = \\alpha + \\beta_1 \\text{D}_i + \\beta_2 \\text{Post}_t + \\delta*(\\text{D}_i \\times \\text{Post}_t) + \\epsilon_{it}\n\\]\nKus:\n\n\\(\\alpha\\): Kontrollgrupi keskmine enne sekkumist (Constant).\n\\(\\beta_1\\): Gruppidevaheline püsiv erinevus (Treatment Group Effect).\n\\(\\beta_2\\): Ajaline trend, mis on ühine mõlemale grupile (Time Trend).\n** \\(\\delta_{DiD}\\) **: Põhjuslik mõju ehk huvipakkuv parameeter (ATT). See näitab lisandumist tulemuses, mis tekib ainult osalejatel pärast sekkumist.\n\n\n\nParalleelse trendi eeldus ja ATT\nDiD meetodi kehtivus sõltub paralleelse trendi eeldusest (Parallel trends assumption).\nEeldus väidab, et sekkumise puudumisel oleks osalusrühma keskmine tulemus muutunud ajas samamoodi nagu võrdlusrühmal.\nMatemaatiliselt (kasutades potentsiaalseid tulemusi \\(Y^0\\)):\n\\[\nE[Y^0_{t=1} - Y^0_{t=0} | D=1] = E[Y^0_{t=1} - Y^0_{t=0} | D=0]\n\\]\nKuidas see annab ATT?\nMeie eesmärk on leida keskmine mõju osalejatele (ATT - Average Treatment Effect on the Treated):\n\\[ATT = E[Y^1_{t=1} - Y^0_{t=1} | D=1] \\] Kuna \\(Y^0_{t=1}\\) (osalejate tulemus ilma sekkumiseta) ei ole vaadeldav, kasutame paralleelse trendi eeldust selle asendamiseks:\n\nTegelik muutus osalejatel: \\(E[Y^1_{t=1} | D=1] - E[Y^0_{t=0} | D=1]\\)\nMuutus kui sekkumist poleks: Eelduse kohaselt võrdne kontrollgrupi muutusega \\(E[Y^0_{t=1} | D=0] - E[Y^0_{t=0} | D=0]\\).\n\nSeega:\n\\[\nATT = (\\text{Osalusrühma muutus}) - (\\text{Võrdlusrühma muutus})\n\\]\n\n\nKahesuunaline fikseeritud effektide mudel (TWFE)\nTwo-way Fixed Effects model\nKui andmed on paneelkujul (sama objekti jälgitakse mitmel ajahetkel) või meil on palju objekte ja ajahetki, kasutatakse TWFE mudelit. See on 2x2 disaini üldistus.\n\\[\nY_{it} = \\alpha_i + \\gamma_t + \\delta D_{it} + \\mathbf{X}_{it}\\beta + \\epsilon_{it}\n\\]\nKus:\n\n\\(\\alpha_i\\) (Unit Fixed Effects): Ühiku-spetsiifiline fikseeritud efekt. See kontrollib kõiki tegureid, mis on ühikule \\(i\\) omased ja ajas ei muutu (nt asukoht, kultuur, geneetika). Asendab \\(\\text{Treat}_i\\) muutujat.\n\\(\\gamma_t\\) (Time Fixed Effects): Aja-spetsiifiline fikseeritud efekt. See kontrollib šokke, mis mõjutavad kõiki ühikuid antud aastal \\(t\\) ühtemoodi (nt majanduskriis, seadusemuudatused). Asendab \\(\\text{Post}_t\\) muutujat.\n\\(D_{it}\\) (Treatment Indicator): Binaarne muutuja, mis on 1, kui ühik \\(i\\) on ajal \\(t\\) sekkumise all.\n\\(\\delta\\): Hinnanguline ATT (eeldusel, et mõju on homogeenne).\n\n\n\nSündmuste uuring (Event study)\nSündmuste uuring (Event Study) on dünaamiline regressioonimudel, mis võimaldab hinnata meetme mõju muutumist ajas ning testida visuaalselt ja statistiliselt paralleelse trendi eeldust.\n\nRegressioonivalem\nÜldkuju Kahesuunalise Fikseeritud Efektide (TWFE) mudelina:\n\\[\nY_{it} = \\alpha_i + \\gamma_t + \\sum_{k=-K, k \\neq 0}^{L} \\beta_k \\cdot D_{it}^k + \\epsilon_{it}\n\\]\n\n\n\nMuutujate selgitus\n\n\\(Y_{it}\\): Tulemusmuutuja ühikule \\(i\\) ajahetkel \\(t\\).\n\\(\\alpha_i\\): Ühiku fikseeritud efekt (Unit Fixed Effects). Kontrollib ajas muutumatuid eripärasid (nt asukoht, kultuur).\n\\(\\gamma_t\\): Aja fikseeritud efekt (Time Fixed Effects). Kontrollib šokke, mis mõjutavad kõiki ühikuid samal ajal (nt majanduskriis, inflatsioon).\n\\(k\\): Suhteline aeg sündmuseni (\\(t - E_i\\), kus \\(E_i\\) on sündmuse toimumise aeg).\n\n\\(k &lt; 0\\): Perioodid enne meedet (Leads).\n\\(k \\ge 0\\): Perioodid pärast meedet (Lags).\n\n\\(D_{it}^k\\): Sündmuse indikaatorid (Event Time Dummies).\n\nMuutuja on 1, kui ühik \\(i\\) on ajahetkel \\(t\\) täpselt \\(k\\) perioodi kaugusel sündmusest.\nMuutuja on 0 muudel juhtudel.\n\n\\(\\beta_k\\): Huvipakkuvad koefitsiendid:\n\nKui \\(k &lt; 0\\) (Eel-periood): \\(\\beta_k\\) näitab erinevust töötlus- ja kontrollgrupi vahel enne meedet. See testib paralleelseid trende. Kui eeldus kehtib, peaksid need \\(\\beta\\)-d olema statistiliselt nullist eristamatud (nulljoone lähedal).\nKui \\(k \\ge 0\\) (Järel-periood): \\(\\beta_k\\) näitab meetme dünaamilist mõju \\(k\\) perioodi pärast sündmust.\n\n\\(k \\neq 0\\): Väljajäetud kategooria.\n\nTavaliselt jäetakse mudelist välja periood vahetult enne sündmust (\\(k = 0\\)), et vältida multikollineaarsust. Kõiki teisi koefitsiente (\\(\\beta_k\\)) tõlgendatakse selle baasperioodi suhtes. Eeldame, et perioodil 1 tekib esimest korda avatus meetmele.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#näide-tööpoliitikast",
    "href": "04-difdif.html#näide-tööpoliitikast",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.2 Näide tööpoliitikast",
    "text": "5.2 Näide tööpoliitikast\n\nlibrary(dplyr)\nlibrary(coefplot)\nlibrary(stargazer)\n\n\n#Muutke ära andmete kataloog\ndatapath = \"http://kodu.ut.ee/~avork/files/oppetoo/pohjustagajarg/\"\n\n#Lugege sisse andmefail\ndf &lt;- read.csv(file = paste0(datapath, \"adulttraining.csv\"))\ndfl &lt;- read.csv(file = paste0(datapath, \"adulttraininglong.csv\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#kirjeldav-statistiline-analüüs",
    "href": "04-difdif.html#kirjeldav-statistiline-analüüs",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.3 Kirjeldav statistiline analüüs",
    "text": "5.3 Kirjeldav statistiline analüüs\n\nstargazer(df, type = \"text\")\n\n\n=========================================================\nStatistic       N     Mean    St. Dev.    Min      Max   \n---------------------------------------------------------\nid            4,586 2,293.500 1,324.008    1      4,586  \nkoolituses    4,586   0.500     0.500      0        1    \npalk2008      4,586   6.063     5.537    0.000   24.959  \npalk2009      4,586   4.971     5.003    0.000   22.860  \npalk2010      4,586   4.509     4.872    0.000   21.768  \npalk2011      4,586   5.014     5.181    0.000   22.508  \npalk2012      4,586   5.737     5.764    0.000   25.584  \npalk2013      4,586   6.208     6.217    0.000   27.530  \nharidus       4,586   4.154     1.287      2        6    \nmees          4,586   0.573     0.495      0        1    \neestlane      4,586   0.657     0.475      0        1    \nvanus         4,586  39.831    11.892     16       73    \nkulu          2,293 3,334.167 1,461.837 331.320 6,624.000\nkoolitusaasta 4,586 1,005.240 1,005.350    0      2,011  \nseisund       4,586   1.463     0.749      1        3    \n---------------------------------------------------------\n\nstargazer(df %&gt;% filter(koolituses ==1), type = \"text\")\n\n\n=========================================================\nStatistic       N     Mean    St. Dev.    Min      Max   \n---------------------------------------------------------\nid            2,293 1,147.000  662.076     1      2,293  \nkoolituses    2,293   1.000     0.000      1        1    \npalk2008      2,293   6.399     5.412    0.000   24.959  \npalk2009      2,293   5.298     4.971    0.000   22.860  \npalk2010      2,293   4.736     4.817    0.000   21.768  \npalk2011      2,293   5.492     5.174    0.000   22.508  \npalk2012      2,293   6.339     5.758    0.000   25.584  \npalk2013      2,293   6.776     6.293    0.000   27.530  \nharidus       2,293   4.215     1.288      2        6    \nmees          2,293   0.604     0.489      0        1    \neestlane      2,293   0.652     0.476      0        1    \nvanus         2,293  39.310    11.719     17       73    \nkulu          2,293 3,334.167 1,461.837 331.320 6,624.000\nkoolitusaasta 2,293 2,010.481   0.500    2,010    2,011  \nseisund       2,293   1.578     0.846      1        3    \n---------------------------------------------------------\n\nstargazer(df %&gt;% filter(koolituses ==0), type = \"text\")\n\n\n===================================================\nStatistic       N     Mean    St. Dev.  Min   Max  \n---------------------------------------------------\nid            2,293 3,440.000 662.076  2,294 4,586 \nkoolituses    2,293   0.000    0.000     0     0   \npalk2008      2,293   5.726    5.640   0.000 24.959\npalk2009      2,293   4.644    5.014   0.000 22.860\npalk2010      2,293   4.282    4.918   0.000 21.768\npalk2011      2,293   4.536    5.146   0.000 22.508\npalk2012      2,293   5.135    5.708   0.000 25.584\npalk2013      2,293   5.640    6.088   0.000 27.530\nharidus       2,293   4.092    1.283     2     6   \nmees          2,293   0.543    0.498     0     1   \neestlane      2,293   0.662    0.473     0     1   \nvanus         2,293  40.353    12.042   16     64  \nkoolitusaasta 2,293   0.000    0.000     0     0   \nseisund       2,293   1.348    0.616     1     3   \n---------------------------------------------------\n\n\n\n#Gruppide võrdlus\nprop.table(table(\"Koolituses\" = df$koolituses, \"Mees\" = df$mees),1)\n\n          Mees\nKoolituses         0         1\n         0 0.4570432 0.5429568\n         1 0.3964239 0.6035761\n\n\nKeskmine vanus\n\ndf %&gt;% group_by(koolituses) %&gt;% \n  summarise(keskminevanus = mean(vanus))\n\n# A tibble: 2 × 2\n  koolituses keskminevanus\n       &lt;int&gt;         &lt;dbl&gt;\n1          0          40.4\n2          1          39.3\n\n\nPalk on tuhandetes eurodes\nMis on palga muutus osalusgrupis ja võrdlusgrupis? (Enne-pärast hinnang)\nVaatame 2008 vs 2013. Arvutame erinevuse.\n\ndf %&gt;% \n  group_by(koolituses) %&gt;% \n  summarise(palk2008 = mean(palk2008),\n            palk2013 = mean(palk2013))\n\n# A tibble: 2 × 3\n  koolituses palk2008 palk2013\n       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1          0     5.73     5.64\n2          1     6.40     6.78\n\n\nPalga muutus osalusgrupis\n\ntemp &lt;- df %&gt;% \n  group_by(koolituses) %&gt;% \n  summarise(palk2008 = mean(palk2008),\n            palk2013 = mean(palk2013)) %&gt;% \n  mutate(palgamuut = palk2013-palk2008)\n\n#Enne-pärast hinnang\ntemp\n\n# A tibble: 2 × 4\n  koolituses palk2008 palk2013 palgamuut\n       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1          0     5.73     5.64   -0.0865\n2          1     6.40     6.78    0.377 \n\n#Osalusgrupis\ntemp$palgamuut[2]\n\n[1] 0.3773767\n\ndifdif = temp$palgamuut[2] - temp$palgamuut[1]\ndifdif\n\n[1] 0.463845",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#joonis",
    "href": "04-difdif.html#joonis",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.4 Joonis",
    "text": "5.4 Joonis\n\n#Keskmised palgad osalus ja võrdlusrühmas\n\ntemp &lt;- dfl %&gt;% group_by(koolituses, aasta) %&gt;% \n  summarise(palk = mean(palk))\n\n`summarise()` has grouped output by 'koolituses'. You can override using the\n`.groups` argument.\n\ntemp\n\n# A tibble: 12 × 3\n# Groups:   koolituses [2]\n   koolituses aasta  palk\n        &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1          0  2008  5.73\n 2          0  2009  4.64\n 3          0  2010  4.28\n 4          0  2011  4.54\n 5          0  2012  5.14\n 6          0  2013  5.64\n 7          1  2008  6.40\n 8          1  2009  5.30\n 9          1  2010  4.74\n10          1  2011  5.49\n11          1  2012  6.34\n12          1  2013  6.78\n\n#Praksis tee rida haaval\n\nggplot(temp, aes(x = aasta, y = palk, color = factor(koolituses))) +\n  geom_rect(xmin = 2009.5, xmax = 2011.5, ymin = min(temp$palk)-0.5, ymax = max(temp$palk), fill = \"grey100\", \n            alpha = 0.1, color = \"steelblue\") +\n  geom_point() +\n  geom_line() +\n  geom_text(aes(label = round(palk,1)), vjust = -2, show.legend = FALSE) +\n  labs(color = \"\", x = \"\", y = \"tuh.eur\") + \n  theme_light()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "04-difdif.html#regressioonanalüüs",
    "href": "04-difdif.html#regressioonanalüüs",
    "title": "5  Juurdekasvude erinevus (Dif-Dif)",
    "section": "5.5 Regressioonanalüüs",
    "text": "5.5 Regressioonanalüüs\n2x2 disain\n\n#Jätame alles aastad\ndfls &lt;- dfl   %&gt;% \n  filter(aasta == 2008 | aasta ==2013) %&gt;% \n  mutate(aasta = as.factor(aasta))\n\nmudel &lt;- lm(data = dfls, formula = palk ~ koolituses + aasta + koolituses*aasta)\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta, \n    data = dfls)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.776 -5.279 -1.159  3.224 21.890 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           5.72637    0.12256  46.724  &lt; 2e-16 ***\nkoolituses            0.67266    0.17332   3.881 0.000105 ***\naasta2013            -0.08647    0.17332  -0.499 0.617872    \nkoolituses:aasta2013  0.46385    0.24512   1.892 0.058476 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.869 on 9168 degrees of freedom\nMultiple R-squared:  0.006445,  Adjusted R-squared:  0.006119 \nF-statistic: 19.82 on 3 and 9168 DF,  p-value: 8.386e-13\n\n#Võrrelge nüüd 2009 ja 2012 andmetega\ndfls &lt;- dfl %&gt;% \n  filter(aasta ==2009 | aasta ==2012) %&gt;% \n  mutate(aasta = as.factor(aasta))\n\nmudel &lt;- lm(data = dfls, formula = palk ~ koolituses + aasta + koolituses*aasta)\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta, \n    data = dfls)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.339 -4.644 -1.134  2.971 20.449 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            4.6441     0.1123  41.369  &lt; 2e-16 ***\nkoolituses             0.6534     0.1588   4.116 3.89e-05 ***\naasta2012              0.4910     0.1588   3.092  0.00199 ** \nkoolituses:aasta2012   0.5504     0.2245   2.451  0.01425 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.376 on 9168 degrees of freedom\nMultiple R-squared:  0.01303,   Adjusted R-squared:  0.01271 \nF-statistic: 40.34 on 3 and 9168 DF,  p-value: &lt; 2.2e-16\n\n#Lisame mudelisse muud tegurid\n\n#Andmestik uuesti\ndifdif1 &lt;- dfl %&gt;% \n  filter(aasta == 2008 | aasta ==2013) %&gt;% \n  mutate(aasta = as.factor(aasta)\n         )\n\n#Ja mudel\nmudel &lt;- lm(data = difdif1, formula = palk ~ koolituses + aasta + \n              koolituses*aasta + mees + eestlane + factor(haridus) + vanusgr + factor(seisund))\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta + \n    mees + eestlane + factor(haridus) + vanusgr + factor(seisund), \n    data = difdif1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4026  -3.6984  -0.5935   2.8292  20.9597 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           2.63883    0.26268  10.046  &lt; 2e-16 ***\nkoolituses            0.49975    0.16041   3.115 0.001842 ** \naasta2013            -0.08647    0.15749  -0.549 0.582981    \nmees                  2.39451    0.11512  20.799  &lt; 2e-16 ***\neestlane              0.30816    0.11864   2.597 0.009408 ** \nfactor(haridus)3      0.58185    0.20738   2.806 0.005032 ** \nfactor(haridus)4      0.68067    0.19926   3.416 0.000638 ***\nfactor(haridus)5      1.52820    0.21882   6.984 3.07e-12 ***\nfactor(haridus)6      2.92520    0.21333  13.712  &lt; 2e-16 ***\nvanusgr(25,35]        1.84815    0.18750   9.857  &lt; 2e-16 ***\nvanusgr(35,45]        2.25874    0.18872  11.969  &lt; 2e-16 ***\nvanusgr(45,55]        1.32949    0.19052   6.978 3.20e-12 ***\nvanusgr(55,100]       0.88350    0.22516   3.924 8.78e-05 ***\nfactor(seisund)2     -4.03936    0.16201 -24.933  &lt; 2e-16 ***\nfactor(seisund)3     -2.85658    0.16182 -17.652  &lt; 2e-16 ***\nkoolituses:aasta2013  0.46385    0.22272   2.083 0.037310 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.332 on 9156 degrees of freedom\nMultiple R-squared:  0.1808,    Adjusted R-squared:  0.1795 \nF-statistic: 134.7 on 15 and 9156 DF,  p-value: &lt; 2.2e-16\n\nmudel &lt;- lm(data = difdif1, formula = palk ~ koolituses + aasta + \n              koolituses*aasta + mees + eestlane + factor(haridus) + vanusgr)\n\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ koolituses + aasta + koolituses * aasta + \n    mees + eestlane + factor(haridus) + vanusgr, data = difdif1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.0784  -4.2239  -0.5918   3.1125  22.1705 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.62852    0.26374   2.383 0.017185 *  \nkoolituses            0.35621    0.16480   2.162 0.030678 *  \naasta2013            -0.08647    0.16424  -0.526 0.598564    \nmees                  2.61807    0.11978  21.858  &lt; 2e-16 ***\neestlane              0.57926    0.12310   4.705 2.57e-06 ***\nfactor(haridus)3      0.80047    0.21600   3.706 0.000212 ***\nfactor(haridus)4      1.07191    0.20718   5.174 2.34e-07 ***\nfactor(haridus)5      1.94470    0.22746   8.550  &lt; 2e-16 ***\nfactor(haridus)6      3.63372    0.22061  16.471  &lt; 2e-16 ***\nvanusgr(25,35]        2.29960    0.19483  11.803  &lt; 2e-16 ***\nvanusgr(35,45]        2.88528    0.19538  14.768  &lt; 2e-16 ***\nvanusgr(45,55]        1.65069    0.19804   8.335  &lt; 2e-16 ***\nvanusgr(55,100]       0.80390    0.23462   3.426 0.000614 ***\nkoolituses:aasta2013  0.46385    0.23227   1.997 0.045850 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.561 on 9158 degrees of freedom\nMultiple R-squared:  0.1089,    Adjusted R-squared:  0.1076 \nF-statistic: 86.05 on 13 and 9158 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n#Leiame erinevuse koolituse aastast. \n# Kõigile koolituses mitteosalejatele paneme selle nulliks\n\ndfl &lt;- dfl %&gt;%  \n  mutate(aegkoolitusest = ifelse(koolituses ==1, \n                                 aasta - koolitusaasta,\n                                 0))\n\n#Joonise jaoks teeme selle faktoriks, et võrdlusrühm oleks null\ndfl &lt;- dfl %&gt;% \n  mutate(aegkoolitusest = factor(aegkoolitusest, levels = c(0, -3:-1, 1:3)))\n\ntable(dfl$aegkoolitusest)\n\n\n    0    -3    -2    -1     1     2     3 \n16051  1102  2293  2293  2293  2293  1191 \n\n#Time event model\n\nmudel &lt;- lm(data = dfl, formula = palk ~ aegkoolitusest + mees + \n              eestlane + factor(haridus) + vanusgr + factor(aasta) + factor(seisund))\n\nsummary(mudel)\n\n\nCall:\nlm(formula = palk ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta) + factor(seisund), data = dfl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.1467  -3.1984  -0.5901   2.4896  21.2495 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        3.33072    0.15536  21.439  &lt; 2e-16 ***\naegkoolitusest-3   0.61845    0.17385   3.557 0.000375 ***\naegkoolitusest-2   0.67030    0.12333   5.435 5.53e-08 ***\naegkoolitusest-1   0.51922    0.11952   4.344 1.40e-05 ***\naegkoolitusest1    0.86321    0.11950   7.224 5.19e-13 ***\naegkoolitusest2    1.10103    0.12305   8.948  &lt; 2e-16 ***\naegkoolitusest3    1.22460    0.16875   7.257 4.07e-13 ***\nmees               1.99551    0.06044  33.015  &lt; 2e-16 ***\neestlane           0.31287    0.06232   5.020 5.20e-07 ***\nfactor(haridus)3   0.64890    0.10894   5.957 2.61e-09 ***\nfactor(haridus)4   0.74425    0.10466   7.111 1.18e-12 ***\nfactor(haridus)5   1.54188    0.11492  13.417  &lt; 2e-16 ***\nfactor(haridus)6   2.65592    0.11204  23.704  &lt; 2e-16 ***\nvanusgr(25,35]     1.37220    0.09848  13.933  &lt; 2e-16 ***\nvanusgr(35,45]     1.74154    0.09913  17.567  &lt; 2e-16 ***\nvanusgr(45,55]     0.96528    0.10008   9.645  &lt; 2e-16 ***\nvanusgr(55,100]    0.63932    0.11826   5.406 6.50e-08 ***\nfactor(aasta)2009 -1.06512    0.11343  -9.390  &lt; 2e-16 ***\nfactor(aasta)2010 -1.35564    0.11863 -11.427  &lt; 2e-16 ***\nfactor(aasta)2011 -0.95030    0.12090  -7.860 3.98e-15 ***\nfactor(aasta)2012 -0.49641    0.12559  -3.953 7.75e-05 ***\nfactor(aasta)2013 -0.11446    0.13047  -0.877 0.380319    \nfactor(seisund)2  -4.37419    0.08505 -51.433  &lt; 2e-16 ***\nfactor(seisund)3  -3.51146    0.08458 -41.518  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.852 on 27492 degrees of freedom\nMultiple R-squared:  0.2179,    Adjusted R-squared:  0.2173 \nF-statistic: 333.1 on 23 and 27492 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel, intercept = FALSE)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\nLisame mineviku palga enne koolitust sisse ja vaatame muutust võrreldes 2008 aasta palgaga\n\ndfl &lt;- dfl %&gt;% \n  group_by(id) %&gt;% \n  mutate(palk2008 = palk[aasta==2008]) %&gt;% \n  mutate(dpalk2008 = palk - palk2008) %&gt;% \n  ungroup()\n\nmudel2 &lt;- lm(data = dfl, formula = dpalk2008 ~ aegkoolitusest + mees + \n              eestlane + factor(haridus) + vanusgr + factor(aasta) + factor(seisund))\n\nsummary(mudel2)\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta) + factor(seisund), data = dfl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.5388  -1.2891   0.2704   1.6983  25.3013 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.34683    0.12829  18.293  &lt; 2e-16 ***\naegkoolitusest-3   0.25237    0.14356   1.758 0.078759 .  \naegkoolitusest-2   0.24246    0.10184   2.381 0.017289 *  \naegkoolitusest-1   0.14363    0.09869   1.455 0.145587    \naegkoolitusest1    0.48287    0.09867   4.894 9.96e-07 ***\naegkoolitusest2    0.64464    0.10161   6.345 2.27e-10 ***\naegkoolitusest3    0.69184    0.13935   4.965 6.92e-07 ***\nmees              -0.51370    0.04991 -10.292  &lt; 2e-16 ***\neestlane          -0.18885    0.05146  -3.669 0.000244 ***\nfactor(haridus)3  -0.01539    0.08996  -0.171 0.864121    \nfactor(haridus)4  -0.06219    0.08642  -0.720 0.471801    \nfactor(haridus)5   0.03194    0.09490   0.337 0.736445    \nfactor(haridus)6  -0.36442    0.09252  -3.939 8.21e-05 ***\nvanusgr(25,35]    -1.48122    0.08132 -18.214  &lt; 2e-16 ***\nvanusgr(35,45]    -1.85345    0.08186 -22.641  &lt; 2e-16 ***\nvanusgr(45,55]    -1.93637    0.08264 -23.430  &lt; 2e-16 ***\nvanusgr(55,100]   -2.42367    0.09765 -24.819  &lt; 2e-16 ***\nfactor(aasta)2009 -1.06384    0.09367 -11.358  &lt; 2e-16 ***\nfactor(aasta)2010 -1.46447    0.09796 -14.950  &lt; 2e-16 ***\nfactor(aasta)2011 -1.05061    0.09984 -10.523  &lt; 2e-16 ***\nfactor(aasta)2012 -0.48558    0.10371  -4.682 2.85e-06 ***\nfactor(aasta)2013 -0.06551    0.10773  -0.608 0.543116    \nfactor(seisund)2  -0.91739    0.07023 -13.063  &lt; 2e-16 ***\nfactor(seisund)3  -1.53353    0.06984 -21.958  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.006 on 27492 degrees of freedom\nMultiple R-squared:  0.07153,   Adjusted R-squared:  0.07075 \nF-statistic: 92.08 on 23 and 27492 DF,  p-value: &lt; 2.2e-16\n\ncoefplot(mudel2, intercept = FALSE)\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\nTeeme mudeli eraldi töötavate, töötute ja mitteaktiivsete jaoks.\n\nlibrary(broom)\n\nresults &lt;- dfl %&gt;%\n  group_by(seisund) %&gt;%\n  group_modify(~ broom::tidy(\n    lm(dpalk2008 ~ aegkoolitusest + mees + eestlane +\n         factor(haridus) + vanusgr + factor(aasta),\n       data = .x)\n  ))\nresults\n\n# A tibble: 66 × 6\n# Groups:   seisund [3]\n   seisund term             estimate std.error statistic  p.value\n     &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1       1 (Intercept)        2.03      0.162     12.6   5.05e-36\n 2       1 aegkoolitusest-3   0.0686    0.181      0.379 7.04e- 1\n 3       1 aegkoolitusest-2   0.251     0.125      2.00  4.54e- 2\n 4       1 aegkoolitusest-1   0.267     0.122      2.19  2.88e- 2\n 5       1 aegkoolitusest1    0.558     0.122      4.56  5.05e- 6\n 6       1 aegkoolitusest2    0.544     0.125      4.35  1.35e- 5\n 7       1 aegkoolitusest3    0.258     0.170      1.52  1.28e- 1\n 8       1 mees              -0.418     0.0615    -6.80  1.05e-11\n 9       1 eestlane          -0.281     0.0640    -4.40  1.10e- 5\n10       1 factor(haridus)3   0.220     0.118      1.86  6.26e- 2\n# ℹ 56 more rows\n\n\nVõi\n\ndfl &lt;- dfl %&gt;% \n  mutate(seisundtext = case_when(\n    seisund == 1 ~ \"Töötab\",\n    seisund == 2 ~ \"Mitteaktiivne\",\n    seisund == 3 ~ \"Töötu\"))\n    \ntable(dfl$seisund, dfl$seisundtext)\n\n   \n    Mitteaktiivne Töötab Töötu\n  1             0  19068     0\n  2          4152      0     0\n  3             0      0  4296\n\nmodels &lt;- lapply(split(dfl, dfl$seisundtext), function(df) {\n  \n  lm(dpalk2008 ~ aegkoolitusest + mees + eestlane +\n       factor(haridus) + vanusgr + factor(aasta),\n     data = df)\n  \n})\n\nsummary(models[[1]])  # results for seisund = 1\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.8540  -0.9882   0.4606   1.6002  21.8434 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        1.45382    0.24216   6.004 2.10e-09 ***\naegkoolitusest-3  -0.06414    0.35509  -0.181  0.85667    \naegkoolitusest-2  -0.41936    0.24689  -1.699  0.08948 .  \naegkoolitusest-1  -0.58676    0.24370  -2.408  0.01610 *  \naegkoolitusest1    0.60835    0.24370   2.496  0.01259 *  \naegkoolitusest2    1.39161    0.24663   5.643 1.79e-08 ***\naegkoolitusest3    1.67315    0.33804   4.949 7.74e-07 ***\nmees              -0.53755    0.11044  -4.867 1.17e-06 ***\neestlane           0.22079    0.11093   1.990  0.04661 *  \nfactor(haridus)3  -0.46576    0.17386  -2.679  0.00741 ** \nfactor(haridus)4  -0.08594    0.17345  -0.495  0.62028    \nfactor(haridus)5  -0.28684    0.19251  -1.490  0.13630    \nfactor(haridus)6  -0.48029    0.19660  -2.443  0.01461 *  \nvanusgr(25,35]    -1.06025    0.16224  -6.535 7.14e-11 ***\nvanusgr(35,45]    -1.09392    0.17827  -6.136 9.23e-10 ***\nvanusgr(45,55]    -0.87006    0.16862  -5.160 2.59e-07 ***\nvanusgr(55,100]   -1.82290    0.16634 -10.959  &lt; 2e-16 ***\nfactor(aasta)2009 -0.96318    0.19760  -4.874 1.13e-06 ***\nfactor(aasta)2010 -1.86286    0.20271  -9.190  &lt; 2e-16 ***\nfactor(aasta)2011 -2.07730    0.20495 -10.136  &lt; 2e-16 ***\nfactor(aasta)2012 -1.69572    0.20979  -8.083 8.24e-16 ***\nfactor(aasta)2013 -1.24303    0.21512  -5.778 8.10e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.41 on 4130 degrees of freedom\nMultiple R-squared:  0.08617,   Adjusted R-squared:  0.08152 \nF-statistic: 18.55 on 21 and 4130 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[2]])  # results for seisund = 2\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.6139  -1.3406   0.2502   1.5351  25.2833 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.03160    0.16179  12.557  &lt; 2e-16 ***\naegkoolitusest-3   0.06861    0.18086   0.379 0.704415    \naegkoolitusest-2   0.25106    0.12547   2.001 0.045407 *  \naegkoolitusest-1   0.26715    0.12220   2.186 0.028815 *  \naegkoolitusest1    0.55766    0.12219   4.564 5.05e-06 ***\naegkoolitusest2    0.54447    0.12510   4.352 1.35e-05 ***\naegkoolitusest3    0.25842    0.16963   1.523 0.127666    \nmees              -0.41810    0.06146  -6.803 1.05e-11 ***\neestlane          -0.28148    0.06399  -4.399 1.10e-05 ***\nfactor(haridus)3   0.21979    0.11802   1.862 0.062574 .  \nfactor(haridus)4   0.03033    0.11240   0.270 0.787312    \nfactor(haridus)5   0.14695    0.12205   1.204 0.228631    \nfactor(haridus)6  -0.10041    0.11735  -0.856 0.392179    \nvanusgr(25,35]    -1.67483    0.10387 -16.124  &lt; 2e-16 ***\nvanusgr(35,45]    -1.94220    0.10325 -18.810  &lt; 2e-16 ***\nvanusgr(45,55]    -2.13732    0.10668 -20.034  &lt; 2e-16 ***\nvanusgr(55,100]   -2.39087    0.12881 -18.561  &lt; 2e-16 ***\nfactor(aasta)2009 -1.07584    0.11400  -9.437  &lt; 2e-16 ***\nfactor(aasta)2010 -1.12759    0.11833  -9.529  &lt; 2e-16 ***\nfactor(aasta)2011 -0.52076    0.12103  -4.303 1.70e-05 ***\nfactor(aasta)2012 -0.01717    0.12514  -0.137 0.890873    \nfactor(aasta)2013  0.43029    0.12966   3.319 0.000906 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.083 on 19046 degrees of freedom\nMultiple R-squared:  0.05172,   Adjusted R-squared:  0.05067 \nF-statistic: 49.47 on 21 and 19046 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[3]])\n\n\nCall:\nlm(formula = dpalk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.3129  -1.6260   0.3084   2.1003  23.6084 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.5419     0.3245   7.833 5.99e-15 ***\naegkoolitusest-3    0.2090     0.3399   0.615  0.53859    \naegkoolitusest-2    0.2158     0.2577   0.837  0.40240    \naegkoolitusest-1    0.3005     0.2340   1.284  0.19913    \naegkoolitusest1     0.3839     0.2344   1.638  0.10157    \naegkoolitusest2     0.7346     0.2610   2.815  0.00491 ** \naegkoolitusest3     1.7024     0.3605   4.722 2.40e-06 ***\nmees               -0.9696     0.1268  -7.645 2.56e-14 ***\neestlane           -0.2064     0.1268  -1.627  0.10374    \nfactor(haridus)3   -0.1022     0.2069  -0.494  0.62130    \nfactor(haridus)4   -0.1554     0.1970  -0.789  0.43029    \nfactor(haridus)5    0.2983     0.2251   1.325  0.18516    \nfactor(haridus)6   -1.1627     0.2323  -5.006 5.78e-07 ***\nvanusgr(25,35]     -1.2890     0.2022  -6.373 2.04e-10 ***\nvanusgr(35,45]     -2.4755     0.2046 -12.099  &lt; 2e-16 ***\nvanusgr(45,55]     -2.3052     0.1961 -11.756  &lt; 2e-16 ***\nvanusgr(55,100]    -3.5651     0.2628 -13.565  &lt; 2e-16 ***\nfactor(aasta)2009  -1.4256     0.2598  -5.487 4.33e-08 ***\nfactor(aasta)2010  -3.0061     0.2897 -10.375  &lt; 2e-16 ***\nfactor(aasta)2011  -2.8486     0.3003  -9.485  &lt; 2e-16 ***\nfactor(aasta)2012  -1.8581     0.3274  -5.676 1.47e-08 ***\nfactor(aasta)2013  -1.5700     0.3506  -4.478 7.71e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.029 on 4274 degrees of freedom\nMultiple R-squared:  0.1415,    Adjusted R-squared:  0.1373 \nF-statistic: 33.55 on 21 and 4274 DF,  p-value: &lt; 2.2e-16\n\nmultiplot(models) + theme_light() + labs(color = \"Rühm\")\n\n`height` was translated to `width`.\n`height` was translated to `width`.\n\n\n\n\n\n\n\n\n\n\nmodels &lt;- lapply(split(dfl, dfl$seisundtext), function(df) {\n  \n  lm(palk2008 ~ aegkoolitusest + mees + eestlane +\n       factor(haridus) + vanusgr + factor(aasta),\n     data = df)\n  \n})\n\nsummary(models[[1]])  # results for seisund = 1\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.622 -2.564 -1.081  1.558 20.586 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.08828    0.26678   0.331  0.74073    \naegkoolitusest-3   1.05772    0.39120   2.704  0.00688 ** \naegkoolitusest-2   0.71123    0.27199   2.615  0.00896 ** \naegkoolitusest-1   0.60972    0.26848   2.271  0.02320 *  \naegkoolitusest1    0.60144    0.26848   2.240  0.02514 *  \naegkoolitusest2    0.63325    0.27171   2.331  0.01982 *  \naegkoolitusest3    0.33148    0.37242   0.890  0.37348    \nmees               0.88861    0.12167   7.303 3.35e-13 ***\neestlane          -0.14686    0.12221  -1.202  0.22952    \nfactor(haridus)3   0.91963    0.19153   4.801 1.63e-06 ***\nfactor(haridus)4   0.51133    0.19109   2.676  0.00748 ** \nfactor(haridus)5   0.82674    0.21208   3.898 9.84e-05 ***\nfactor(haridus)6   1.96305    0.21660   9.063  &lt; 2e-16 ***\nvanusgr(25,35]     2.06524    0.17874  11.554  &lt; 2e-16 ***\nvanusgr(35,45]     1.49076    0.19640   7.591 3.91e-14 ***\nvanusgr(45,55]     0.81097    0.18577   4.365 1.30e-05 ***\nvanusgr(55,100]    1.88562    0.18325  10.290  &lt; 2e-16 ***\nfactor(aasta)2009  0.07600    0.21769   0.349  0.72700    \nfactor(aasta)2010  0.20639    0.22332   0.924  0.35545    \nfactor(aasta)2011  0.19472    0.22579   0.862  0.38853    \nfactor(aasta)2012  0.08971    0.23113   0.388  0.69795    \nfactor(aasta)2013  0.14072    0.23699   0.594  0.55270    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.757 on 4130 degrees of freedom\nMultiple R-squared:  0.0829,    Adjusted R-squared:  0.07824 \nF-statistic: 17.78 on 21 and 4130 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[2]])  # results for seisund = 2\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4843  -3.6930  -0.3336   2.7044  17.8494 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.087931   0.207368   0.424 0.671547    \naegkoolitusest-3   0.222973   0.231812   0.962 0.336128    \naegkoolitusest-2   0.300380   0.160813   1.868 0.061794 .  \naegkoolitusest-1   0.270490   0.156622   1.727 0.084179 .  \naegkoolitusest1    0.275049   0.156615   1.756 0.079068 .  \naegkoolitusest2    0.329830   0.160344   2.057 0.039698 *  \naegkoolitusest3    0.408656   0.217418   1.880 0.060180 .  \nmees               3.015865   0.078770  38.287  &lt; 2e-16 ***\neestlane           0.534474   0.082020   6.516 7.38e-11 ***\nfactor(haridus)3   0.498829   0.151267   3.298 0.000977 ***\nfactor(haridus)4   0.862890   0.144061   5.990 2.14e-09 ***\nfactor(haridus)5   1.675925   0.156439  10.713  &lt; 2e-16 ***\nfactor(haridus)6   3.103365   0.150405  20.633  &lt; 2e-16 ***\nvanusgr(25,35]     3.434511   0.133134  25.797  &lt; 2e-16 ***\nvanusgr(35,45]     4.404769   0.132337  33.284  &lt; 2e-16 ***\nvanusgr(45,55]     3.637899   0.136737  26.605  &lt; 2e-16 ***\nvanusgr(55,100]    3.610856   0.165102  21.871  &lt; 2e-16 ***\nfactor(aasta)2009 -0.009002   0.146118  -0.062 0.950874    \nfactor(aasta)2010  0.067422   0.151660   0.445 0.656641    \nfactor(aasta)2011  0.054753   0.155122   0.353 0.724119    \nfactor(aasta)2012 -0.018875   0.160395  -0.118 0.906324    \nfactor(aasta)2013 -0.051106   0.166187  -0.308 0.758452    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.233 on 19046 degrees of freedom\nMultiple R-squared:  0.1409,    Adjusted R-squared:  0.1399 \nF-statistic: 148.7 on 21 and 19046 DF,  p-value: &lt; 2.2e-16\n\nsummary(models[[3]])\n\n\nCall:\nlm(formula = palk2008 ~ aegkoolitusest + mees + eestlane + factor(haridus) + \n    vanusgr + factor(aasta), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.3960 -3.0622 -0.5514  2.1596 20.4849 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -0.93264    0.36192  -2.577 0.010001 *  \naegkoolitusest-3   0.64064    0.37908   1.690 0.091102 .  \naegkoolitusest-2   0.80822    0.28736   2.813 0.004938 ** \naegkoolitusest-1   0.65959    0.26098   2.527 0.011528 *  \naegkoolitusest1    0.72961    0.26143   2.791 0.005280 ** \naegkoolitusest2    1.04000    0.29109   3.573 0.000357 ***\naegkoolitusest3    1.33796    0.40203   3.328 0.000882 ***\nmees               2.06985    0.14143  14.635  &lt; 2e-16 ***\neestlane           0.84338    0.14143   5.963 2.67e-09 ***\nfactor(haridus)3   0.88077    0.23071   3.818 0.000137 ***\nfactor(haridus)4   0.73807    0.21967   3.360 0.000786 ***\nfactor(haridus)5   1.09255    0.25105   4.352 1.38e-05 ***\nfactor(haridus)6   3.31594    0.25903  12.801  &lt; 2e-16 ***\nvanusgr(25,35]     2.12557    0.22555   9.424  &lt; 2e-16 ***\nvanusgr(35,45]     2.81844    0.22818  12.352  &lt; 2e-16 ***\nvanusgr(45,55]     2.92538    0.21868  13.377  &lt; 2e-16 ***\nvanusgr(55,100]    3.68956    0.29309  12.588  &lt; 2e-16 ***\nfactor(aasta)2009 -0.02063    0.28976  -0.071 0.943247    \nfactor(aasta)2010  0.26294    0.32312   0.814 0.415823    \nfactor(aasta)2011  0.29567    0.33493   0.883 0.377403    \nfactor(aasta)2012 -0.11509    0.36508  -0.315 0.752582    \nfactor(aasta)2013 -0.34545    0.39095  -0.884 0.376948    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.493 on 4274 degrees of freedom\nMultiple R-squared:  0.1462,    Adjusted R-squared:  0.142 \nF-statistic: 34.86 on 21 and 4274 DF,  p-value: &lt; 2.2e-16\n\nmultiplot(models) + theme_light() + labs(color = \"Rühm\")\n\n`height` was translated to `width`.\n`height` was translated to `width`.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Juurdekasvude erinevus (Dif-Dif)</span>"
    ]
  },
  {
    "objectID": "05-rdd.html",
    "href": "05-rdd.html",
    "title": "6  Regressiooni katkemise meetod",
    "section": "",
    "text": "6.1 Mudeli seade\nPoolik - arenev\nRegressiooni katkemise disain (Regression Discontinuity Design, RDD) on kvaasieksperimentaalne meetod põhjusliku mõju hindamiseks, kui osalemine programmis või meetmes sõltub mõnest pidevast tunnusest (nt vanus, sissetulek, hinne) ja selgelt määratletud lõikepunktist.:contentReferenceoaicite:0\nTüüpilised näited:\nOluline mõte: me ei saa leida täpselt samasugust osalus- ja võrdlusrühma (puudub ühine tugi, common support), kuid saame võrrelda väga lähedal lõikepunktile olevaid isikuid: nt 64 vs 65 aastat, hinne 4,4 vs 4,6.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#mudeli-seade",
    "href": "05-rdd.html#mudeli-seade",
    "title": "6  Regressiooni katkemise meetod",
    "section": "",
    "text": "pensioniõigus alates vanusest 63 või 65\n\ntasuta hambaravi kuni 19. eluaastani\n\ntoetus, kui käive langeb rohkem kui 30%\n\nstipendium, kui hinne ületab 4,5\n\n\n\nTähistused\nOlgu:\n\n\\((Y_i(1)\\) – isiku \\(i\\) potentsiaalne tulemus, kui ta osaleb programmis (D=1)\n\n\\((Y_i(0)\\) – potentsiaalne tulemus, kui ta ei osale (D=0)\n\n\\(D_i \\in \\{0,1\\}\\) – tegelik osalemine meetmes\n\n\\(X_i\\) – määramismuuttuja (vanus, hinne, sissetulek), mis määrab abikõlblikkuse\n\n\\(c\\) – lõikepunkt, lävend (cutoff)\n\nVaatleme tinglikke keskmisi:\n\\[\nm_1(x) = \\mathbb{E}[Y_i(1)\\mid X_i = x], \\quad\nm_0(x) = \\mathbb{E}[Y_i(0)\\mid X_i = x].\n\\]\nRD meetod põhineb ideel, et vahetult lõikepunkti ümbruses on isikud “peaaegu juhuslikult” jaotatud.\n\n\nJärsk (sharp) disain\nMääramistingimus\nJärsk disain (sharp design) tähendab, et määramismuutuja \\(X_i\\) ja lõikepunkt \\(c\\) määravad osalemise deterministlikult:\n\\[\nD_i = \\mathbf{1}(X_i \\ge c),\n\\]\nkus \\(\\mathbf{1}(\\cdot)\\) on indikaatorfunktsioon.\n\nKui \\(X_i \\ge c\\), siis kõik osalevad: \\(D_i = 1\\)\n\nKui \\(X_i &lt; c\\), siis keegi ei osale: \\(D_i = 0\\)\n\nTe gelikult vaatleme täheldatud tulemust\n\\[\nY_i = D_i Y_i(1) + (1-D_i)Y_i(0).\n\\]\n\n\nMõju hindamise valem (sharp RDD)\nRDD põhiobjekt on lokaalne keskmine mõju lõikepunktis:\n\\[\n\\tau^{SRD} = \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x]\n            - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x].\n\\]\nSõnades:\n– võtame tingliku keskmise väljundi vahetult lõikepunktist paremal (abikõlblikud)\n– lahutame sellest tingliku keskmise väljundi vahetult lõikepunktist vasakul (mitteabikõlblikud).\nKui pidevuse eeldus (vt allpool) kehtib, siis see vahe identifitseerib:\n\\[\n\\tau^{SRD} = \\mathbb{E}\\big[Y_i(1) - Y_i(0) \\,\\big|\\, X_i = c\\big],\n\\]\nehk lokaalse ATE – Local Average Treatment Effect lõikepunkti juures (LATE).\n\n\nHägus (fuzzy) disain\nMääramistingimus\nHägus disain (fuzzy design) tähendab, et lõikepunkt ei määra osalemist deterministlikult:\n\nosalemise tõenäosus hüppab lõikepunktis, kuid\n\nenne lõikepunkti on osa isikuid, kes ikkagi osalevad\n\npärast lõikepunkti on osa, kes ei osale.\n\nFormaalne:\n\\[\np(x) = \\Pr(D_i = 1 \\mid X_i = x)\n\\]\non katkev punktis (c), st\n\\[\n\\lim_{x \\downarrow c} p(x) \\neq \\lim_{x \\uparrow c} p(x),\n\\]\naga kumbki pole 0 ega 1.\nMida see tähendab sisuliselt?\n– reegel on olemas (nt pensioniiga 63)\n– aga osa inimestest läheb pensionile varem või hiljem → reeglit ei järgita täielikult\n– lõikepunkti lähedal on \\(X_i\\) käitumas nagu instrumentmuutuja: mõjutab tugevalt osalemise tõenäosust, mitte otseselt tulemust.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#mõju-hindamise-valem-fuzzy-rdd-wald",
    "href": "05-rdd.html#mõju-hindamise-valem-fuzzy-rdd-wald",
    "title": "6  Regressiooni katkemise meetod",
    "section": "6.2 Mõju hindamise valem (fuzzy RDD, Wald)",
    "text": "6.2 Mõju hindamise valem (fuzzy RDD, Wald)\nHägusa disaini korral võrdleme lisaks \\(Y\\) hüppele ka meetmes osalemise hüpet:\n\\[\n\\Delta Y = \\lim_{x \\downarrow c} \\mathbb{E}[Y_i \\mid X_i = x]\n         - \\lim_{x \\uparrow c} \\mathbb{E}[Y_i \\mid X_i = x],\n\\]\n\\[\n\\Delta D = \\lim_{x \\downarrow c} \\mathbb{E}[D_i \\mid X_i = x]\n         - \\lim_{x \\uparrow c} \\mathbb{E}[D_i \\mid X_i = x].\n\\]\nLokaalne Waldi hinnang:\n\\[\n\\tau^{FRD} = \\frac{\\Delta Y}{\\Delta D}.\n\\]\nSee on analoogne IV-Waldi hinnanguga: kui lõikepunkti juures oleks tõenäosus muutunud 0-lt 1-le, siis \\(\\Delta Y\\) olekski mõju; kuna muutus on väiksem, skaleerime selle üles jagades \\(\\Delta D\\)-ga.\n\nPidevuse eeldus\nRDD tuum on pidevuse eeldus (continuity assumption). Informaalne mõte:\nKõik muud tegurid peale programmi mõju muutuvad lõikepunkti ümbruses “sujuvalt” (pidevalt). Ainus diskreetne hüpe \\(Y\\)-s lõikepunktis tuleb programmist.\nFormaalne kuju:\n\\[\n\\lim_{x \\downarrow c} \\mathbb{E}[Y_i(0)\\mid X_i=x]\n=\n\\lim_{x \\uparrow c} \\mathbb{E}[Y_i(0)\\mid X_i=x]\n\\]\nja terava disaini korral samamoodi \\(Y_i(1)\\) jaoks, või üldisemalt, et potentsiaalsete tulemuste tinglikud keskmised on pidevad \\(x=c\\) juures.\nLisaks saame kontrollida, kas ka $X£-i tihedusfunktsioon on pidev lõikepunkti juures (vt McCrary test).\nPidevuse rikkumised:\n\ninimesed manipuleerivad oma $X£-i (hinne, sissetulek) üle/alla piiri, et reegliga mängida\n\nsamal lõikepunktil juhtub mõni muu poliitikamuutus (teine reform, teine programm)\n\nlõikepunkt ise on endogeenne (nt “nutikad” ettevõtted planeerivad töötajate arvu täpselt alla piiri, et toetust saada)\n\n\n\nMcCrary test: x-jaotuse pidevus\nKui inimesed saavad määramismuutujat \\(X\\) ise mõjutada (nt taotlusvormi täitmise kuupäeva, sissetuleku deklareerimist), võivad nad “koonduda” lõikepunkti alla või üles. Selle tuvastamiseks kasutatakse McCrary tihedustesti.\n\n\\(H_0\\): \\(X\\) tihedus on lõikepunkti juures pidev (ei ole manipulatsiooni)\n\n\\(H_1\\): tiheduses on hüpe lõikepunkti juures (viitab manipulatsioonile)\n\nIdee:\n\nhinnatakse \\(X\\) tihedust lõikepunkti vasakul ja paremal (nt lokaalse polünoomi abil),\n\ntestitakse, kas hinnatud tihedused erinevad statistiliselt olulisel määral.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  },
  {
    "objectID": "05-rdd.html#näide-vanaduspensioniiga-pensionide-saamine-ja-tööaeg-eestis-2010.",
    "href": "05-rdd.html#näide-vanaduspensioniiga-pensionide-saamine-ja-tööaeg-eestis-2010.",
    "title": "6  Regressiooni katkemise meetod",
    "section": "6.3 Näide: Vanaduspensioniiga, pensionide saamine ja tööaeg Eestis 2010.",
    "text": "6.3 Näide: Vanaduspensioniiga, pensionide saamine ja tööaeg Eestis 2010.\n\naastal oli meeste seadusjärgne pensioniiga 63 aastat. Selles vanuses võiksid nad saada täispensioni. Nad võivad minna pensionile varem (ja kaotada pensioni suuruses) või hiljem pensionile jääda (ja neil on suurem pension). Neil võib olla ka eripension, mida mõnikord maksti varem, või ka töövõimetuspension.\nPensioniiga annab õiguse vanaduspensionile, väikesele, kuid kindlale lisasissetulekule, mis võib võimaldada vanematel inimestel oma tööaega lühendada.\n\nMeie uurimisküsimus: - kuidas mõjutab pensioni saamist nominaalpensioniikka (63) jõudmine? (Me peame seda järsuks disainiks– sest õigus tekib igal mehel) - kuidas mõjutab pensioni saamine nominaalpensioniea (63) lähedal töötunde. Seda võiks pidada hägusaks disainiks, sest nominaalpensioniikka jõudmine mõjutab pensioni saama hakkamist vaid osadel inimestel.\nProbleem on selles, et vanus ise mõjutab tervist, mis loomulikult vähendab tööaega. Kuidas neid mõjusid eristada – üks tervise ja teine lisatulu kaudu? Meil ei ole tervise jaoks selget mõõdikut, seega kasutame vanust lihtsalt lähendina.\nTeeme oletuse: vanuse mõju tööajale tervise kaudu on pidev, kuid vanuse mõju pensioni saamise õigusele on diskreetne (või hüppeline).\nLaadige paketid.\n\nlibrary(tidyverse)\nlibrary(haven) #Stata failide jaoks\nlibrary(rdrobust)\nlibrary(lmtest) \nlibrary(sandwich)\nlibrary(stargazer)\nlibrary(rdrobust)\nlibrary(ivreg)\n\n\nLaadige andmed\nMeil on järgmised tunnused\n\nage\nppension - 1-0 tunnus, kui inimene saab pensioni (meie meede)\noldage – inimene saab vanaduspensioni\ndisben – inimene saab töövõimetuspensioni\nhours – nädala töötunnid (meie väljund)\nemployed - 1-0 kui inimesel on täisajaga töökoht\ntaustatunnused: estlang (räägib Eesti keelt), haridus (haridustase: 1,2,3)\n\n\ndf &lt;- read_dta(\"https://kodu.ut.ee/~avork/files/oppetoo/micro/pensioners.dta\")\n\n\n\nAlati alusta joonistest\nTee joonis vanuse ja pensioni saamise vahel\n\ndf %&gt;% ggplot(aes(x=age, y = pension)) +\n  geom_point()\n\n\n\n\n\n\n\n\nlisa sammhaaval a) silumine b) värvi vanuse järgi age &gt; 62 c) tee punctid väiksemaks (size = 0.5) ja läbipaistvaks (alpha = 0.5) d) lisa juhuslikku müra punktidele “position = position_jitter(width = 0.2,height = 0.05, seed = 1234)” e) lisa vertikaalne joon 62.5\nVaata, kuidas joonis muutub\n\ndf %&gt;% ggplot(aes(x=age, y = pension, \n                  color = age&gt;62)) +\n  geom_point(size = 0.5, alpha = 0.5, \n             position = position_jitter(width = 0.2,height = 0.05, seed = 1234)) +\n  geom_smooth() +\n  geom_vline(xintercept = 62.5) + theme_bw()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\nKeskmine vanusrühmade järgi\nArvutage pensioni saavate meeste keskmine osakaal (muutuja pension), keskmine tööaeg (muutuja hours) vanuse järgi ja näitaja (over62), kui vanus on üle 62,5\n\ndfmeanprop &lt;- df %&gt;% group_by(age) %&gt;% \n  summarise(pension = mean(pension)*100,\n            hours = mean(hours),\n            over62= as.factor(mean(age&gt;62.5)))\n\nJoonistage igas vanuses pensioni saavate meeste keskmine osakaal, värvige see üle62 võrra. Lisa silutud joon.\n\ndfmeanprop %&gt;% ggplot(aes(x=age, y = pension, color = over62)) +\n  geom_point() +\n  geom_smooth(se= FALSE) +\n  scale_x_continuous(breaks = c(seq(50, 75, 5)))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nKas 63-aastaselt on hüpe?\nKas pensioniea mõju pensioni saamisele on järsk või hägune?\n\n\nVanus ja töötunnid\nJoonistage lähteandmet põhjal seos iganädalaste töötundide ja vanuse järgi. Kasutage sama koodi, mida kasutasite pensioni jaoks, kuid asendage pension töötundidega. Vajadusel muutke position_jitter\n\ndf %&gt;% ggplot(aes(x=age, y = hours, color = age&gt;62)) +\n  geom_point(size = 0.5, alpha = 0.5, \n             position = position_jitter(width = 0.2,height = 1, seed = 1234)) +\n  geom_smooth() +\n  geom_vline(xintercept = 62.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nJoonista samuti grupeeritud andmete järgi\n\ndfmeanprop %&gt;% ggplot(aes(x=age, y = hours, color = over62)) +\n  geom_point() +\n  geom_smooth(method = lm, se = FALSE) +\n  geom_vline(xintercept = 62.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nTee lõikepunkt ja leia vanus selle suhtes\nTeeme muutuja ‘penage’ = 62.5\n\npenage = 62.5\n\nLooge uus muutuja “agec”, mis on erinevus vanusest 62,5. (Me ei tea täpselt, millal inimene sai 63-aastaseks, seetõttu kasutame 62,5). Looge tsentraliseeritud vanuse ruut ja kuupliige. Genereerige ka näitaja (1-0) muutuja, kui vanus on vanem kui pensioniiga: “overpenage”.\n\ndf &lt;- df %&gt;%  \n  mutate(agec = age-penage,\n         agec2 = agec*agec,\n         agec3 = agec*agec*agec,\n         overpenage = (age&gt;penage)*1)\n\n\n\nJärsk (terav) disain – pensioniea mõju tõenäosusele saada pensioni\nVanaduspensioni ea kättejõudmise mõttes on tegu järsu disainiga (inimestel tekib õigus täispensionile, küll aga mõned valivad või saavad minna varem ja mõned hiljem). Võrdleme pensioni saamist enne ja pärast pensioniiga Võtame u = 2. Võrdleme pensioni saamist vanuses 61-62 ja 63-64.\n\nu = 2\n\nLeia käsitsi osakaalud enne ja pärast pensioniiga\n\nmeanpensbelow &lt;- df %&gt;%  filter(age&gt;penage-u, age &lt;penage) %&gt;% \n  summarise(meanpensbelow = mean(pension)) %&gt;%  as.numeric()\n\nmeanpensabove &lt;- df %&gt;%  filter(age&gt;penage, age &lt;penage+u) %&gt;% \n  summarise(meanpensabove = mean(pension)) %&gt;% as.numeric()\n\nKui suur on erinevus pensioni saamises enne ja pärast pensioniiga?\n\nmeanpensabove - meanpensbelow\n\n[1] 0.3123874\n\n\nVõtke u = 1. Kui palju tulemus muutub?\n\n\nMõju hindamine regressioonimudeliga\nHinnake lineaarne tõenäosusmudel (mudel1), kus pensioni näitaja sõltub näitajast, kui inimene on pensionieas ja vanus. Lisage seejärel vanuse ruutliige (mudel2) ja kuupliige (mudel3)\nMuutuja “overpenage” koefitsient näitab pensioniea mõju pensioni saamise tõenäosusele. Vanus iseloomustab teiste kanalite mõju, nt terviseseisundi ja töövõimetuspensioni saamise.\n\nmodel1 &lt;- lm(pension ~ overpenage + agec, data = df)\nmodel2 &lt;- lm(pension ~ overpenage + agec +  agec2 , data = df)\nmodel3 &lt;- lm(pension ~ overpenage + agec +  agec2 + agec3, data = df)\n\nVõrrelge tulemusi tabelis\n\nstargazer(model1, model2, model3, type = \"text\", no.space = TRUE)\n\n\n===================================================================================================\n                                                  Dependent variable:                              \n                    -------------------------------------------------------------------------------\n                                                        pension                                    \n                                (1)                        (2)                       (3)           \n---------------------------------------------------------------------------------------------------\noverpenage                   0.316***                   0.361***                  0.221***         \n                              (0.028)                    (0.029)                   (0.037)         \nagec                         0.029***                   0.025***                  0.050***         \n                              (0.002)                    (0.002)                   (0.005)         \nagec2                                                   -0.001***                 -0.001***        \n                                                        (0.0002)                  (0.0002)         \nagec3                                                                            -0.0002***        \n                                                                                  (0.00003)        \nConstant                     0.472***                   0.497***                  0.578***         \n                              (0.016)                    (0.016)                   (0.021)         \n---------------------------------------------------------------------------------------------------\nObservations                   2,607                      2,607                     2,607          \nR2                             0.496                      0.503                     0.509          \nAdjusted R2                    0.495                      0.502                     0.509          \nResidual Std. Error      0.354 (df = 2604)          0.352 (df = 2603)         0.350 (df = 2602)    \nF Statistic         1,279.302*** (df = 2; 2604) 877.175*** (df = 3; 2603) 675.659*** (df = 4; 2602)\n===================================================================================================\nNote:                                                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nPensioniea vanuspiiri ületamise efekt tõenäosusele, et mehed saavad pensioni on 31.6 protsendipunkti kui lubame lineaarse liikme mudelisse, 36.1 protsendipunkti ruutliikega mudelis ja 22.1 protsendipunkti kuuliikmega mudelis. Seega see, millist mittelineaarsust me lubame vanuspiiri lähedal, mõjutab meie tulemusi üsna palju.\nSaame lubada ka erinevaid parameetreid lõikepunkti mõlemale poolele. overpenage koefitsient näitab nüüd pensioniea kättejõudmise mõju pensioni saamise tõenäosusele lõikepunktis.\n\nmodel1a &lt;- lm(pension ~ overpenage + agec +  \n                agec*overpenage, data = df)\nmodel2a &lt;- lm(pension ~ overpenage + agec +  agec2 + \n               agec*overpenage +  agec2*overpenage , data = df)\nmodel3a &lt;- lm(pension ~ overpenage + agec +  agec2 + agec3 +\n               agec*overpenage +  agec2*overpenage + agec3*overpenage, data = df)\n\n\nstargazer(model1a, model2a, model3a, type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                       pension                                   \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  0.363***                  0.200***                  0.176***         \n                             (0.028)                   (0.042)                   (0.058)         \nagec                        0.039***                  0.086***                  0.073***         \n                             (0.002)                   (0.010)                   (0.025)         \nagec2                                                 0.004***                    0.001          \n                                                       (0.001)                   (0.004)         \nagec3                                                                            -0.0001         \n                                                                                (0.0002)         \noverpenage:agec             -0.028***                 -0.045***                   0.009          \n                             (0.004)                   (0.016)                   (0.042)         \noverpenage:agec2                                      -0.006***                  -0.012          \n                                                       (0.001)                   (0.008)         \noverpenage:agec3                                                                  0.001          \n                                                                                (0.0004)         \nConstant                    0.535***                  0.640***                  0.625***         \n                             (0.018)                   (0.027)                   (0.038)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.505                     0.511                     0.511          \nAdjusted R2                   0.505                     0.510                     0.510          \nResidual Std. Error     0.351 (df = 2603)         0.349 (df = 2601)         0.349 (df = 2599)    \nF Statistic         885.732*** (df = 3; 2603) 543.685*** (df = 5; 2601) 388.675*** (df = 7; 2599)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nNäeme, et mida suurt mittelineaarsust lubada, seda väiksem mõjuhinnang on. Kuupliikmetega mudelis on pensioniea kättejõudmise mõju 17.6 protsendipunkti.\nEdasijõudnutele: kasutame robustseid standardvigu, mis lubavad heteroskedastiivsust\n\nstargazer(model1a, model2a, model3a, \n          se=list(sqrt(diag(vcovHC(model1a, \"HC1\"))),\n                  sqrt(diag(vcovHC(model2a, \"HC1\"))),\n                  sqrt(diag(vcovHC(model3a, \"HC1\")))),\n          type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                       pension                                   \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  0.363***                  0.200***                  0.176***         \n                             (0.030)                   (0.048)                   (0.068)         \nagec                        0.039***                  0.086***                   0.073**         \n                             (0.003)                   (0.012)                   (0.033)         \nagec2                                                 0.004***                    0.001          \n                                                       (0.001)                   (0.006)         \nagec3                                                                            -0.0001         \n                                                                                (0.0003)         \noverpenage:agec             -0.028***                 -0.045***                   0.009          \n                             (0.004)                   (0.015)                   (0.042)         \noverpenage:agec2                                      -0.006***                  -0.012*         \n                                                       (0.001)                   (0.007)         \noverpenage:agec3                                                                 0.001*          \n                                                                                (0.0003)         \nConstant                    0.535***                  0.640***                  0.625***         \n                             (0.024)                   (0.037)                   (0.053)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.505                     0.511                     0.511          \nAdjusted R2                   0.505                     0.510                     0.510          \nResidual Std. Error     0.351 (df = 2603)         0.349 (df = 2601)         0.349 (df = 2599)    \nF Statistic         885.732*** (df = 3; 2603) 543.685*** (df = 5; 2601) 388.675*** (df = 7; 2599)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\nMitteparameetriline hindamine\nKasutame silumist paketist rdrobust.\n\nrdrobust(y = df$pension, x = df$age, c = 62.5) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$pension, x = df$age, c = 62.5): Mass points detected\nin the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.778        3.778\nBW bias (b)                   5.943        5.943\nrho (h/b)                     0.636        0.636\nUnique Obs.                      13           12\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect     0.185     1.921     0.055    [-0.003 , 0.333]     \n=====================================================================\n\n\nTulemuste tõlgendamisest.\n\nVõib tulla hoiatus: masspunktid (mass points)\n\nSee tähendab, et vanusemuutujal on palju korduvaid väärtusi (meil täisaastad). See on vanusepõhiste RDD-de puhul tavaline – see ei riku disaini, kuid näitab, et jaotus ei ole täiesti sile.\n\nValimi suurus Kokku on vaatlusi 2607 vaatluse. Hinnang tehakse aga lokaalsete lineaarsete regressioonidega, kolmnurkse kerneliga lõikepunkti ümber. Optimaalne ribalaius (mserd) on umbes 3,778 aastat mõlemal pool lävendit, seega kasutatakse enim vanuseid umbes 58–67.\n\n“BW type mserd” – ribalaius või aken (bandwidth) on valitud nn mean squared error optimal for RD (ehk mserd) reegli alusel. See on automaatne optimaalne akna valik, mis püüab tasakaalustada täpsust ja nihet.\n“Kernel Triangular” – kasutatakse kolmnurkset kernelit (tuuma), mis tähendab, et lõikepunktile kõige lähemad vaatlused saavad suurima kaalu ja kaugemad väiksema. See on RDD puhul standardne valik, sest rõhutab just lõikepunkti ümbrust.\nVCE method NN – dispersioonide ja standardvigade arvutamisel on kasutatud nearest-neighbor (NN) meetodit, mis põhineb lähimate punktide võrdlemisel. See on üks võimalikest robustsete standardvigade arvutusviisidest.\n\nEfektiivne vaatlustearv Kuigi kokku on 2607 vaatluse, panustavad tegelikult kõige enam 472 vaatlust enne ja 332 pärast lõikepunkti, sest kaalumine annab rohkem kaalu neile, kes on lõikepunktile lähedal.\n\nOrder est. (p) - lõikepunkti ümbruses on kasutatud esimese astme polünoomi, ehk lokaalset lineaarset regressiooni. See on RDD standardne valik.\nOrder bias (q) = 2 - võimaliku nihke hindamiseks kasutatakse teise astme polünoomi (ruutfunktsiooni). Teisisõnu, nihke parandust hinnatakse natuke paindlikuma mudeliga kui põhihinnangut.\nBW est. (h) = 3.778 - Optimaalne aken hinnangu tegemiseks on 3,78 aastat mõlemal pool lõikepunkti.\nW bias (b) = 5.943 - Nihke hindamiseks kasutatakse laiemat akent, 5,94 aastat mõlemal pool lõikepunkti. See on tavapärane, sest nihke hindamiseks on vaja rohkem andmeid.\nrho (h/b) = 0.636 - See on suhe hinnangu akna ja nihke akna vahel: 3.78 / 5.94 ≈ 0.64. Väärtus alla 1 näitab, et nike hindamiseks kasutatakse suuremat akent kui põhihinnangu jaoks (mis on just õige).\nUnique Obs. = 13 (vasakul), 12 (paremal) - lõikepunkti ümbruses on ainult 13 erinevat vanuseväärtust vasakul ja 12 erinevat vanuseväärtust paremal. Kuna vanus on diskreetne (tavaliselt täisaastad), ei ole lõikepunkti ümber väga palju erinevaid väärtusi, mis võib täpsust piirata.\n\nKoefitsient (mõju)\n\nTavaline hinnang lõikepunkti mõjule on 0,185. See tähendab, et pensioniea ületamine suurendab pensioni saamise tõenäosust 18,5 protsendipunkti võrra. Standardviga: 0,070 z-statistik: 2,64 p-väärtus: 0,008 → statistiliselt oluline 1% tasemel\n\nRobustne (bias-corrected) hinnang on konservatiivsem: z = 1,921, p = 0,055. See on vaid napilt oluline 10% tasemel, sest 95% usaldusvahemik on [−0,003; 0,333] ja hõlmab nulli.\n\nTulemuste usaldusväärsus sõltub seega ka sellest, kas kasutame tavalist või robustset hinnangut: tavalise järgi on efekt kindlalt oluline, robustse järgi piiri peal.\nKommentaar robustsete standardvigade kohta\nTavaline (“Conventional”) punkthinnang on lihtsalt vahe lõikepunkti vasakul ja paremal poolel lokaalse polünoomi ekstrapoleeritud väärtustes, antud akna korral.\nStandardvead põhinevad asümptootilisel teoorial, kuid kipuvat liiga vähe arvestama nihet (bias), eriti väikeste valimite puhul.\n“Robust bias-corrected (RBC) hinnang” - Calonico, Cattaneo ja Titiunik (2014) järgi püüab korrigeerida lõikepunkti lähedal tekkivat hinnangute nihet.\nAlguses hinnatakse nihe kõrgema astme polünoomi abil.\nSeejärel lahutatakse nihe tavalise hinnangu väärtusest ning arvutatakse uued standardvead, mis arvestavad nii valimi juhuslikkust kui ka nihke korrigeerimist.\nPunktihinnang ise tavaliselt palju ei muutu, kuid usaldusvahemikud muutuvad laiemaks, sest standardvead suurenevad.\nSeega on RBC hinnang konservatiivsem ja usaldusväärsem, vähendades riski vale-positiivsete tulemuste jaoks.\nJa ka graafik\n\nrdplot(y = df$pension, x = df$age, c = 62.5)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\n\n\nPensioniea mõju töötundidele\nKäsitleme pensioniea mõju töötundidele nüüd hägusa disainina, sest pensioniiga ei määra täpselt pensioni saamist.\n\nKäsitsi LATE hägusa disaini jaoks\nArvutame käsitsi Waldi kohaliku statistiku (LATE) häguse disaini jaoks. Võtke +/- 2 aastat.\n\nu = 5\n\nOleme juba arvutanud keskmise pensionäride osa, mis jääb alla ja üle piirpunkti intervalli u piiresse. ‘meanpensbelow’ ja ‘meanpensabove’\nSamamoodi arvutame keskmised töötunnid allpool ja kõrgemal: ” meanhoursbelow “meanhoursabove”.\n\nmeanhoursbelow &lt;- df %&gt;%  filter(age&gt;penage-u, age &lt;penage) %&gt;% \n  summarise(meanhourbelow = mean(hours)) %&gt;% as.numeric()\n\nmeanhoursabove &lt;- df %&gt;%  filter(age&gt;penage, age &lt;penage+u) %&gt;% \n  summarise(meanhourabove = mean(hours)) %&gt;% as.numeric()\n\nLeidke muutused\n\n#muutus pensionäride osakaalus\nmeanpensabove-meanpensbelow\n\n[1] 0.3123874\n\n\nEerinevus pensioni saajate osakaalus on seega 0.312\n\n#muutus töötundides \nmeanhoursabove - meanhoursbelow\n\n[1] -9.098265\n\n\nTöötundide vähenemine on samal ajal -9.1 tundi nädalas.\nLATE on suhtarv, mis skaleerib muutuse.\n\nlate = (meanhoursabove - meanhoursbelow) / (meanpensabove-meanpensbelow)\nlate\n\n[1] -29.12494\n\n\nÕigus saada vanaduspensioni vähendaks töötunde ligi -29.1249376 tunni võrra nädalas.\nAga, et paljud on juba varem läinud pensionile ja paljud lükkavad edasi, siis andmetest me näeme pensioniea ligidal vaid vähenemist -9.1 töötundi.\n\n\n\nRegressioonimudel – kui oleks järsk disain\nHindame sarnased regressioonimudelid nagu üleval\n\nmodel1 &lt;- lm(hours ~ overpenage + agec, data = df)\nmodel2 &lt;- lm(hours ~ overpenage + agec +  agec2 , data = df)\nmodel3 &lt;- lm(hours ~ overpenage + agec +  agec2 + agec3, data = df)\n\nstargazer(model1, model2, model3, type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                        hours                                    \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  -3.984***                 -4.002***                  -1.638          \n                             (1.444)                   (1.496)                   (1.934)         \nagec                        -1.101***                 -1.099***                 -1.527***        \n                             (0.098)                   (0.106)                   (0.246)         \nagec2                                                  0.0004                     0.006          \n                                                       (0.008)                   (0.008)         \nagec3                                                                            0.003*          \n                                                                                 (0.002)         \nConstant                    18.005***                 17.995***                 16.636***        \n                             (0.804)                   (0.833)                   (1.091)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.215                     0.215                     0.216          \nAdjusted R2                   0.214                     0.214                     0.215          \nResidual Std. Error    18.326 (df = 2604)        18.330 (df = 2603)        18.320 (df = 2602)    \nF Statistic         355.784*** (df = 2; 2604) 237.099*** (df = 3; 2603) 178.938*** (df = 4; 2602)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nNäeme, et mõju hinnang on palju väiksem ja sõltub kui paindlikku mudelit kasutame. Lineaarse ja ruutliikmetega mudels on mõju vaid 4 tundi. Kui lubame vanuse kuupfunktsiooni, siis ei ole mõju enam statistiliselt oluline.\nTaas, kasutame praktikas robustseid standardvigu.\n\nstargazer(model1, model2, model3, \n          se=list(sqrt(diag(vcovHC(model1, \"HC1\"))),\n                  sqrt(diag(vcovHC(model2, \"HC1\"))),\n                  sqrt(diag(vcovHC(model3, \"HC1\")))),\n          type = \"text\", no.space = TRUE)\n\n\n=================================================================================================\n                                                 Dependent variable:                             \n                    -----------------------------------------------------------------------------\n                                                        hours                                    \n                               (1)                       (2)                       (3)           \n-------------------------------------------------------------------------------------------------\noverpenage                  -3.984***                 -4.002***                  -1.638          \n                             (1.528)                   (1.511)                   (2.066)         \nagec                        -1.101***                 -1.099***                 -1.527***        \n                             (0.101)                   (0.097)                   (0.256)         \nagec2                                                  0.0004                     0.006          \n                                                       (0.007)                   (0.007)         \nagec3                                                                            0.003*          \n                                                                                 (0.002)         \nConstant                    18.005***                 17.995***                 16.636***        \n                             (0.861)                   (0.927)                   (1.181)         \n-------------------------------------------------------------------------------------------------\nObservations                  2,607                     2,607                     2,607          \nR2                            0.215                     0.215                     0.216          \nAdjusted R2                   0.214                     0.214                     0.215          \nResidual Std. Error    18.326 (df = 2604)        18.330 (df = 2603)        18.320 (df = 2602)    \nF Statistic         355.784*** (df = 2; 2604) 237.099*** (df = 3; 2603) 178.938*** (df = 4; 2602)\n=================================================================================================\nNote:                                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nKui olete vanem kui 63, väheneb tööaeg kõige paindlikumates mudelites vaid 1.64 tundi nädalas.\n\n\nSilumise kasutamine\nJällegi kasutage kohalikku polünoomi silumist käsuga rdrobust, vaata ülalt käsku ja asenda pensioni saamine töötundidega\n\nrdrobust(y = df$hours, x = df$age, c = 62.5) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 62.5): Mass points detected\nin the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.710        3.710\nBW bias (b)                   5.647        5.647\nrho (h/b)                     0.657        0.657\nUnique Obs.                      13           12\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect    -0.134    -0.137     0.891    [-8.467 , 7.364]     \n=====================================================================\n\n\nSeekord näeme, et väga paindlikult hinnates, seos puudub. Saame vaadata seda ka joonisel.\n\nrdplot(y = df$hours, x = df$age, c = 62.5)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\n\nIseloomustamaks funktsionaalse kuju ja lõikepunkti valiku mõju, siis kui oleksime nõudnud lineaarset seost vanuse ja töötundide vahel ja paneks piiri 63.5 (sest tööturukäitumise kohandamine võtab aega), oleks mõju ca 4 tundi vähem töötunde nädalas, küll pole see statistiliselt oluline:\n\nrdplot(y = df$hours, x = df$age, c = 63.5, p = 1)\n\n[1] \"Mass points detected in the running variable.\"\n\n\n\n\n\n\n\n\nrdrobust(y = df$hours, x = df$age, c = 63.5, p = 1) %&gt;% \n    summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 63.5, p = 1): Mass points\ndetected in the running variable.\n\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1708          899\nEff. Number of Obs.             472          292\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   3.701        3.701\nBW bias (b)                   5.826        5.826\nrho (h/b)                     0.635        0.635\nUnique Obs.                      14           11\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect    -3.917    -1.207     0.228   [-12.433 , 2.958]     \n=====================================================================\n\n\n\nEdasijõudnutele: instrumentmuutuja kasutamine\nEsimene samm on hinnata pensioni saamise tõenäosus. Kasutage lineaarset tõenäosusmudelit koos overpenage ja lineaarse ja ruudukujul vanusega. Seejärel prognoosige pensioni saamise tõenäosus. Pange nimeks “pensionhat”. Hinnake tundide võrrand, kus pensioni saamise asemel on selgitavaks teguriks prognoositav pensioni saamine “pensionhat”.\n\npensmodel &lt;- lm(pension ~ overpenage + agec +  agec2, data = df)\nsummary(pensmodel)\n\n\nCall:\nlm(formula = pension ~ overpenage + agec + agec2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.01937 -0.21779 -0.01524  0.08558  0.96070 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4970274  0.0159821  31.099  &lt; 2e-16 ***\noverpenage   0.3611695  0.0287180  12.576  &lt; 2e-16 ***\nagec         0.0248456  0.0020332  12.220  &lt; 2e-16 ***\nagec2       -0.0009418  0.0001543  -6.105 1.18e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3519 on 2603 degrees of freedom\nMultiple R-squared:  0.5027,    Adjusted R-squared:  0.5022 \nF-statistic: 877.2 on 3 and 2603 DF,  p-value: &lt; 2.2e-16\n\n\nMeeldetuletus: kui palju pensioniikka jõudmine suurendas tõenäosust pensioni saada? Vaata “overpenage” kordajat.\nPrognoosime pensioni saamise, nimetame muutuja ‘pensionhat’.\n\ndf$pensionhat &lt;- predict(pensmodel)\nsummary(df$pensionhat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0393  0.2178  0.4290  0.5370  0.9509  1.0194 \n\n\nHindame töötundide võrrandi, kus sees on prognoositud tõenäosus pension saada.\n\nmodelf &lt;- lm(hours ~ pensionhat + agec +  agec2, data = df)\nsummary(modelf)\n\n\nCall:\nlm(formula = hours ~ pensionhat + agec + agec2, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-31.788 -13.444  -2.498  13.743  63.256 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  23.503075   2.745330   8.561  &lt; 2e-16 ***\npensionhat  -11.081325   4.141871  -2.675  0.00751 ** \nagec         -0.823388   0.201762  -4.081 4.62e-05 ***\nagec2        -0.010058   0.007967  -1.263  0.20687    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.33 on 2603 degrees of freedom\nMultiple R-squared:  0.2146,    Adjusted R-squared:  0.2137 \nF-statistic: 237.1 on 3 and 2603 DF,  p-value: &lt; 2.2e-16\n\n\nPensioniikka jõudmise mõju töötundide vähendamisele on ligi 11 tundi. See on sarnane käsitsi hinnatud LATEga (vt üles).\nKäsk ivreg teeb selle kahesammulise hindamise automaatselt.\n\nfuzzyreg &lt;- ivreg(\n  hours ~ pension + agec +  agec2 | overpenage + agec +  agec2,\n  data = df\n)\n\nsummary(fuzzyreg)\n\n\nCall:\nivreg(formula = hours ~ pension + agec + agec2 | overpenage + \n    agec + agec2, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.224 -12.008  -2.667  11.570  67.354 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  23.503075   2.490179   9.438  &lt; 2e-16 ***\npension     -11.081325   3.756926  -2.950  0.00321 ** \nagec         -0.823388   0.183010  -4.499 7.12e-06 ***\nagec2        -0.010058   0.007226  -1.392  0.16408    \n\nDiagnostic tests:\n                  df1  df2 statistic  p-value    \nWeak instruments    1 2603    158.17  &lt; 2e-16 ***\nWu-Hausman          1 2602     19.74 9.23e-06 ***\nSargan              0   NA        NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.63 on 2603 degrees of freedom\nMultiple R-Squared: 0.3538, Adjusted R-squared: 0.3531 \nWald test: 288.2 on 3 and 2603 DF,  p-value: &lt; 2.2e-16 \n\n\nvaadake kordajat pension Pensioniikka jõudmise mõju töötundide vähendamisele on ligi 11 tundi.\n\n\nPaindlikum mudel\nVõime kasutada veelgi paindlikumat mudelit, lokaalset lineaarset regressioonimudelit, taas paketist rdrobust.\n\nrdrobust(y = df$hours, x = df$age, c = 62.5, fuzzy = df$pension) %&gt;% \n  summary()\n\nWarning in rdrobust(y = df$hours, x = df$age, c = 62.5, fuzzy = df$pension):\nMass points detected in the running variable.\n\n\nFuzzy RD estimates using local polynomial regression.\n\nNumber of Obs.                 2607\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                 1608          999\nEff. Number of Obs.             472          332\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   4.500        4.500\nBW bias (b)                   7.303        7.303\nrho (h/b)                     0.616        0.616\nUnique Obs.                      13           12\n\nFirst-stage estimates.\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n=====================================================================\n     Rd Effect     0.193     2.134     0.033     [0.014 , 0.319]     \n=====================================================================\n\nTreatment effect estimates.\n\n=====================================================================\n                   Point    Robust Inference\n                Estimate         z     P&gt;|z|      [ 95% C.I. ]       \n---------------------------------------------------------------------\n     RD Effect     0.930     0.190     0.849   [-33.306 , 40.450]    \n=====================================================================\n\n\nSelle paindliku mudeli järgi ei ole seost pensioniea ja töötundide vahel. Seost ei ole, sest muutus töötundides võib olla mittelineaarse seose tulemus vanuse ja töötundide vahel.\n\n\n\nPlatseebo-test\nVaatame, kas vanuses 63 on hüpe erinev võrreldes teiste lõikepunktidega. Me sooviksime näha, et 63 on hüpe kõrge ja mujal ei ole erinevused statistiliselt olulised.\n\n#Meie väljund\ny &lt;- as.numeric(df$pension)\n#jooksev muutuja\nx &lt;- as.numeric(df$age)\n\n# Võimalikud lõikepunktid\ncuts &lt;- seq(60, 65, by = 0.5)\n\n#Funktsioon võtmaks välja meie hinnangud \nextract_rd &lt;- function(cu) {\n  out &lt;- rdrobust(y = y, x = x, c = cu)\n  est &lt;- out$Estimate\n  # Meie hinnangud\n  tau_us &lt;- est[1, \"tau.us\"]\n  se_us  &lt;- est[1, \"se.us\"]\n  tau_rb &lt;- est[1, \"tau.bc\"]\n  se_rb  &lt;- est[1, \"se.rb\"]\n  #Teeme tabeli\n  data.frame(cutoff = cu, tau_us = tau_us, se_us = se_us, tau_rb = tau_rb, se_rb = se_rb)\n}\n\nJa nüüd rakendame tabelit. Kasutame Ri käsku mapdfr, mis annab tulemustest andmetabeli. Ja funktsiooniks on meie enda tehtud funktsioon extract_rd\n\nres &lt;- map_dfr(cuts, extract_rd) %&gt;%\n  mutate(\n    #Ligilähedased 95% usalduspiirid robustsete hinnangutega \n    lwr_rb = tau_rb - 1.96 * se_rb,\n    upr_rb = tau_rb + 1.96 * se_rb,\n    #Ja tavapärased\n    lwr_us = tau_us - 1.96 * se_us,\n    upr_us = tau_us + 1.96 * se_us\n  )\n\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\nWarning in rdrobust(y = y, x = x, c = cu): Mass points detected in the running\nvariable.\n\n\nJa paneme tulemused joonisele. Kasutan praegu tavalisi standardvigu (mitte nihkega- korrigeeritud.)\n\n# \nggplot(res, aes(x = cutoff, y = tau_us)) +\n  geom_ribbon(aes(ymin = lwr_us, ymax = upr_us), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud koos ligilähedase 95% usalduspiiridega\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nJa ka robustsed usalduspiirid.\n\nggplot(res, aes(x = cutoff, y = tau_rb)) +\n  geom_ribbon(aes(ymin = lwr_rb, ymax = upr_rb), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud koos ligilähedase 95% usalduspiiridega\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nJoonistelt näeme, et tõepoolest kas vanus 62.5 või 63 on see, kus on statistiliselt oluline hüpe pensioni saamise tõenäosuses. Samas on mingi kummaline tõenäosuse vähenemine hoopis vanuses 65, mis muidugi ei saa olla tõene, aga viitab metoodika nõrkusele.\n\n\nPlatseebo test ka töötundidele\nNüüd peame muutma funktsiooni keerukamaks, et ta võtaks arvesse meie hägusat disaini\n\n#Meie väljund muutub\ny &lt;- as.numeric(df$hours)\n#meede\nz &lt;- as.numeric(df$pension)\n#jooksev muutuja\nx &lt;- as.numeric(df$age)\n\n#Funktsioon võtmaks välja meie hinnangud \nextract_rd &lt;- function(cu) {\n  #See rida muutub\n  out &lt;- rdrobust(y = y, x = x, c = cu, fuzzy = z)\n  est &lt;- out$Estimate\n  # Meie hinnangud\n  tau_us &lt;- est[1, \"tau.us\"]\n  se_us  &lt;- est[1, \"se.us\"]\n  tau_rb &lt;- est[1, \"tau.bc\"]\n  se_rb  &lt;- est[1, \"se.rb\"]\n  #Teeme tabeli\n  data.frame(cutoff = cu, tau_us = tau_us, se_us = se_us, tau_rb = tau_rb, se_rb = se_rb)\n}\n\nJa taas rakendame\n\nres &lt;- map_dfr(cuts, extract_rd) %&gt;%\n  mutate(\n    #Ligilähedased 95% usalduspiirid robustsete hinnangutega \n    lwr_rb = tau_rb - 1.96 * se_rb,\n    upr_rb = tau_rb + 1.96 * se_rb,\n    #Ja tavapärased\n    lwr_us = tau_us - 1.96 * se_us,\n    upr_us = tau_us + 1.96 * se_us\n  )\n\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\nWarning in rdrobust(y = y, x = x, c = cu, fuzzy = z): Mass points detected in\nthe running variable.\n\n\nNing tulemused\n\n# \nggplot(res, aes(x = cutoff, y = tau_us)) +\n  geom_ribbon(aes(ymin = lwr_us, ymax = upr_us), alpha = 0.2) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_vline(xintercept = 62.5, linetype = \"dotted\") +\n  labs(\n    title = \"Platseebo hinnangud - pensioniea mõju töötundidele\",\n    x = \"Lõikepunkt\",\n    y = \"Hinnang (nihkega korrigeerimata)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nNäeme, et mõjud kõiguvad väga palju. Mingeid erilist hüpet või muutust me ei näe pensioniea juures. Pigem on mingid anomaaliad vanuses 64.\nKokkuvõtteks, me tõesti näeme hüpet pensioniea lähedases vanuses pensioni saajate seas. Kuid me ei saa ümber lükata nüll hüpoteesi, et töötundidele otsest pensionieani jõudmine avaldaks mõju. Töötundide vähenemine toimub sujuvalt.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regressiooni katkemise meetod</span>"
    ]
  }
]